{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of pritil2_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan0122/PRI/blob/master/Copy_of_pritil2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYipE0hzw7Z5",
        "colab_type": "text"
      },
      "source": [
        "1. Funcion de costo 1(cka-itl)\n",
        "Capa RBF fourier \n",
        "$$L_{1}(S_{est},S_{true})=R^{+}$$\n",
        "$$S_{est}\\in R^{N\\times D}$$\n",
        "$$S_{true}\\in R^{N\\times F}$$\n",
        "\n",
        "$d^{2}(x,x')=(x_{n}−x_{n'})S^{-1}(x_{n}−x_{n'})^{⊤}:\\forall n,n' \\in N$\\\n",
        "$S=E[(x-E[x])(x'-E[x'])]$\\\n",
        " $K_{S_{pred}}=A^{2}e^{\\frac{-d^{2}(S_{pred},S_{pred})}{2\\sigma_{x}^{2}}}\\in R^{N\\times N}$\\\n",
        " $K_{S_{true}}=A^{2}e^{\\frac{-d^{2}(S_{true},S_{true})}{2\\sigma_{y}^{2}}}\\in R^{N\\times N}$\\\n",
        " $\\textbf{H}=I-\\frac{\\textbf{1}\\textbf{1}^{T}}{N};I \\in R^{N\\times N};\\textbf{1} \\in R^{N}$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{pred}}\\textbf{H})\\in R$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{true}}\\textbf{H})\\in R$\\\n",
        "$L_{1}=\\lambda\\log \\left(\\frac{\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}}{\\sqrt{\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}}}\\right)$\\\n",
        "$L_{1}=\\lambda\\log (\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F})-0.5\\lambda\\log(\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F})$\n",
        "\n",
        "\n",
        "2. Funcion de costo 2- Supervisado(cka itl,crossentropy, mse,kl)\n",
        "Capa Out\n",
        "$$L_{2}(S_{est},S_{true})=$$\n",
        "$$S_{est}\\in [0,1]^{N\\times C}$$\n",
        "$$S_{true}\\in [0,1]^{N\\times C}$$\n",
        "- cka itl\\\n",
        " $K_{S_{pred}}=A^{2}e^{\\frac{-d^{2}(S_{pred},S_{pred})}{2\\sigma_{x}^{2}}}\\in R^{N\\times N}$\\\n",
        " $K_{S_{true}}=A^{2}e^{\\frac{-d^{2}(S_{true},S_{true})}{2\\sigma_{y}^{2}}}\\in R^{N\\times N}$\\\n",
        " $\\textbf{H}=I-\\frac{\\textbf{1}\\textbf{1}^{T}}{N};I \\in R^{N\\times N};\\textbf{1} \\in R^{N}$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{pred}}\\textbf{H})\\in R$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{true}}\\textbf{H})\\in R$\\\n",
        "$L_{2}=\\lambda\\log \\left(\\frac{\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}}{\\sqrt{\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}}}\\right)$\\\n",
        "$L_{2}=\\lambda\\log (\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F})-0.5\\lambda\\log(\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F})$\n",
        "- MSE\n",
        "\n",
        " $L_{2}=E\\left [(S_{pred}-S_{true})^{2}\\right]$\n",
        "- Cross entropy\\\n",
        " $L_{2}=-E_{S_{true}}[\\log(S_{pred})]$\n",
        "- KL\\\n",
        "$L_{2}=E_{S_{true}}\\left[\\log\\left(\\frac{S_{true}}{S_{est}}\\right)\\right]$\\\n",
        "$L_{2}=E_{S_{true}}[\\log(S_{true})-\\log(S_{est})]$\n",
        "3. Funcion de costo 2- No Supervisado(cka-itl)\n",
        "Capa Out\n",
        "$$L_{3}(S_{est},S_{true})=R^{+}$$\n",
        "$$S_{est}\\in [0,1]^{N\\times C}$$\n",
        "$$S_{true}\\in R^{N\\times F}$$\n",
        "$K_{S_{pred}}=S_{pred}S_{pred}^{T}$\\\n",
        "$K_{S_{pred}}=\\frac{K_{S_{pred}}-\\min(K_{S_{pred}})}{K_{S_{pred}}}$\\\n",
        " $K_{S_{true}}=A^{2}e^{\\frac{-d^{2}(S_{true},S_{true})}{2\\sigma_{y}^{2}}}\\in R^{N\\times N}$\\\n",
        " $\\textbf{H}=I-\\frac{\\textbf{1}\\textbf{1}^{T}}{N};I \\in R^{N\\times N};\\textbf{1} \\in R^{N}$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{pred}}\\textbf{H})\\in R$\\\n",
        "$\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}={\\rm{tr}}(K_{S_{true}}\\textbf{H}K_{S_{true}}\\textbf{H})\\in R$\\\n",
        "$L_{1}=\\lambda\\log \\left(\\frac{\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F}}{\\sqrt{\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F}}}\\right)$\\\n",
        "$L_{1}=\\lambda\\log (\\left\\langle K_{c(S_{true})},K_{c(S_{pred})}\\right\\rangle _{F})-0.5\\lambda\\log(\\left\\langle K_{c(S_{true})},K_{c(S_{true})}\\right\\rangle _{F})$\n",
        "- Prueba 1\n",
        "Funcion fcosto1 y fcosto2 no supervisado\n",
        "-Prueba2\n",
        "Funcion fcosto1 y fcosto2 supervisado con ckaitl\n",
        "- Prueba3\n",
        "Funcion fcosto1 y fcosto2 supervisado con sparse categorical crossentropy\n",
        "- Prueba4\n",
        "Funcion fcosto1 y fcosto2 supervisado con mean square error\n",
        "- Prueba5\n",
        "  Funcion fcosto1 y fcosto2 supervisado con mean Kl divergence\n",
        "DB= Carita, Luna y Mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5wOheyNiZO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "2c976880-006d-42ac-8796-56431ccdd01c"
      },
      "source": [
        "# Cargar base de datos sinteticas\n",
        "#https://drive.google.com/file/d/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB/view?usp=sharing\n",
        "#id del archivo: 17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB\n",
        "\n",
        "FILEID = \"17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O codigos.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip codigos.zip\n",
        "!dir\n",
        "!pip install mne==0.19"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-18 14:30:34--  https://docs.google.com/uc?export=download&confirm=&id=17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.100, 74.125.20.113, 74.125.20.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e=download [following]\n",
            "--2020-08-18 14:30:35--  https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e=download\n",
            "Resolving doc-0k-1k-docs.googleusercontent.com (doc-0k-1k-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-0k-1k-docs.googleusercontent.com (doc-0k-1k-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=4k1ve7flojlfu&continue=https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e%3Ddownload&hash=r6510rkvf08s25rparq2p8uqsev74deg [following]\n",
            "--2020-08-18 14:30:35--  https://docs.google.com/nonceSigner?nonce=4k1ve7flojlfu&continue=https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e%3Ddownload&hash=r6510rkvf08s25rparq2p8uqsev74deg\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e=download&nonce=4k1ve7flojlfu&user=15853050876854306554Z&hash=akbvf5td1r4dm2c6voq61gvp9rq8nhu6 [following]\n",
            "--2020-08-18 14:30:35--  https://doc-0k-1k-docs.googleusercontent.com/docs/securesc/suogshtos7c7ume5v228h3tm3crdkskp/va5f6mm3gceppf1ug7vi96qhggtu7dhm/1597761000000/11146100322577758036/15853050876854306554Z/17lVU6fkPARDwRSThDR4LCIw5AvdkoIRB?e=download&nonce=4k1ve7flojlfu&user=15853050876854306554Z&hash=akbvf5td1r4dm2c6voq61gvp9rq8nhu6\n",
            "Connecting to doc-0k-1k-docs.googleusercontent.com (doc-0k-1k-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121016 (118K) [application/x-zip-compressed]\n",
            "Saving to: ‘codigos.zip’\n",
            "\n",
            "codigos.zip         100%[===================>] 118.18K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-08-18 14:30:35 (146 MB/s) - ‘codigos.zip’ saved [121016/121016]\n",
            "\n",
            "Archive:  codigos.zip\n",
            "  inflating: CKAPRI/CKA_PRI.py       \n",
            "  inflating: CKAPRI/DB.mat           \n",
            "CKAPRI\tcodigos.zip  sample_data\n",
            "Collecting mne==0.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/44/b5b96426623c9dca0dfcdcfdf1f57058bb668f7c1a01bed0b0b867eb8b92/mne-0.19.0-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne==0.19) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne==0.19) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEDaulN-ifbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "Path='/content/CKAPRI'\n",
        "sys.path.append(Path)\n",
        "DB = os.path.join(Path, 'DB')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC9HspfVhYEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "642d4230-1385-4616-ce0c-f49ba3f74e19"
      },
      "source": [
        "!pip install tf-nightly\n",
        "import numpy as np\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import scipy.io as sio\n",
        "from CKA_PRI import *\n",
        "import tensorflow as tf\n",
        "from joblib import dump,load\n",
        "from sklearn import  datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_probability as tfp\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from datetime import date, datetime\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans, SpectralClustering\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from sklearn.metrics import accuracy_score,jaccard_score"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/1e/d33a4339aea9597e532b6ba181560dc646135d2825c3b4c994ea0f5ab99f/tf_nightly-2.4.0.dev20200818-cp36-cp36m-manylinux2010_x86_64.whl (325.9MB)\n",
            "\u001b[K     |████████████████████████████████| 325.9MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.31.0)\n",
            "Collecting flatbuffers>=1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Collecting tb-nightly<3.0.0a0,>=2.4.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ea/088f4a0ea268e5d159db9658b846bf64d104606afaf0c83e0c0c9d2f92d7/tb_nightly-2.4.0a20200818-py3-none-any.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/b3/2559478c65b8b88911b7b44a5d3372d453a9fc5fb0fef21dc3f7a91a4c79/tf_estimator_nightly-2.4.0.dev2020081801-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (49.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "Installing collected packages: flatbuffers, tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed flatbuffers-1.12 tb-nightly-2.4.0a20200818 tf-estimator-nightly-2.4.0.dev2020081801 tf-nightly-2.4.0.dev20200818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MgbWageYNXr",
        "colab_type": "text"
      },
      "source": [
        "**Pre proceso Happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kq4XPNmix7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c41a025c-10d6-462c-a8a8-e349c6109af5"
      },
      "source": [
        "data = sio.loadmat(DB)['DB'][0, 0]\n",
        "#happy = data['happy']\n",
        "happy = data['happy']\n",
        "Ck = 3\n",
        "sc = SpectralClustering(n_clusters=Ck, n_neighbors=5, gamma = 500)\n",
        "sc.fit(happy)\n",
        "labels_happy = sc.labels_\n",
        "labels_happyo=labels_happy\n",
        "u=np.unique(labels_happy)\n",
        "labels=np.zeros((labels_happy.shape[0],len(np.unique(labels_happy))))\n",
        "for i in u:\n",
        "  labels[np.where(labels_happy==i),i]=1\n",
        "labels_happy=labels\n",
        "\n",
        "plt.scatter(happy[:,0],happy[:,1],c=labels_happy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f52462b4128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wUVdfHfze72TKbhJZQpFeRovCAXRELiA1FUFAfu4IKoj42xIZipVlRBOuLWAAVUVAEBbtIUBDpvUmXlt5+7x8nm2yZ2d0km2ST3O9+5pOdmXtnzk52z9w59xRFEhqNRqOpvsRVtgAajUajKV+0otdoNJpqjlb0Go1GU83Ril6j0WiqOVrRazQaTTXHXtkCBJKcnMwWLVpUthgajUZTpVi6dOl+kilm+2JO0bdo0QKpqamVLYZGo9FUKZRSW632adONRqPRVHO0otdoNJpqjlb0Go1GU83Ril6j0WiqOVrRa0xZh3X4ET/iCI5UtigajaaMaEWv8WMv9uJknIwTcAJ6ozeSkYyRGFm0fyVWYhZmYT3WV6KUGo2mJMSce6WmcrkclyMVqShAQdG2Z/Es9mIvNmIjfsfvsMOOXOSiN3pjOqbDAUclSqzRaMIR0YheKdVHKbVWKbVBKTXCos2VSqlVSqmVSqkPfLbnK6WWFS6zoyW4Jvpsw7YgJe/lLbyFX/ALMpCBIziCTGTiG3yDJ/BEJUiq0WhKQtgRvVLKBmAigF4AdgBYopSaTXKVT5u2AB4CcDrJg0qp+j6HyCTZJcpya8qBAzgQcn8OcvzWM5GJN/AGnsbTZT73fuzHHMwBAFyEi5CM5DIfU6PRCJGM6E8CsIHkJpI5AD4CcGlAm1sBTCR5EABI7o2umJqKoAM6lLhPBjLKfN6pmIqmaIqhha+maIqpmFrm42o0GiESRd8YwHaf9R2F23xpB6CdUupnpdRvSqk+PvtcSqnUwu2XmZ1AKTW4sE3qvn37SvQBNNHDCSdGYVTE7RUUzsW5ZTrnDuzAYAxGFrKQXvjKQhaGYAh2YEeZjl2TWbwY+O9/gfPOA155BUhPj85xSeCnn4AXXgBmzgRycsL3CWT9emDRIuDff6MjkyYCSIZcAAwA8KbP+rUAXg1o8yWAzwDEA2gJuTHULtzXuPBvKwBbALQOdb5u3bpRU7kM4RDGMY4I86rN2lzP9WU61wROoJPOoGO76OILfCFKn6hm8cYbpGGQSpGAvG/fnjx6tGzHzcoizz6b9HhIh4NMTCQbNCA3bIis/4ED5BlnkG43WasW6XKRDz1EFhSUTS6NACCVFno1khH9TgBNfdabFG7zZQeA2SRzSW4GsA5A28Ibyc7Cv5sALALQNfLbkKYymIRJWIEVGIVRcMNt2sYOO37AD2iDNmU6VzaykY/8oO15yEMWssp07JpIejpwzz1ARoaMvgF5v3Ur8MYbZTv2uHHAb7/JOXJygKNHgX37gEGDIut/zTXA778DmZnA4cNAVhbw8svAhx+WTS5NeCJR9EsAtFVKtVRKOQAMAhDoPTMLQE8AUEolQ0w5m5RSdZRSTp/tpwNYBU3M0wEd8DgeR3d0N91PEFMwBZ/hM3yDb3AUR0MebyM2YgqmYAZmIBOZRdv7oi/iER/UPh7xuDRoKkgTjtRUwG7iYpGZCXz6aei+8+cDF10EnHQS8NRToox9eecdOY4vBQXAihXA3jCzcvv3AwsXBpt60tOB8eND99VEAauhPv1NMxdCRukbATxcuO1JAH0L3ysAEyBKfAWAQYXbTytcX1749+Zw59Kmm8ojhzl8na/zVJ7KM3gG3+E7XMRFNGiENOF46KGbbr7Ft4KOWcAC3sN76KKLBg0mMpG1WIu/8beiNiM4ggYNKirGMY4GDd7H+/gO3+FNvInP8Bnu4q6KvBRVlmXLxLQi43n/5ZJLrPuNGycmHm9bl4ts2ZI8dKi4TZMm5sd1ucidO0PLtWGDtVzNm0flo9d4EMJ0E5Gir8hFK/rKIZ/5PI/n+Sl1Dz3sz/78jt+xFVuFtdkbNPgH//A77lzOpYeeoLYpTGEuc4vaLeZi3lP4ms/5bMM2Rf1cdDGBCVzMxZbypzOdj/JRNmdzNmMzPsyHmca0crtesUpBgShOM4Xaq5d5n0OHRFkHtne7yeefJ/PyyDvuIG028+N26BBerrw8Mjk5uK/dTg4ZEtVLUGPRil4TlvmczwQmmCrv0RxNF11hFb2NNg6h/6+2H/uZtk1iEkdyJP/D/7A1W/Me3sN93EeSvJt300FHUJ92bMcCBs/c5TOfJ/NkPxlddLEbuzGPeRVy/WKFZctEeZopZKeT3L07uM+335JJSeZ9Tj+dHDrU/EZgt0u/u+8mGzcm69Ylr7/e/ynAl08+kaeGuLhieVJSwj8NaCJDK3pNWEZypKlCjmc8a7FWWCXvfV3Oy/2OeyJPNG3noMNPMTvoYBM24SEeYhM2Me3jpJM7GawV5nGe6U0qgQmcwzkVdQkrnYICsm1bc4UNiKfLL78E9/vrL2uzit1e7L1jduPo0SN4e0ICmWbxMJWaSl59NXnKKeTDD5N79pTvNalJhFL0OqmZBgDQAA1MPWwccISdaPXigQf90K9ofTEWYzmWm7bNQY6fV00OcrAHe3ANroGCMu2TjWzT6N1UpJoGbqUhDamoOWUpN28GdoQIPcjKAtqYOEnZ7YDLZd4nL6/YeyeQ7Gzgxx+Dt6elAcOHm/fp1g2YNg349VeZ8K1f37ydJrpoRa8BAFyFqxBn8nWINPLVDTc6oiOuxJVF2x7H40FpE7zYYAvalotczMVc7MIu0z4KCpMxOWh7MzQzvUklIAHN0Cwi+asDJKDM75FQSgKoUgJKR8+dC3TvDhw8WPpzmjHbIqtVVhbwzz9AfrBHraYc0YpeAwBIQQrmYi7qoz4SkFC0naBpkjMv3tF3DnLQGI2RjuIQzJVYadnPzHfee7485Fnu+w7f+W1LQxo+w2d+5/XK5YADV+AKSxmqG61aAY0ame/r1QuYNMl/W34+cMMN4mdfYP0vLhXx8eJ2+fLLwPvvA4cOAf/7H1C3rjxV1K8PTA6+Z2vKCZ2mWFNED/TAP/gHwzEckzAppIL3QsiQLh/5mIM56IVeWIIlAIC6qBv1NAbN0dxv/QpcgYVYGNSuHdrhM3wGDzxRPX8soxQwYwZw9tlicklPBxISgC5dgM8/l9H3hx8Cn30G1Ksn6REyyp6qyJSGDYGTT5YbSHw8cPPNIl92tuzPzJTArpQUoF+/0MfSlB2t6DV+2GDDYiyOSMkHkoMcrMEaLMESfIJPsA7ryiSLgiq6kQCAAQMjUJwleyu2YhEWIRvZQf26oiuOw3FlOn9VpGtXYNs2YPp0YOdO4LTTRPF/9x0wdKhsy8wE4uKAd9+VG0I0UQpo2hRYu7Y4uCo727xtRgbw2GNAx45AkyaAYURXFk0xWtFrgshFbqn7ZiELP+EnvIyXI0ph4IILcYgLmgswYKADOmAFViC+8PUSXkIP9Chqsw3b4IQz6DwEa3QFrKQk4JZb5P2ePUCnTsCWLf4Kt6BA7OVKidIPZbpRCmjRQtIomLWz24HGjYFjjgFuvFGeKrZti0zWv/8GjjtOjvHgg8ATT1jPM2hKj7bRA5KO79xz5dvau7ck9KjBnIJTSt03H/l4A2/ACWfYtnGIQ3u0x0zMhAEDLojrhwce9EEf/IbfsBM7sRRLsRd7cS2u9evfER2DRvOAeAqdiTNL/RmqEzfeCGzcaD2q9njErp+QALjN0xohLk5G3FYKOC9PbgJLl4q3zdq1JZOxoEBSIzz9tGTa1EQfRatp80qie/fuTE2tQJe4efOAyy/3N1YaBjBnDtCzZ8XJEUOsxmp0QRdLj5lwOOFEHOL8ctp4scEGA/KMXg/1sBAL0QItsBu78QE+wAEcQB/0wRk4w9LN0pcH8AAmYmLRE0Ec4lALtbACK9A4KJt2zSIjA6hdG8gN8YCWmCgeMk6nmHVeeUUUtm9aY6WsvWvMcDjk5pBVipx0KSnh8+ZozFFKLSVpkZwqBoKkfJcKD5hq3948GqRLl4qVI8Z4ja/RRRc99JhGqYZ61WIttmVb2mn3227Q4Af8gFfwCp7Dc/giX+RhHi6TnAUs4Jt8k+3ZnvVZn1fxKm7ipihdharNoUNkfLx1ABUgaYbzfIKHc3MlEtYq3UEki1Jk06bFQVhOZ+R94+Iq73pVdaAjYy3Iz7f+xtntFSdHjLKXezmVU/khP+QNvIEOOiLKU++ii2u4hj3Yo+hmUY/1OJ7jmcjEoohYgwYbsiF3cEdlf9RqS5cu5l/v+HhJP/Dnn8F9+vYtvZL3KvpbbyW/+Ya8/37Jl9OwYWR9Gzas+GtULvz6K9mzJ1mnDnn88eRnn5X7KbWiD0XduubfuEaNKlaOCuAAD/BW3srarM26rMthHFaiEfUe7uGP/JHX8TrGM55uugmCiqpIyXvo4cN8uKjPTu7kKq5iLnP5H/4n6KZgo43X8Jqw505jGudwDr/hN8xmdqk+f01k2TLJR+N2y9faMMh69ciPP5bRuxmDBpVd0S9Y4H/M0aOLZQi1fPll+V+TcufXX/1TgXov/FvB2V2jiVb0oXjmGfN/yksvVawc5UwOc9iWbRnP+CIl66STJ/AE5jPftM9hHuYojmJHduSpPJXTOK0oqdhhHuYf/IPLuIy38BY2ZVN2YRe+z/dNE4+lMS3IlONr6gnFDM6ghx4mFb5qsRYXcmGZr0lNYe9eGVXfeKNUnzLLQzNzpuTJsdtlpB+J6ebKK83bxcfL8XzJySEvu0yUfWJicWIz3yUxkbzgAvK334Llq1KcdZb5BXO55A5YTiW1tKIPRX4+OWKEKHePR5bHH6929c1mcIZp4q9EJvJrfs293MsH+AA7szN7sRdncRbbsZ1f4jEPPRzGYaU6fxaz/G4yvq8GbGDZbwu3FD05BCYsK6t9XyPMnBk81olk1H711eb77HbyuefMz7V6NfnRR+TixeSKFaL8AxOnGUbwE0GVonZt6wtnGGS/fqJ3ooxW9JGQkUFu2kRmZlbO+cuZh/mwqZK1087H+BgbsZHfpKuDDlPF7KST27itVDL0Y7+giV033XyEj1j2eZpPm04GJzCB7/G90l4OjQ9t2pRMyQMyMh86VDJVmo3M50SYNNRqDqFTp/L9zOVK586hL57HQ86YEfXThlL0NcuPPi9PIjLq15d0feedB6wszMfidgMtW1qn8avitEEb03QAbrixEivxL/71c6fMQY5p4JQDDvyKX03PkY98zMVcjMVYfIEvgnLWTMEUtEd7OOEscp3MRz4aoqGl3NuwzdTNMw95OIIjlv00kbN5c+n63XYb0KCBpDjw4nAAzZoB558f2TFWrDDfvnKlaMUqyahRocN809MlhWdFYnUHqKyl3Eb08+fLBGtgcu3ERHLLlvI5ZwyRznTWZ30/rxkbbWzKpuzKrqajfbNXAhP4Pb8POv4BHuBxPI6JTKSddiYyka3Zmnvon3B8GqfRSaffMQ0anMRJQcd8iS9ZmnvcdHMN1/i1X8zFvI7X8QJewEmcxAxmRPciVjHy88kpU8gTTiBbtSLvvZfcvz+4XYsWJRvNezzktddK3337yBtukJ9RUhI5eDB58GDkMqakmJ+jXr3oXINKY8oUuSihJjiiDGq86WbiROsp//h48q67on/OGGQjN7Ine9Je+Dqf53M7t/MSXhKxom/MxqaTt15PnECzUH/292vXmq1Nj9uQ/n51a7jG1DbvvTHcRf//2SROokGj6EZm0OAJPKFGK/tbb/W3vTscotSPHvVvN21aZDZ6paRs4OTJpTMx5+eTX38t/g8ffCBW0jFjzH0hnn46OtegUsnIkGovZpMYd9xBHo7uHFPNVvQZGeaGRN/ltNOie84YJ5OZzGJW0XokBcC9rz7sY3pMq/522v28cKxG6CD8yv6N4ihTLx0bbbyLd/kd8wiPmN4UDBqcyInlcAVjny1bzMv/GQb5yivB7d97z7r4t1fJd+xYenmOHiW7dZOfos0mf2vXlnnJTp0kqCohQcZj991XLnOVlcP338sHCyzh5XZLEd2NG6N2qlCKvvrb6FetknjsULRqVTGyxAguuPxy0ZyFs/ACXkACEpCEJD8beiBLsTRoW17hywyv1vXSCubX2gMPuqEbmqAJLsfl2Imdphk0HXCgLdr6ybcYixGP+KC2GcjATMw0PV91Z8kSwBZc2wUZGcCCBcHbr7sO2L5dctTv3SupjR0OSY2QmCipCT75pPTyjB4tCczS0uQcaWmSo/6zz2S7zQZccgmwbx8wdmz4n2yVoUcPqbRy7LH+yYIyM4F//5WJjgqgulxOa1JSJGNSKBYujH6+1irGYAzGPuzDd/gOy7AMDjhM2zVAA7/1eZiHBmhgqpRtsKEP+vhVrnoezxfluvElHelYjuXYiZ34DJ9hKqaaykAQl+ASv221UMsyrXI91DPdXp3Jzwfeess/X42X+Hjzcc3u3cCGDfI+JQX480/gl1+AceMknfG2baKrQpGXB3zwAXDppcA11wDff1+8b+pU68RqgNyAPv8cWF8dk44mJprPLhcUSP7oaFd9McNqqO+7AOgDYC2ADQBGWLS5EsAqACsBfOCz/XoA6wuX68Odq1xs9GedJQZKq+fSxETyiy+if94qzA28wc+H3msKeZ/vF7XZxm2WJhsPPTyGx5i6Yn7Oz3ksjw1rJmrBFkV2dxttdNLJ+3hfUEBWAQvYgi38InS98tbEwKoXX7S2uRsGuX59cdtdu8gzzxTTiWFICoKvvirZ+Q4elGCswCAowyCffFLaNGoUfg7AZqsmtnkzrKqvOxxRi9lBWWz0AGwANgJoBcABYDmADgFt2gL4E0CdwvX6hX/rAthU+LdO4fs6oc5XLop+/37JO2EV7ud0VrtI2LKSwQwO5EC66GISk2jQ4NN82k/JPsWngjxoQPHBv5N3Wk6EZjOb0zgt6EYS+KrLukxlKi/lpXTSSQ89NGiwAztwI/1tm2u5ls3YjIlMZBKT6KKLYzimXK9RrNK2rbUyrV1bFPKxx8rYplMnmRsMVNCrVxcfb8cOWfdNfuYlP1+8egKP4fvT2rlTPH7CJTeLi5MJ5GoWqygMHhx8ARwO8prw6T8ipayK/lQA83zWHwLwUECbMQBuMel7FYA3fNbfAHBVqPOVa8DUSy+Ze98kJMikiYakjJC/5/d8hI/wST7Jb/kt0xgcNz+UQ00VtJtuvs7XTY/9Bb8Iq+C9r47syBVcEfTUEMc4NmfzIO+ffObzJ/7EL/gFD/BAuVybqkAko2evEjabsLXbyWHDRMGfcoq08XjE5fH118W/wcu334b2dUhIIN9/nzxyRHJ7hfOLMAzy5psr79qVG4cPF89Gu93yt3Nn8t9/o3aKsir6AQDe9Fm/FsCrAW1mFSr7nwH8BqBP4fb7ADzi0+5RAPeZnGMwgFQAqc2aNYvaBw8iK0scin1zt7pc8m2ulsOIkpPHPPZjP3rooaKiiy4aNPgVg5/nZ3GWaVoFN91cxVVB7bdya0ivm0Czy0f8iHfwDtpoC9qfyET+wB8q4pJUOYYMsR5hm42izbZfcIFk8DZ7CHa7xcRSUCAePKFG6h6PJEl76CHJ9TV7NjlqFHnnndbWVMOQZGxVnj17yHHjxH37k08k4c8PP8jd8rvvoq5zKkLRfwngMwDxAFoC2A6gdqSK3ncp9xQI+/fLY1TduhKtcd995lmeaiBbuZX3835TV8UkJvm5ZJJyUziDZ/iNuD308EbeaHr8URwVVsHHMY4JTOALfIEkeSkvNW2XyETO5EzT89R0du8mjzmm+OE1XE56M0U7fHjo0bdhSIqoxo3DH89ulxuKYfiHrIwcGRy/6JV3TFW3uv3yi1xA7yNTQgL5n/+Uq64Jpegj8brZCaCpz3qTwm2+7AAwm2Quyc0A1kHs9pH0jQ65ucCmTcDhw6Hb1asHvPEGcOCA+JGNHSv11GowecjDNbgGx+JYvIAXTCtDAcAv+MVv3QYbFmABxmIsTsEp6ImeeBNv4i28Zdp/B3ZYymCDDTMwA2uwBgdwAHfjbgDAhbjQNHVDOtIxAzPwO37HURzFDuwoVUHz6kiDBuJV/NRTQN++wJ13SqlAM+rX9//6OxxA3brimROqdmtGBvD881KVygzfvnl54liSkQFMmQIsXizbU1LEfTMQhwOoVSv0Z4xpSGDQIPEh9ZbZSkuTf8pLL5n3Wb4cGDECuP9+4Pffy0OmsCN6O2QStSWKJ2M7BrTpA+C9wvfJkBF9Pcgk7GbIRGydwvd1Q52vVCP6KVNklsnjkefIq6/2NyRqQvI0nw4bMJXIRNPUByVhFmdZHr8LzSt6ZTCDHdjB9CnD641jo41uutmIjTibs8skY3Xi8GF5YG3cWAI0A805NptYFN55h+zalWzZUuzoVrb7SJfOncXObub5o5TIRIrHj1kbj4c8UJWnWNautXZ7at8+uP3TT0t7m00ukGHI7HUJQVkjYwFcCBmlbwTwcOG2JwH0LXyvAEyAuFeuADDIp+9NELfMDQBuDHeuEiv6r78OvqguF3nVVSW+UDWVY3hMWJNKXdZlLi0qVURIHvPYgi2Cjm2jLaQb5FEe5fN8ns3ZPGyFK4MGU5laJjmrA7m5Eskayqs4Lk6yR3pNxVdcYW2zj3RJSiJ/+ol8+21zj0KbTez1Xr78sjhPTlKS3JDmz6+caxY1Nm2yTrly/PH+bTduNG/rdpuX/wpBmRV9RS4lVvRnnml+QV0u6xntFSvEXaAk2ZeqMYlMDKk4E5jAD/khx3Ecx3Is13N9+IOaMJVT6aTTz9/dQQc/5scR9e/DPmFvSHGM40AOLJV81YVvv43Mdg7IjeDnnyUdlFWbQDu6mV3d92e3bx+5dav5JK3bTf71l7+8mZnkvHlSejAry/wzxTxpaeTUqeTYsVI5pWPH4AtlGOSrr/r3e/FF88cnm03qYpSA6q3orVLvJSSQa/yzG/Kff8Tp1zBk6OBykc8+G3zMggJzp+FqyuW83HSkXJd1+Sbf5HN8ji666Ch8uejiWI4t0Tn2cZ+lW2Vd1uV+mqRVDGAQBwUFRZm9WrJlaS9FlWfp0pIXEXn11fCmGu+Eqs0Wuq7GrbdKNSu3u/iYNlvxepWfZDVj2TK5KAkJMpPs8UjcTkqKPK64XPJPufTS4PqNr71mfvHj40scPVa9Ff1//2vuA5aUFDw8OPHE4LaGUVwlISNDssq53XI37taN/P33kslTBdnIjazLuqZFQTqwg2lQlIsuruM6FrCAR3jEshyhl3f5Lj30mCpmG20cxVFBMo3jOI7neG7mZpLkD/whouRrdtr5NKtriGVo+vcPPeI2W+6/P7J6ruFG9PHxctMIvNHYbBKYtXVrZV+dcqCgQFy2Ay+GYZAvvyyTIK+8IndgMyZNMr+YLhe5YUOJRKnein79elHqvsZFs0ekDRusv829ekmbiy8OvrsmJIjNrZqzm7vZgz2CRvY22kxH0Xba2Y/9mMxk2mlnHdbhBE4wrRdLku/wnZCBUqfzdJJix3+cj9NJJx100EknXXTxVcr/cyzHhrXTe01OZkFe1Z327Uum5AGZOC1JeytF7/GQJ59svs/plNq11Y7Vq63TG4TTZX/9Za2TJpY862ooRV/1k5q1aQOkpgIDBwJNmgAnnwx8+CEwdKh/u3//9S+F48veveKauWBBsTuUl+xsYMKE8pE9hmiABtiADUEuivnIB8Gg9nnIwxf4AvuxH3nIw0EcxCN4BK/iVdPjX4yLLd0fFRRaoRXexbtIRjKewBPIRjZykINsZCMLWbgP92ErtuI+3IfP8Jll0jUvdtixDusi/PTVh27dSpb5MSkJmD69ZOcggzNjGgbwwAPyUzIjPl48mqsd+fml2wcAr71mnnAxIQE4/viyyRVA1Vf0ANC2raTN274d+O03cR4OpHNn+YYG4nRK+/XrzZ16c3PFx7WasRZrMQzDcD7OxxiMwSEcsvSftyIwNXEGMjAao03bJiMZUzDFNP2xG250QzcMxVAcwiHT/lnIwvW4HkdwBH3RF9MwDY3QyC8zpi85yEEjNCrR56kOjBwpVTF9cbnENz0QpYAnnzT/WYTCMIB77pExlcsFNG0qWS4ffRTo1Quw24P72O1A69YlO0+VoEMHoE6d4O2GAdxwQ+i+//xjfjOIi5N8zdHEaqhfWUu5Rsa+846YdbzPni4X2ayZOO1u3Wo+KeJwFDv+VhO+4Tc0aBQV9vD6oPdnf9NiHyV9+RYQCWQ5l7Mt2xb5viczmZ/wE3Zn97DHtdHGzuxcdPx85nM2Zwf52Lvo4mW8rKIuZ8yRmirOaC6XRMiOH08uWiTzgt5QE4dDMkseOBA+2Vjgz6FlS+sAz23bJCeObzSuYUhhk2rLL7/IxfWaYRIS5B8QzoVo0iTzmXOXS4IMSgiqtY2+pPzyi9RrPP10mdX2dbEcONDfZqaU2P+3BafaraoUsIBN2CRIicYzntfxOjZkw6IJTyeddBe+Attbeb80Y2S5ivZwD9dybZHSrs/6Ed1EEpgQFBT1AT9gMpNp0KCTTg7ioBppnw9Hejo5fbr4uG/fXrz9iisiyyzZuLFM3IYLZtq5U1IodOpEXnhhDckXuH+/TLo+9JDE9kRSIisjQ2oz+uocj0dyQ5QCregjJSeHfOQRGZI4neR555ErV1aePOXAVm61rMXahE14iIf4Al/gFbyCj/Ex7uAOnsEz/Pq46GJbtjXNV/8RPwo6ZzazuZVbmclMS7ku5IURuU6C4ON8PKh/HvO4hVt4mNGtw1kTeP/98F43jRoF664VK8iHH5acN6kRxKjl5kq0rs4f6MPRo+JzeuKJ4hTy+eelPpRW9JoiDvBAkBul99WBHUz7ZDKTT/EptmZrtmIrjuIopjOdX/NrdmVXGjTYiZ34Of2/pAUs4HN8jolMpFH4up/3m7pi/sk/I3KdTGAC3+W75XJtaiJmgeVKFZtevCmKFy2SwKYlS8QJ7bnn5OZgsxX71zsckitw2DD/utc5OeTdd8t54uPJpk3JWbMq7zNXV2quoi8okGfU/eGDcWoSvdgrKF2wQYOTOKlEx9nN3XyYD/NMnqsjy3oAACAASURBVMmbeTP/5t9++6dwSpDyNmj4jcgLWMBf+AtncRbncz7P5/msx3rszM6sxVp+rpSKivVYj/u539KNU1MyTjrJfATvcklIyXPPibn47beLUxU4naF99Z1OyZ3jfQIYPDj4icEwJGOvJnrUTEX/ww8SNetyyVDj7LMlMlbDvdzLruxKDz1MYhKddHIwB4cNevJlK7eyHusVBVPZaKNBg9/wm6I2ZnltQEl5nM98buEWtmEbJjChqCrUSI4sUuIbuZGn8TTGM5522tmczVmHdRjHODZgA07hlKhfm5pGvXrmytrtLv65/PxzyaNtExIkZ82hQ9ZRt97wlWrPmjViu7/jDnmEKifbVc1T9Fu2BAcx2O3kccdpA2EhBSzgH/yDn/Nzbuf28B0C+C//a1oQpDmbFynqUAFSj/ARdmCHoOAnO+2cwAl+5zrEQ5zACaZPB++xOrtzRJe8PJkY/fLLYtPKWWeZK+FatYqj9QcMKHm0rcMhNTd+/NF6ordFi0q7FBXHu+/KXdObOtTjkVQIkUzWlpCap+gffNA8bV9CgqTW05QZKy8ZJ53cRXENO5knWyp6Bx2Wk69xjOPbfNvvfA3Z0LSt741FY82yZVL422t+cbvFu+/nn83NKhN87rWnnFIyJQ/IeR57zHqSVyny8ssr73pUCIcOmV8Aj4f89NOony6Uoq8eAVOBbNhgHnGmlARVaSImC1mYhVl4D+9hO4qvXS2YV4YgiARIlYtxGAcDhmm7HOSAoOm+AhRgGIYhDWlF67ux27TtVmyFDTY0QAO8jJctj1mTycsDevcGdu8Gjh4FjhwBMjMl6Ck+HnjmGYk5dLmk4MjEibLPy4UXyj4zzIqT2GxSvOSFF+Q8ZpDyM83OLvvni1kWLjSPxk9PBz76qEJFqZ6KvmdPiUwLJDdXYsQ1EbEES3AMjsH1uB7DMAxt0RaP4BEAwN24O0iJO+DAxbi4SNGfgTOwEAtxEk4yjYgNhR12/IpfAQBxiEMzNLNsSxB7sRcjMRJjMKZE56kJLFxornAzM4GzzgIeewzYs0e2DR4cHNA5bBiQnOwfOO5yiUKnyX311FOl+lSoClWAKPpp00r0UaoWZpH2gFyYwPDl8sZqqF9ZS1RMN0eOSMRrYHje1VeX/dg1hFzmMpnJQaYSDz1cwAXMZz7v4B100slarEU33TyLZ/EQDwUdawM3WPruW73iGc+f+XPRMT7gBxG5XyYxqcwFUqobM2eGrv8aaLZZtCj4GPv3SxzP8ceT554rWXitipTY7WTr1pGd8/zzK/56VBhZWTLZYXaRyyGKDDXORk9K9YPhw8kmTchjj5WUob455g8e1OUGSa7iKn7Mj/kH/yBJzuVcdmd3JjHJdLIVhF9hj13cxXmcxzVcY3UKkuRJPCkovYJBg8M53PQciopf8ku/Y3zKT9me7emiyzKDpZNO7uO+6F+oKszevcFlBK0WpSRAPBwnnhj+WOGqVUV6rpgkJ0cCnVq1kmiy2283T8/5/fcyYZGYKAre5SIffbRcRKqZit6Kn3+WXK7x8TJhO2BAjaw0lcUsXsSL6KabSUyiQYNt2CaikfcFvIBv8S32Zm8O4AB+y2/Dnm8Xd7Ebu9GgUfQEMJ7j+RN/sgzgCpWvxmqitxZr6RG9CcccE5miB8jevcMf7+67/R+YzZb4eJmLtHLNtHp6qBJcfrn/B4uPFyvC0aPBbdPSyI8+ktrWW7aUm0ha0XvZuDHY7dLhIE87rfzOGaM8xIdCuj9avTz0sA3b+BURMWgEFQ6xYjVX83t+zyM8QpJcwAVMYpLpubqzOwdwAM/hOZzIicxg8RPYAi4IuikZNDiO48rlelV1OneOTMl7POSbb4Y/3vbtUlQpXODUnDnk5Mnk//4nPvve2rBOJ/nMM+X/ucuFlSvNvWlcLvKWW6Q4eCWgFb0Xq2GIYZDLl5ffeWMQM/t7uFcCE9iRHU1t5S66uIu7+Dt/53k8j8lMZnd25xzOCSlHOtNNK0/FM95vpG/QYBd28cuXM5dzeRyPo402HsNj+Bpf066WFowZY21K8W73eCRSNtK6rRs2WBca8Y6hfAe4ubnkggUyZ1Cli5D83/9ZT0DY7aLwL7uMzM6uULG0ovdy/vnm/5ykpDIlE6qKWJX1M3vVYR3exJv4OT/nAA4wbZPIRI7maNNR9lRODSnLdE6nm+6itAweekx97D308C2+VUFXqHqRni6j+sBKmgMGyCD0sssklXBJdVNGBpmcbP6zGluyssJVh++/Dz/T7HZLIEEFohW9lyefNI/HdrlqRLlAX/qxn+mEZuA2gwY/4AdF/YZyqGk/g4alKagBG4RNr7CO6/gQH+KtvJUjOZKJTDQ91kW8qLwvTbUlO5ucNk2U+003katWRee469ZJbpu4uOLM3m+/Hb5flaWgQBw8ws1wN2gQ+jirV0tN6iiN/LWi97Jvnww/fIc1NdTtchM3sR7rFSlnJ51MZCKv43U0aNBNN2uzNl/my379lnN5iV0lHXTwAMMkMffhB/5gqujjGMebeFO0L4UmSuzbV8VNMiVh1y7xMzWLwPcuiYnmfTdtIjt2FN2TlCQumNOnl1mkMit6AH0ArAWwAcAIk/03ANgHYFnhcovPvnyf7bPDnatMij43V4rqdukiVQ+efz7YhXLrVlHsdepIvtTnnitO6lHD2M/9fIbP8DJexkf5KHdyJ0nxyPmH/1h6r7zDd2jQYBKTmMhEeugJWZnKQw9zmBOxXPnMZxM2CTLfGDS4hEui8tk1mqhw8KAobbOJjwEDgtvn50uJrsAJE8OQBP9loEyKHoANwEYArQA4ACwH0CGgzQ0AXrXonxbuHL5LmRR9377+Lk9ut8wu5eXJ8+W338qww4ysLMnAlJqqE59FwFEe5TzO48/8mefyXEsl76STIziixMdfwzVszuZFmS3ddPMNvlEOn0SjKSOpqTJ6947uXS6xHGzeHNz2xx/N7fs2m2S3LAOhFL1JGd8gTgKwgeQmAFBKfQTgUgCrShOJW24sWQIsWABkZBRvy8wEVq4ETjgB2LRJKiRnZwN33ukfo/3JJ8CNN8p6QQFQrx7w5ZdAp06V81mqAAlIQG/0BgCcilPxE35CNoITl1yH6/AUnirx8Y/FsdiMzViCJTiMwzgVpxalVtBoYopu3YBVq4DXXgP+/hs45RRgyBDRI4Hs3WueGyI/H/j6a0lMZFZdvaxY3QG8C4ABAN70Wb8WAaN3yIh+F4C/AMwE0NRnXx6AVAC/AbjM4hyDC9ukNmsWWc3RIF580TofauBjkscj6UNJ8Xk184mtX1+i3zRh2cVdrM3afqYWF13sz/6VLZpGE1v884+1noqPFxfwUoIKyF75BYAWJI8HMB/Aez77mpPsDuBqAC8qpVqb3Gwmk+xOsntKSkrpJGjUSEbsZhQU+K+npwMTJsj7KVMk2VkgWVnA/Pmlk6WG0RANsQRLcAkugQceNEADjMAIfIgPK1s0jSa2aNQIGD4ciDNRvbm5wOTJ5ZLSM5JnhJ0AmvqsNyncVgTJAz6rbwLFKQRJ7iz8u0kptQhAV4jNP7r07SuKXim5P4bjQKHIe/bI41IgBQXFbTRhaYM2+ByfV7YYGk3Fkp0NLFokSrpnTyAhAvPi888Dr78OpKUF7ysoAA4eBBo2jKqYkYzolwBoq5RqqZRyABgEYLZvA6VUI5/VvgBWF26vo5RyFr5PBnA6ysu273IB338PtGsnKYo9HqBpU0mMHYjdDpx/vry/8EJpG0heHtCjR7mIqtFoqgELFwINGgBXXglcc428nzEjfD+lJJezGQkJQGmtGiEIq+hJ5gEYBmAeRIFPJ7lSKfWkUqpvYbPhSqmVSqnlAIZDbPYAcByA1MLtCwE8R7L8JnE7dgRWrwaWLwdSU4GtW4F33xXF731UcjqB2rWBJ56Q9f79pZ9v/nqPB7j9dqB583ITVaPRVGEOHwYuuUT+HjkiS0YGcP31onfC8dxzwTUzDAMYM0YS/UcZxUjMHBVI9+7dmZqaGt2DLlsGjB8PbNwInH02cNddQP36xfuzsoC33wY+/FDuqH37SmGARo2Ac88tn1lwjUZTdXnvPanIEmh+cTiAxx8HRo4Mf4w//5R2S5cCzZpJv0suKbVISqmlhfOhQdQMDdalCzB1qvV+lwu44w7gttuAW24B7r1XngDi4oCkJLHBtWlTYeJqNJoY5+hR87m93FyxsUdC167AV19FVy4Laoaij5SpU4GPP/avu5aWBlx2mfjHajQaDQD06mXuD28YwMUX+28jge++k5F7y5ZiMbAqM1hOaEXvJT8fePBB/4ArQP5JmzaJ2ad1kGeoRqOpiRx7rFgAJk8Wd21A5vYuuMDfiSM9HTjnHAmoysoSk3BCAvDzz6L0Kwit6L2MHi1Ra2bYbME3AI1GU7MZP1689t55B8jJEc+bvn39R/qjRwN//SVKHhCTT3o6cO21wE8/VZioNWMyNhJq15YZdDPq1wf++adcZsM1Gk015phjgF27grfHxwP79gG1akXtVKEmY6MVGVu1KSiwVvIA8P77WslrNJrwBE7QhhpIB0bslyNa0QPiXXPcceb7OneWiReNRqOx4oMPJEAzPl4sABMnipIfODB44lUpSbRYp06FiacVvZd77w0etRuGhCprNBqNFZ9+Ctx6K7Bjh6zv2wc88IAo+yeeECcOb2oEj0ei9UO5e5cD2kZPAjfdBPzf//k/SrlcwKxZxakSNBqNxoz27YG1a4O3JyeLg0d+PvDFF8XulQMHRpYTp4SEstFrRT99OvDf/5pnsOzdG5g3r+Jk0Wg0VQ+3u9irxhebTbxs3O4KEUNHxoZi8mRzJQ9IkENGRnBOCo1GU73Ytk3s7AcPii/8WWeZB0SZ0bYtsGJF8PbkZLEMxADaRu+1q5lBymOXRqOpvnz2mZhfRo2SpGIXXwwMGBC5V8xzzwWP2g0DeOaZyG8W5YxW9EeOWO87/nggMbHiZNFoNBVLRoYEL2VmFhf8SE8Xk+2nn0Z2jAsvFBNwhw7iddOqlVgKbrqp/OQuIdp04w1fNuPVVytODo1GU/H88IN5jEx6unjGDBgQ2XEuvjg4x00MoUf0Xbuab09OliK/APDvv3LXd7vFJ/byy4GdO837aTSaqkOoFORWpUmrIFrRP/useQGAceMkkCo/HzjjDMlqmZUlOS1mzwZOOsk/y6VGo6l69OhhXr/V44kp00tZ0Yr+1FOBb7+VgiR168oI/8MPpVIMIAXCd+zw98zJzxfb/vTplSOzRqOJDg6HxMskJMjicsmT+403An36VLZ0UUPb6AEx0Xz3nfm+1avNq7Knpekc9RpNdeCss8QUO2uW5Lzq1Uu8cKoRWtGHo317scvn5PhvT0iQWrMajabqk5QEXHddZUtRbmjTTTh69wYaNxa3KS82m7hdXnll5cml0Wg0EaIVfThsNikQcMklouztduCii4Dff9cRsxqNpkqgFX04tm2TqjFffimz861bA489BjRpUtmSaTSaiuLTT4HTTgPatQPuugvYvbuyJSoRESl6pVQfpdRapdQGpdQIk/03KKX2KaWWFS63+Oy7Xim1vnC5PprClzt5ecCZZwKLF4uNPjtbstSdfbakItVoNNWfJ5+UOJpffwXWr5fU5V26VCkdEFbRK6VsACYCuABABwBXKaU6mDT9mGSXwuXNwr51ATwO4GQAJwF4XClVcdn2y8o330iSo8B8N3l5wHvvVY5MGo2m4jh0CHjqKf+a0bm5xcnPjjsOOO880RUxTCQj+pMAbCC5iWQOgI8AXBrh8c8HMJ/kvyQPApgPoOo4p27dGlwaDJBAqY0bK14ejUZTcZASBW+W3TYnR/LLr1kjcTj9+gGTJlW8jBESiaJvDGC7z/qOwm2B9FdK/aWUmqmUalqSvkqpwUqpVKVU6r5Yehw66STz7HMJCRItq9Foqi/ffCNm20jIyJCqUmYxNzFAtCZjvwDQguTxkFF7iewaJCeT7E6ye0pKSpREigLdukmItG8KUodDKrtHmuxIo9FUTT75xN9kEwnr1pWPLGUkEkW/E0BTn/UmhduKIHmApPdW9iaAbpH2jXk+/1y8bFq1kuK/d94pd/nAgr8ajaZ6YRjmeXCsyM2VwuAxSCSfYgmAtkqplkopB4BBAGb7NlBKNfJZ7QtgdeH7eQB6K6XqFE7C9i7cVnVwOIARI8Qmv22bJDurXbuypdJoNOXN9ddHXiHK6QTOOQdo0KB8ZSolYRU9yTwAwyAKejWA6SRXKqWeVEr1LWw2XCm1Uim1HMBwADcU9v0XwGjIzWIJgCcLt2k0Gk1s07UrMHq0KHuPJ3Tbc86RUoQxii4OHm0OHhS/25kz5Wlg8GDgnnuqVW5rjaZGsXu3VJwaOtS8UFGrVjHhhaeLg1cUWVnAySeLW6Y3CdoTTwA//iiRtRqNpmqxfTvw7rui7K+4QlKT+07QemvDxjha0UeT6dOBXbv8M11mZgILFwJ//mldzUqj0cQeX38N9O8vsTQ5OeJW3aCBPLWnpQH16knhooEDK1vSsGhFXxZ++klG7GvWACecIEnP0tLM26amakWv0VQVcnOBq6/2H72npQEFBcDYsTJRaxjmcTYxiFb0pWXuXPGl95YT3LlTMl06ncFBEzabuGZqNJqqwR9/BKc+AUTxT5sG3HFHxctUBnT2ytIyfLh/zVhSHvHMwqVzc2M2Yk6j0ZjgcMjo3YxAl8vDh+WJfe/e8perlGhFXxpycoBNm8z32WxA27b+j3RZWcA11wCPPFIx8mk0mrLRpQtQxyT/oscDDBki70lJe9CwIXDuuUCzZsBVV8nvPcbQir40xMdLhSkzGjQAHnzQP20CIG5Z48dXuTzWGk2NRCngiy+AunXlt24Y8pseNEi8bwBJVzxxoij2I0fkqf3zz8WdOsbQir40KAXcfXdwhSnDkCjaL780z5HhcAA//1wxMmo0NZX8fH+zajj27JGI93vuEUXttc2fcILMvb3zDjBhgtjt33yz+Gl93Ljg33lmprhjmplwKxE9GVsa8vKA44+XwuF//VWc9+b++2WSZuVKMeEETuaQQHJyxcur0dQEsrOBe+8F3n5bzKtt28qou2dP6z4//ih55fPzZWT+5ptAx47iEu12iz2+f3/zvgcOmG/Pz5cbQK1aZf5I0UKP6EtKWhpw4oniXvXHH3J3LyiQyLnHH5f1228PTnqmlNj8zjyzcuTWaKo7114rSj4zU5TtmjVS3/nvv83bFxSID3x6erFdPS1NBm8TJ4Y/3+mnm7tXNmkCJCWV/nOUA1rRl5QxY4DVq4tDoXNz5Yt13nnF2zp3BqZMEdteUpJM4LRtCyxYIOXITjlFRgstW0q7GEtDodFUOf75B5g9O9hkk5UFPP+8eZ/Vq8W2HkhmJjB1avhzjhkjQVQ2m6wrJebb116LOf96rehLyrRp5q6SWVn+kzBXXy3uVnPninJfs0Yi6nr3ljTHWVnAli1i67f6Imo0msjYvNk802RBgZhSzYiPtx5kRZKbqlMneaq//nox9/TrB3z/PdAn9oroaRt9SfHevc2YOROYPLl43eWSxzsA2LFDEpwFTt5kZEiujP/9Tyc+02hKy7HHmg/A7HapFOdl714xy/z0E9CuneSP37LFv49hALfeGtl527QB3nqr1GJXFHpEX1Kuv956n1l9WRIYNky+EH/9Zd4vOxtYsiQ68mk0NZHkZODGG4M94dxu8XUHJNlghw7yBP3ddzLxunu3TJomJsrAzDBkcvbmmyv+M5QjWtGXlPvvN59Nt9mAS01qpk+dKu5Z2dnWj4k5OWLjf/nl6Mqq0dQkXn0VGDVKSn0ahvymfv5Z0ggDwMiRwKFDxSP/vDwxodatK0p/zBgZ6c+cGfrJvQqi89GXhlWrZEI1K0smYw1DPGqWLAEaNfJve+KJEh4dCS6X2BO9X0yNRhM9kpPNXSIdDvGXr+Kuz6Hy0esRfWno0EHsemPGALfcArzwArB2bbCSByQPRqQUFMhoQqPRRJ9QLo+BJp9qhlb0paVuXfGYmTJFJlmtSo316xf5JCupXS01mvLizjuDU5M4HEDfvlrRa8rIgw8CjRsXf5HsdjHRmCl/u11uDBqNxhpSHBt+/93cAcKMjz6SSVivfT4+Xn6HJ58s9vlqjlb05U3dusDy5cBzzwEXXwzcdptUm3r6afmixceLgne7gcceE5cvjUZjzt9/A61bA6edJpOt9esDX30Vus/8+eJFs2dPcerh3FxxgkhLA44eLX+5Kxk9GVuZrFsHfPKJjFAuv1xy52g0GnNyciS9wL59/tsNQxwkmjc373fmmeJNY0ZcnAyuVq2KuWjWkqInY2OVdu2Ahx4Sty+t5DWa0Hz1lXmu97w8yXFjhVXtCEBG+Dt2RO4ZV0WJSNErpfoopdYqpTYopUaEaNdfKUWlVPfC9RZKqUyl1LLCZVK0BNdoNDWMffvMqz7l5AC7dln369Yt9Gg9Lk7MOtWYsIpeKWUDMBHABQA6ALhKKdXBpF0igLsALA7YtZFkl8LltijIrNFoaiI9epjXcU1IAM4/37rf6NHB3ja+5OTIpGw1JpIR/UkANpDcRDIHwEcATEJAMRrA8wBir46WRqOp+rRrJ6mIfV2ZDUMSiplFpXs54QTghx+As86S0bvv6N7jkRz2KSnlJ3cMEImibwxgu8/6jsJtRSil/gOgKck5Jv1bKqX+VEp9r5TSydhLwrZtEohlVaRYo6lpvPGGJBHr2VNG4c89ByxaJJ5roejWTdodOCBpEk44QY7x/vsy4q/mlDl7pVIqDsAEADeY7N4FoBnJA0qpbgBmKaU6kjwScIzBAAYDQLNmzcoqUtVn82aparN6tYxAateWL+TZZ1e2ZBpN5aKUFAsZONB/e06O/FbCKfzatcWN+bHHyk/GGCSSEf1OAE191psUbvOSCKATgEVKqS0ATgEwWynVnWQ2yQMAQHIpgI0AghzFSU4m2Z1k95Rq/ggVlvx8ecRcvlw8DDIypKjCJZcA27eH76/R1CTWrZPfi2HIcvnlwe6XmogU/RIAbZVSLZVSDgCDAMz27iR5mGQyyRYkWwD4DUBfkqlKqZTCyVwopVoBaAsghK+TBt9+Kxn2As01ublVIu+1RlNhHD4sgVM//igDpNxc4MsvxW9emzv9CKvoSeYBGAZgHoDVAKaTXKmUelIp1TdM9x4A/lJKLQMwE8BtJP8tq9DVmn/+sXYh27y54uXRaGKVqVOl7J9v0GdurvyGvv228uSKQSKy0ZOcC2BuwDZTIxfJnj7vPwHwSRnkq3mceqq5C5nHA5x7bsXLo9HEKqtXB1dsAySAav16oFevipcpRtGRsbHGscfKRKyvC5nLBTRrFjwBpdHUZLp1M88aGxcHHH98xcsTw2hFH2tkZ0ulqQkTgK5dRfE/8ADw22+A01nZ0mk0scOgQVLwx9fTxukUv3pvrWYNAF0cPHZITwfuuAP4+GOx0TdvLrnue/asbMk0mtjEMCRV8X33AV98IQr/2mslM2wVT1AWbXT2ylihTx8J6PCtZG8YUp6wQ2HGiZwcYNkyKWTcvr3+Mms0oThwQLxw8vOBiy4CGjSobInKFZ29MtbZtAn4/nt/JQ/I+vjx8n7GDAnT7tUL6N4d6NQpdFY+jaYm8/HHktJ42DBg+HCgRQt5Qq6haEUfC2zZYm5/z88Xz4K//wZuuAE4ckSWjAxgzRrxwtH+whqNP3v2ADfeKAGHaWliFs3KAu66q8YOjrSijwU6dDDPs+1wSEDI668Hj/YLCuTR9OefK0ZGjaaq8Omn5tvz8qSkYA1EK/pYoE4dcan0TaUaFyc2+nvuAXbuNPetVwrYu7fi5NRoYp2dO4GXXpJAqkDy8mSeqwaiFX1lQgLPPgskJwOzZskXMSlJlksvlYnYxo2BCy809xfOzpYRv0ZTndi9Gxg7Fvjf/8SbxmyQY0Zurvwe1q2zbhMqnXE1RrtXViaTJwNPPeUf3RcfDzz4oH92vWuvlVHK5s3FIxWPRyaaGjWqWJk1mvJk0SLg4otFuWdlyQTqCSdISoNwcSRffAEcPOifEsEXmw2oVSvqIlcF9Ii+MnnmmeAQ7owM8bTx/bK63cDixZJHu1s34JxzJG3xs89WqLgaTbmSny9BUN7JU0AmU//8U/LQh2PjRnOTjReXS45dA9GKvjKxqlOZliaPob4kJEiEbGqqjG4uu0z70WuqFytWmCvijAzg//6veJ2U9XbtxMx5zjli5jz+eFHmVhhGcUxKDUMr+srEKh9H8+bicaPR1CTi463NLr6/h3HjgNtvl8RlR48CCxdKBHlyMtC6tflvxzAk26XNVi6ixzpa0Vcm48fLF9AXwwBeeEFcJ4cMAerVk0Cpu++WL7VGU13p0AGoXz94u8cDDB4s77OzpfRfoMkzMxN44gmpDTt4sHiyud2i+O+6S2JRevcu/88Qo+gUCJXN778Djz4K/PUX0LYt8OST4jnQqZMEUnlNON5kTUuWiOtlJJDSXz8daKoKf/0lJTNzc2WJi5Pqah98IO83bwY6dzY38RxzjLhX1lBCpUDQXjeVzUknAfPm+W+bPh3YtcvfTp+dLW5j330HnHde6GPm5AAjRwKTJslIp317YOJEnSBNE/scfzywY4d40OzZA/ToIV43XurXt44Gb926YmSsgmjTTSzy++8yIRtIdrbUkg3HrbcCr70mo56CAmDVKknqFElfjaaycbuBK68E7rzTX8kDYsa5+WZzk+fjj1ecjFUMrehjkfXrzbcXFACtWoXuu2+fPBEEupllZWl3TE3V4PBhGZxYuUK+8IKk9DYMmcA95hjg3Xd1BbYQaEUfi/zxh/n2/PzwBRWsEqQVFMiTQqRRhhpNNPnpJ1HEjRtLSu7ffw9uk5sL3HYb0LAhcMopYqZ5/PFgTxy7XSJnDx+Wgc2OHcAVc89P0wAAF6BJREFUV1TM56iiaEUfi1gp4/j48L7zrVubJ0gDgO3bZfTzyy9lk0+jKQlffw2cf77ML/3zj8xJnX22pOb25aGHxAUyK0s8zDIyxJXSKljKbpdIVx1PEhat6GORK68095Rp315cLUNRt67Y6ANtmIDk0tm7V0ZUhw9HR1aNJhx33WUeAf6//xWv5+eL84BZu+efL38Zqzla0ccio0YBLVtKNCwgk1O1aknag0h46SU5RlKS+f6CAmDmzGhIqtGEJj/fOsnYn3/Kd5qUHDdWNvl9+8pNvJqCdq+MRWrXFn/iTz8Ffv1VzDHXXitBIJEQFwfcf7+Mhp54ItjGmZ0tAVkaTXkTFyff50OHgveRYpOfO1eyt1rR3dQ1XFMCIhrRK6X6KKXWKqU2KKVGhGjXXylFpVR3n20PFfZbq5Q6PxpC1wgcDknw9NJLUgotUMlnZsoE14oVwYr8yBFg9mx5EjAz4Tgc2qdeUzEoBdx7r/n3EJBR/McfW+eJd7uLy2lqSk3YEb1SygZgIoBeAHYAWKKUmk1yVUC7RAB3AVjss60DgEEAOgI4BsACpVQ7ktr1oyy8+674GMfFyaNx06bAnDnievn++xIC7s0bkp0tiZ68E7Qej+S3P+mkSv0ImhrEyJEy+JgwwdrRwGy73S52+27dyle+GkAkI/qTAGwguYlkDoCPAJhl7x8N4HkAvi4flwL4iGQ2yc0ANhQeT1Nali4Fhg6VgKojR2REtG6dFA1ft06UfGam7Dt6VCZgAeCMM8TTYdKkGltOTVNJxMUBY8ZI7iazpGJxcebb7XZxHNCUmUgUfWMA233WdxRuK0Ip9R8ATUnOKWnfwv6DlVKpSqnUfXriJTQTJwa7TxYUiDfNs88GpzcGZHR/xx3i3vbf/0aeK0ejiSbDhwfHeNhs4vLrW0YTEFPPNdeYJznTlJgy/+KVUnEAJgC4t7THIDmZZHeS3VPCuQ/WdHbvNs/1ERcH7N9fPIL3JT1dUiKsXVv+8mmqL7m5wIcfSnDSkCFSG2HfPmDGDPGNNxtk+HLssRK1nZIiHmVuN9ClC/Djj5J1skcPmT9KSQFGjIis2IgmIiLxutkJoKnPepPCbV4SAXQCsEhJ4EJDALOVUn0j6KspKRdfLIEmgf7GOTnAdddJbu5AN7WCAvHe6dZNglfOOMN//+rVMuG1apVE3t59t0QwRsKaNVLubc8esf0PGKCzZVZHcnMlmd7SpfL9iosD3nlH5oHcbpl0dThE4f/nP9bHuegiSdi3ejWQmCi1FwCgWbPgACpN9CAZcoHcDDYBaAnAAWA5gI4h2i8C0L3wfcfC9s7C/psA2EKdr1u3btSEID2dPO440u0m5WdGejzk6NFkQQF56aWy7t0XuHTs6H+8RYtIwyBtNtnvcJC1apHr1oWXZcYMkcNuL5bjxBPJzMzy+eyaymPatNDfK++SkkLm5la2tDUSAKm00KthTTck8wAMAzAPwGoA00muVEo9WThqD9V3JYDpAFYB+BrAUGqPm7JhGJInZPRo4NRTZYT0ySfAI4/IqOrTT0NX0lmzpvhpgJQo2oyMYq+HnByZxH3ggdByZGUBN90kE79ec1F6OrByJfDWW9H5rJrYYfr0yOqtZmfrkXkMoguPVFcaN5a8IoG4XKLI7XZJg5CSYm5brVXLPMjFy08/yU3myJHgfWecIXZXTfXhxhuB996zLvXnJSlJ6rleauaYpylPQhUe0e4X1ZVhw4KDVFwu8bqxF07NuN3WHjjx8fL36FHxzZ840T+U3TCsC0AkJha/P3RIbP+BcwqayocEFi8Wb63Jk4GDB63bDh4c7BljRk6OTKpqYgsrm05lLdpGHyXy8sgbbiBdLrG5u1zkhReKjd+X664Tu3ygrTU+nhw6lExMJBMSxBbvdpPDh8tcQEEB2aJFcD+Ph/z8czI7m7zpJtLplGMYBvnEE9JPU/nk55NXXCH/L5tN/rrd5Msvk2lp5n3Gj5fvkfc7YbfLOkDGxcn/eOLEiv0cmiIQwkZf6Yo9cNGKPsrs3EnOn09u2mS+Py2NbNw4/CSbryL/6ivy6FGZyK1fn0xKkh++y0Xee68o82HD/CeMAVEEb71VsZ9fY47V5KpSoRX2m2+StWvLQMDhIM87j+zfnxwyhFy6tORypKWRa9bI90lTJkIpem2j10hR8g0bIm/fuLH47ANSJGLIEHGPO/NM+ZubKzb+wCpXANCmjXUFLU3F0asXsGCB9X7DAL76yt8Ms2iRzMv4muHcbmDgQHG1LAkk8PDDwIsviuNAfj5w++1SUEQH9JUKbaPXhMbryxwp//wj3hXZ2cDWrcBTT0ngS7Nmsj8tzTqnyd69ZZNVEx3CDfAyMiShni9PPx0815KZKSk1Qk3cmzFhghw/M1O+L5mZkp7j6adLdhxNRGhFr5GkU4ETt06ntYtmoJLIzpY6nl5q1waSk837ulyll1NjTU6OlKDcuDGy9jfcIAnuQrFnj/+61bHj4iQIqiSMHWteZMT3e6SJGlrRa4BzzgFef12qU3k8ouT79xc3Obe7ONLV6Sz22PElsLiEUhIla8bhwxIVqYke06dLTpiePYHOnYGuXYFt20L3ueoqoHdv6/TBbjdwySX+2045xbxsX0aGxGeUBKt6CAcPWntzaUqNVvQa4brrZAS3YoX8nTYNuPpqUcqPPipl36wCsZxOsc/7YuZfD4jbplXxc03J+esv8XE/fFhcYTMz5X/Yq1do84zNJoF28+cDF1zgn7bC5QIaNRKbuS+PPWZdn/Xee8Obg3w5/njz7ccdp2305YCuMKUpxm6XEoa+NG8uUbdeFi2SfPjex26bTRJUDR/u3699e7kBZGcHn6dFiygKXcN55ZXga5yfL/MoS5aErjugFHDaaVLhaeFCsZnv2SPBTrffHlyKsn17uSGYFZ/ftk1uMlZPCIG8+KKkIM7MLL5BGAbw8suR9deUCH3r1JSMV16R3OJt2ogdftAgSXTVoIF/O2/xE1/i40XJn3ZahYlb7dmxw3ziOy5OMp2GIidHvK0OH5ZaBbNmSfK7ESPEa8qMwP+zF5crOAVxKM48UzJWXnyxTOL36SNptM87L/JjaCJGK3pNyYiLk8In69dLitr33zf32mncGPj2W3kUdzhEyZ97rowefR//ly4Vs9Cdd0rahNK6++7YIVk3u3cX+3NNMQ9deKH5KDonBzj5ZOt+kyaJXb9LF1He111nPlIP5MEHg8/ndssTgNXkvRXduknJy61bxZUzlLyasmHlYF9Ziw6Yqobs2kXedZcE6MTFkW3bkvPmScZNt1u2KSX7b7ut5MffsKE4iMc3SnPOnOh/lljj6FGydeviCFVvUNuIEdZ9Zs+W6+MbKOVykddeG/58BQXko49K/8RE6TdkiM5YGQNAB0xpKpXBg2Vy19edzuUS74rAotCGIfbiktS0HTgQmDkz2FujSROxHVtNIFYXDh8W+/qnn4pr6/DhQL9+1p/7lFMkx00gLpfY6D0e+V8lJFgfIz1dRuKNG1ubeTQVSqiAKa3oNeXLwYNSKs7MLBAXF6yclRLzwLPPRn6OlJTiSF1fnE5RRpmZYtrp1EkUYSTs3i2KMydH7Mht2kQuT6zTtKlcj0AMQ0w4778v/69GjcSvvX//ipdRU2J0ZKym8ti+3brilNkgw26PLEuiL3XrWh9/0CCZJ7j4YlFcjz4afh7gww+BVq2A++6TicnOnYEnnyyZTLHMaaeZuzDm50vsRFqa1BjYvl0U/7ffVryMmqiiFb0m+hw9KuUFR4wAli0LNs8AomjMlI3dLpOpJeG++8wje1NSxIskK0vMG1lZMkL98EPrYx04UFxQJTNTXBezsoDnnwf+/LNkcsUqo0eLecb3+rvd8nRlFq36xBMVK58m6mhFrxEKCsTz4dFHxSOjpLlLvKxdK77499wjynHoUFEiZp4a48fL9oQEWVwu8a9u27Zk57zlFuCOO6R/rVry98wzxSso0Mc8PR0YN876WF9+aR79m5Eh16U60K6dFPYeOFDMOKedJvUGrJ68SpLwThOTaBu9Rkau554rEZVpaaJ87Xbxa+7WrWTHOvVUmejz/V7Fx4vr3JYtMmI+8URR8t27yw1l7lzJeHnBBeLyV1r+/VeKnDRrJqaHzp3NC540aSJmCTPeflsmM83K5tnt8jQwYEDpZYxVcnIkLuLoUf/tSsn/Zc6cypFLEzGhbPSV7k4ZuGj3ykrgmWeCc8cD4rZXkkIhR/6/vXOPkaq8Avjv7MLsg2VTBKqrCMjDIBoNgtgY0TZpDIkRadBKUQOJtFkCJYSmauIjxvpCgg2JWKJUQoi6tsQItSmIL1DJJtLwEo2URShgEQQLosCyu6d/nJnu3Z3XHea1M5xfcsOdu9/97jlzh3O/e77znXOiM8QxUdHoXLF/v4UCDhhgxU8WLrRCK0Ha2uya3eXo1csKoqiq7tun+t57Fv4Z49ChxIVYgqGLyQpzFIrt2y0PfG2t6sUXm/7t7dn3u2BBfNhlba3q5s3Z9+3kHbzwiJOSUaMSG7WaGtWWlvD9fPddckN/4YW5kfXoUTPglZVdY8CnTo1vu2qVGSoRaxeJqPbvr7prl+rkyZ3Vt6qqzPi3talu2JDa0NfXq771Vm50CcuZM6qPPaba0GCx60HdY8Z49uzsr9PRobp8ueqIEVZI5sYbVZubs+/XKQipDL3nunFSJ5HKJMFUXZ0VBt+4seuy/KoquPfe1OeeOAEff2x93HBD8lWWS5eaeyHY/+nTlhO9vt6ycMZknjLFfNALF8KXX9oy//nzLYJm7Vo7Lxb22dQEw4dbJshEk8dBuqd2yBfHjtmagkWLbFI7USEXMPfUsmU2adq//7lfT8TSF8+Yce59OD2TZE+AYm0+oi8CixYldt2MGpV5X/v2qQ4aZCPP3r1tZHjddandHS+9ZNevr7fzGhpUt25N3HbixOSj7aoqG/mmoq0tsa6xt46KiuT9g70BnD6d+fcS5PhxK7t3+HDyNgsWpJelu1ybNmUnl1PSkK3rBpgIfAHsBh5M8PdGYAewFfgIGB09PhQ4FT2+FVia7lpu6IvAmTPm8+3Tx3zYdXWqF1ygumPHufXX2qr6xhv2AHn33dR+/i1b4v3CYLVoEy2rnzcvuXso5lpJdb1Tp5Ib0JgrJ1nfdXXm029tVW1qUr3vPtVHH1Xduzfc99LRYakJqqtNzqoqczl1f3B88kmnuynsVl2t+tVX4eRwypKsDD1QCbQAw4AIsC1myANt6gP7k4C12mnoP013jeDmhr5IdHSofvihjSRXrlT9/vvCXHfWrHifM9jI/u2349u3tCQuah3bKirSj7ivuirxuZWViR8ikYgVwD5+3L6XsWPN6Mf+VlurunZt6muePKn60EPxbxM1NfH5fVK9tSSbS7nrrsy+d6fsSGXowzhgxwO7VXWPqrYCTcDt3dw/wSoTfQAN5Tdyeg4i5l+//364557wecWz5ZtvEqfZFUkcyz9smMX7J0uJO2RI+nS5S5d2hpBCp0+/vd3CPGP07m0x+bNmme++vh5eeMFCOE+etDatreYjv/tuW4Nw0UXW7o47LJwU4JlnLGz0qafi/eynTll+/+C8wMGDqeWPUVFh6xFmzoQVK8Kd45yfJHsCxDbgDmBZ4PO9wPMJ2s3GRv77gZHaOaL/HtgCbAAmJLnGb4DNwObBgwcX5Onn9BBeeSXxCL26WvXrr5Oft3Fj/Oi4tlZ19epw1/38c9WZM1Wvv161X7/k7pAjR7qed+21yd8Gqqq6vln076+6bFnqN5DYW8GxY53XmDs3/Si+slL1hx/iw0qd8xayHNGHfWAsUdXhwANArCTRf4DBqjoGmA+8KiL1Cc59UVXHqeq4gQMH5kokpxS480645prOQtUiNtp++OHUi6cmTLBqV7fcYqPoCRNsVeukSeGuO2qUpWlobjbTmQjV+OyNyfLwtLd3XYXb0WGLrh55JPHiqyANDV2TrT3xRPJVqt1lyTQHvHNeEia88iBwaeDzoOixZDQBfwJQ1TPAmej+P0WkBbgcG707jrlH3n/fVpy+/rqlMGhshJtvTn/u+PGwbl32MowbB++8E3+8Xz/bgjQ2Wqhjd+MtEv/AOH3aQiSTIWLGesmSrg+Uvn1h506YPNn+TUQ5ZdN08k6YEf0nwEgRuUxEIsBUYE2wgYgEk5PcCvwrenygiFRG94cBI4E9uRDcKSMiEZg+3VIhvPZaOCOfS5591t4ogsa2thaeey5+HcG0aZYjpqbGzqmvt+yZ1dXx/UYiFpufaNRdWQm33WYPuVtvjf/7iBHw6acwZ068DJWVsHx55no65y1pDb2qtgFzgHXA58BfVHWniDwuIrH35DkislNEtmIumunR4zcB26PHVwGNqppiiOM4GbJ/vy2Aamy04iNtbZn3MWYMbNpkbp9LLjE30OrVibNoVlTAn/9so/rFi62gyqFD1kf3SeBIxCZ+6+q6JkqrrbV0wKtXpy+wsngxPPmkuXZEzOW0fr3lFHKckHhSM6d0Wb/e3Bsx/3hdneWe37Ah85z22XL8uGXQXLXK5Ln6apsDGDvWom+eftpq4g4daumbb7qpsPI5ZY9XmHLKj/Z2m4TtXlmqpsbCGOfNK45cZ8/aW0WhHzTOeY9XmHLKj23b4nPNg8Wlr1xZeHli9O7tRt7pcbihd0qTqqr4erMx3NA6Thfc0DulyejRFn/ePc69Tx+bmHUc5/+4oXdKExF4802ritS3r0Wy1NRY6oFp04otneP0KDwfvVO6XHklHDhg8feHD1tY5BVXFFsqx+lxuKF3SptIxEIsHcdJirtuHMdxyhw39I7jOGWOG3rHcZwyxw294zhOmeOG3nEcp8zpcbluROQIsK/YcmTAAOCbtK1KD9ertHC9Sot86DVEVRNWbupxhr7UEJHNyRIJlTKuV2nhepUWhdbLXTeO4zhljht6x3GcMscNffa8WGwB8oTrVVq4XqVFQfVyH73jOE6Z4yN6x3GcMscNveM4Tpnjhj4kIjJRRL4Qkd0i8mCCv88Xkc9EZLuIvCsiQ4ohZ6aE0KtRRHaIyFYR+UhERhdDzkxJp1eg3RQRUREpiRC+EPdrhogcid6vrSIysxhyZkqY+yUiv4z+H9spIq8WWsZzIcT9+mPgXu0Skf/mRRBV9S3NBlQCLcAwIAJsA0Z3a/MzoDa6Pwt4vdhy50iv+sD+JGBtseXOhV7Rdn2BjUAzMK7Ycufofs0Ani+2rHnQaySwBegX/fzjYsudC726tf8t8HI+ZPERfTjGA7tVdY+qtgJNwO3BBqr6vqr+EP3YDAwqsIznQhi9TgQ+9gFKYfY+rV5R/gAsAE4XUrgsCKtXqRFGr18DS1T1WwBVPVxgGc+FTO/Xr4DX8iGIG/pwXALsD3w+ED2WjPuAf+RVotwQSi8RmS0iLcCzwNwCyZYNafUSkWuBS1X174UULEvC/g6nRF2Iq0Tk0sKIlhVh9LocuFxEPhaRZhGZWDDpzp3QdiPq6r0MeC8fgrihzzEicg8wDlhYbFlyhaouUdXhwAPAw8WWJ1tEpAJ4DvhdsWXJA38Dhqrq1cB6YEWR5ckVvTD3zU+xke9LIvKjokqUW6YCq1S1PR+du6EPx0EgODIaFD3WBRH5OfAQMElVzxRItmwIpVeAJqAU6val06svcBXwgYjsBX4CrCmBCdm090tVjwZ+e8uAsQWSLRvC/A4PAGtU9ayqfgnswgx/TyaT/19TyZPbBvDJ2JCTKr2APdirVWxS5cpubcZgEy8jiy1vjvUaGdi/DdhcbLlzoVe39h9QGpOxYe5XQ2D/F0BzseXOkV4TgRXR/QGYS6R/sWXPVq9ou1HAXqILWPOxeXHwEKhqm4jMAdZhM+kvq+pOEXkcM3xrMFdNHfBXEQH4t6pOKprQIQip15zom8pZ4FtgevEkDkdIvUqOkHrNFZFJQBtwDIvC6dGE1GsdcIuIfAa0A79X1aPFkzo9GfwOpwJNGrX6+cBTIDiO45Q57qN3HMcpc9zQO47jlDlu6B3HccocN/SO4zhljht6x3GcMscNveM4Tpnjht5xHKfM+R+h1A3Ad/+2aQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PghbCuR1kmIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fd0c5045-3daa-4b89-ce35-871a8362eef5"
      },
      "source": [
        "plt.imshow(sc.affinity_matrix_)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPVAzSabYSho",
        "colab_type": "text"
      },
      "source": [
        "**Pre proceso Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaN1hhycYXYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cbbc873d-a86e-4c8f-fcb7-b6001e759bcb"
      },
      "source": [
        "data = sio.loadmat(DB)['DB'][0, 0]\n",
        "\n",
        "moons = data['hm']\n",
        "Ck = 2\n",
        "sc = SpectralClustering(n_clusters=Ck, n_neighbors=5, gamma = 500)\n",
        "sc.fit(moons)\n",
        "labels_moons = sc.labels_\n",
        "labels_moonso=labels_moons\n",
        "u=np.unique(labels_moons)\n",
        "plt.scatter(moons[:,0],moons[:,1],c=labels_moons)\n",
        "labels=np.zeros((labels_moons.shape[0],len(np.unique(labels_moons))))\n",
        "for i in u:\n",
        "  labels[np.where(labels_moons==i),i]=1\n",
        "labels_moons=labels\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CapG8uHfl1AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "02d77ed4-1162-4fbd-f3ac-cd6390ee5af3"
      },
      "source": [
        "plt.imshow(sc.affinity_matrix_)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgD-lq02m4Jv",
        "colab_type": "text"
      },
      "source": [
        "**Pre proceso Mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DOwZP-gm7zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "8f6e4e46-8270-45e6-c61d-eaef6feee552"
      },
      "source": [
        "(Xtrain, ytrain),_ = tf.keras.datasets.mnist.load_data()\n",
        "Xtrain = Xtrain/255.0 #obligar a flotante normalizado 0 a 1\n",
        "ytrain = ytrain/1.0\n",
        "ytraino=ytrain\n",
        "plt.imshow(Xtrain[0],cmap='binary')\n",
        "u=np.unique(ytrain)\n",
        "labels=np.zeros((ytrain.shape[0],len(np.unique(ytrain))))\n",
        "for i in u:\n",
        "  labels[np.where(ytrain==i),int(i)]=1\n",
        "ytrain=labels\n",
        "Xtrain = Xtrain.reshape(Xtrain.shape[0],-1)\n",
        "ind = np.argsort(ytraino)\n",
        "Xtrain = Xtrain[ind]\n",
        "ytraino = ytraino[ind]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa_SnbEYohDO",
        "colab_type": "text"
      },
      "source": [
        "**Funcion de costo1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LULopbbhbkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss_itlh( scalex=1, lanbda=0.5, scaley=1):\n",
        "    # @tf.function()  #decorador para operar sobre python, mas lento y poco efectivo en muchos casos\n",
        "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
        "    def custom_kitl(y_true, y_pred):  # ytrue labels, ypred  = Xw\n",
        "        #kernels###############################################\n",
        "        scalar_kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
        "            amplitude=1, length_scale=scalex)\n",
        "        scalar_kernely = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
        "            amplitude=1, length_scale=scaley)\n",
        "        k = scalar_kernel.matrix(y_pred, y_pred)\n",
        "        l = scalar_kernely.matrix(y_true, y_true)\n",
        "        #centralizar#####################################################\n",
        "        N = tf.cast(tf.shape(l)[0], dtype=tf.float32)\n",
        "        # matrix for centered kernel\n",
        "        h = tf.eye(N) - (1.0 / N) * tf.ones([N, 1]) * tf.ones([1, N])\n",
        "        # F inicial ####################################################\n",
        "        trkl = (1.0 / N**2) * \\\n",
        "            tf.linalg.trace(tf.matmul(tf.matmul(k, h), tf.matmul(l, h)))\n",
        "        trkk = (1.0 / N**2) * \\\n",
        "            tf.linalg.trace(tf.matmul(tf.matmul(k, h), tf.matmul(k, h)))\n",
        "        f = -(1 - lanbda) * tf.math.log(trkl+1E-10) + 0.5 * \\\n",
        "            lanbda * tf.math.log(trkk+1E-10)  # funcion de costo\n",
        "        return f\n",
        "    # Return a function\n",
        "    return custom_kitl"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ10n6C9olL0",
        "colab_type": "text"
      },
      "source": [
        "**Funcion de costo2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQM1EqOA5ynA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss_itl( lanbda=0.5, scaley=1):\n",
        "    def norckai(K):\n",
        "        Ke=tf.matmul(K,K,transpose_b=True)\n",
        "        Ke=Ke-tf.math.reduce_min(Ke)\n",
        "        Ke=Ke/tf.math.reduce_max(Ke)\n",
        "        return Ke # tensores\n",
        "\n",
        "    # @tf.function()  #decorador para operar sobre python, mas lento y poco efectivo en muchos casos\n",
        "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
        "    def custom_kitl(y_true, y_pred):  # ytrue labels, ypred  = Xw\n",
        "        #kernels###############################################\n",
        "        #scalar_kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
        "        #    amplitude=1, length_scale=scalex)\n",
        "        scalar_kernely = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
        "            amplitude=1, length_scale=scaley)\n",
        "        k=norckai(y_pred)\n",
        "        ####\n",
        "        l = scalar_kernely.matrix(y_true, y_true)\n",
        "        #centralizar#####################################################\n",
        "        N = tf.cast(tf.shape(l)[0], dtype=tf.float32)\n",
        "        # matrix for centered kernel\n",
        "        h = tf.eye(N) - (1.0 / N) * tf.ones([N, 1]) * tf.ones([1, N])\n",
        "        # F inicial ####################################################\n",
        "        trkl = (1.0 / N**2) * \\\n",
        "            tf.linalg.trace(tf.matmul(tf.matmul(k, h), tf.matmul(l, h)))\n",
        "        trkk = (1.0 / N**2) * \\\n",
        "            tf.linalg.trace(tf.matmul(tf.matmul(k, h), tf.matmul(k, h)))\n",
        "        f = -(1 - lanbda) * tf.math.log(trkl+1E-10) + 0.5 * \\\n",
        "            lanbda * tf.math.log(trkk+1E-10)  # funcion de costo\n",
        "\n",
        "        return f\n",
        "    # Return a function\n",
        "    return custom_kitl"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKkO-1kev6jr",
        "colab_type": "text"
      },
      "source": [
        "**Funcion de costo3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Orx46Ev6ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss_sce():\n",
        "    def custom_cre(y_true, y_pred):  # ytrue labels, ypred  = Xw\n",
        "        f = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "        return f\n",
        "    # Return a function\n",
        "    return custom_cre"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHS-WMGjyJSY",
        "colab_type": "text"
      },
      "source": [
        "**Funcion de costo4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_JFLNj4v_VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss_mse():\n",
        "    def custom_mse(y_true, y_pred):  # ytrue labels, ypred  = Xw\n",
        "        f = tf.keras.losses.MSE(y_true, y_pred)\n",
        "        return f\n",
        "    # Return a function\n",
        "    return custom_mse"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDWw6BWuy0pA",
        "colab_type": "text"
      },
      "source": [
        "**funcion de costo5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29iF58lAy0wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss_kld():\n",
        "    def custom_kld(y_true, y_pred):  # ytrue labels, ypred  = Xw\n",
        "        f=tf.keras.losses.kullback_leibler_divergence(y_true, y_pred)\n",
        "        return f\n",
        "    # Return a function\n",
        "    return custom_kld"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8W872h_orB4",
        "colab_type": "text"
      },
      "source": [
        "**Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW3Fz147hg5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b238e657-7d0f-4acc-9147-56bc5287b1f9"
      },
      "source": [
        "D=150\n",
        "seed=100\n",
        "sigmay=0.05\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lambda_=0.5\n",
        "lk = 0.5\n",
        "bs=64\n",
        "initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=sigmay, kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "output = tf.keras.layers.Dense(Ck, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "tf.keras.utils.plot_model(model)\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/RandomFourierFeatures              "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsKoSV6iPfxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ec678ba6-217b-4f95-8855-7ba1c3e0cd60"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "entrada (InputLayer)         [(None, 28)]              0         \n",
            "_________________________________________________________________\n",
            "rbf_fourier (RandomFourierFe (None, 150)               4351      \n",
            "_________________________________________________________________\n",
            "out (Dense)                  (None, 2)                 302       \n",
            "=================================================================\n",
            "Total params: 4,653\n",
            "Trainable params: 302\n",
            "Non-trainable params: 4,351\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fa2sRlGo5V8",
        "colab_type": "text"
      },
      "source": [
        "**Prueba 1 (fcosto1 y fcosto2 supervisado con ckaitl)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2SPKWnppWtw",
        "colab_type": "text"
      },
      "source": [
        "**Happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efYYo1_mpYzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=3\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumWX_o_kgUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b4eaf18-34a8-4efd-92c2-ab6e3dfc63b0"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/happyp1' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_happy))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(happy.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl(lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(happy)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_happyo)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_happyo,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_happyo,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_happyo,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_happyo,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)\n",
        "\n",
        "              \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 2.1914 - out_loss: 2.4257 - rbf_fourier_loss: 1.9572\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0575 - out_loss: 2.1333 - rbf_fourier_loss: 1.9817\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9789 - out_loss: 1.9748 - rbf_fourier_loss: 1.9830\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8708 - out_loss: 1.7705 - rbf_fourier_loss: 1.9711\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8155 - out_loss: 1.6317 - rbf_fourier_loss: 1.9993\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7599 - out_loss: 1.5287 - rbf_fourier_loss: 1.9910\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7632 - out_loss: 1.5427 - rbf_fourier_loss: 1.9837\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7394 - out_loss: 1.4865 - rbf_fourier_loss: 1.9924\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7398 - out_loss: 1.4890 - rbf_fourier_loss: 1.9905\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7516 - out_loss: 1.5073 - rbf_fourier_loss: 1.9959\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7362 - out_loss: 1.4894 - rbf_fourier_loss: 1.9831\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7185 - out_loss: 1.4715 - rbf_fourier_loss: 1.9655\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7575 - out_loss: 1.5486 - rbf_fourier_loss: 1.9665\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7242 - out_loss: 1.4441 - rbf_fourier_loss: 2.0044\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6787 - out_loss: 1.3867 - rbf_fourier_loss: 1.9706\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6989 - out_loss: 1.3954 - rbf_fourier_loss: 2.0025\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6698 - out_loss: 1.3608 - rbf_fourier_loss: 1.9788\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6626 - out_loss: 1.3596 - rbf_fourier_loss: 1.9656\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6871 - out_loss: 1.3545 - rbf_fourier_loss: 2.0197\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6853 - out_loss: 1.3691 - rbf_fourier_loss: 2.0015\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6877 - out_loss: 1.3750 - rbf_fourier_loss: 2.0004\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6941 - out_loss: 1.3762 - rbf_fourier_loss: 2.0120\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7040 - out_loss: 1.3952 - rbf_fourier_loss: 2.0127\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6532 - out_loss: 1.3492 - rbf_fourier_loss: 1.9572\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6792 - out_loss: 1.3526 - rbf_fourier_loss: 2.0058\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6809 - out_loss: 1.3644 - rbf_fourier_loss: 1.9974\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6666 - out_loss: 1.3489 - rbf_fourier_loss: 1.9843\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6852 - out_loss: 1.3709 - rbf_fourier_loss: 1.9995\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6757 - out_loss: 1.3595 - rbf_fourier_loss: 1.9918\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6744 - out_loss: 1.3565 - rbf_fourier_loss: 1.9924\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6612 - out_loss: 1.3512 - rbf_fourier_loss: 1.9712\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6749 - out_loss: 1.3491 - rbf_fourier_loss: 2.0008\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6894 - out_loss: 1.3663 - rbf_fourier_loss: 2.0124\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6770 - out_loss: 1.3549 - rbf_fourier_loss: 1.9991\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6832 - out_loss: 1.3652 - rbf_fourier_loss: 2.0013\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6677 - out_loss: 1.3633 - rbf_fourier_loss: 1.9722\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6895 - out_loss: 1.3671 - rbf_fourier_loss: 2.0119\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6579 - out_loss: 1.3568 - rbf_fourier_loss: 1.9591\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6602 - out_loss: 1.3545 - rbf_fourier_loss: 1.9660\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6696 - out_loss: 1.3543 - rbf_fourier_loss: 1.9848\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6839 - out_loss: 1.3658 - rbf_fourier_loss: 2.0020\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6785 - out_loss: 1.3529 - rbf_fourier_loss: 2.0042\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6695 - out_loss: 1.3489 - rbf_fourier_loss: 1.9900\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6493 - out_loss: 1.3537 - rbf_fourier_loss: 1.9448\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6704 - out_loss: 1.3606 - rbf_fourier_loss: 1.9802\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6827 - out_loss: 1.3600 - rbf_fourier_loss: 2.0053\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6569 - out_loss: 1.3571 - rbf_fourier_loss: 1.9566\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6544 - out_loss: 1.3508 - rbf_fourier_loss: 1.9580\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6716 - out_loss: 1.3546 - rbf_fourier_loss: 1.9887\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6686 - out_loss: 1.3615 - rbf_fourier_loss: 1.9757\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6720 - out_loss: 1.3538 - rbf_fourier_loss: 1.9901\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6641 - out_loss: 1.3496 - rbf_fourier_loss: 1.9786\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6592 - out_loss: 1.3545 - rbf_fourier_loss: 1.9639\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6720 - out_loss: 1.3524 - rbf_fourier_loss: 1.9916\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6745 - out_loss: 1.3719 - rbf_fourier_loss: 1.9770\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6715 - out_loss: 1.3625 - rbf_fourier_loss: 1.9805\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6684 - out_loss: 1.3604 - rbf_fourier_loss: 1.9763\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6977 - out_loss: 1.3806 - rbf_fourier_loss: 2.0148\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6676 - out_loss: 1.3503 - rbf_fourier_loss: 1.9849\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6617 - out_loss: 1.3659 - rbf_fourier_loss: 1.9575\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6833 - out_loss: 1.3756 - rbf_fourier_loss: 1.9909\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6658 - out_loss: 1.3563 - rbf_fourier_loss: 1.9753\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6534 - out_loss: 1.3529 - rbf_fourier_loss: 1.9539\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6767 - out_loss: 1.3594 - rbf_fourier_loss: 1.9940\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6774 - out_loss: 1.3582 - rbf_fourier_loss: 1.9966\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6987 - out_loss: 1.3995 - rbf_fourier_loss: 1.9979\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6699 - out_loss: 1.3516 - rbf_fourier_loss: 1.9883\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6787 - out_loss: 1.3657 - rbf_fourier_loss: 1.9916\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6630 - out_loss: 1.3492 - rbf_fourier_loss: 1.9769\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6677 - out_loss: 1.3516 - rbf_fourier_loss: 1.9837\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6698 - out_loss: 1.3515 - rbf_fourier_loss: 1.9881\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6952 - out_loss: 1.3947 - rbf_fourier_loss: 1.9957\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6770 - out_loss: 1.3528 - rbf_fourier_loss: 2.0012\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6813 - out_loss: 1.3638 - rbf_fourier_loss: 1.9987\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6595 - out_loss: 1.3653 - rbf_fourier_loss: 1.9538\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6707 - out_loss: 1.3575 - rbf_fourier_loss: 1.9840\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6733 - out_loss: 1.3533 - rbf_fourier_loss: 1.9933\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6719 - out_loss: 1.3578 - rbf_fourier_loss: 1.9859\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6810 - out_loss: 1.3554 - rbf_fourier_loss: 2.0067\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6733 - out_loss: 1.3558 - rbf_fourier_loss: 1.9908\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6760 - out_loss: 1.3580 - rbf_fourier_loss: 1.9940\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6935 - out_loss: 1.3770 - rbf_fourier_loss: 2.0100\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6727 - out_loss: 1.3522 - rbf_fourier_loss: 1.9931\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6818 - out_loss: 1.3543 - rbf_fourier_loss: 2.0093\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6701 - out_loss: 1.3529 - rbf_fourier_loss: 1.9874\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6682 - out_loss: 1.3574 - rbf_fourier_loss: 1.9789\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6929 - out_loss: 1.3695 - rbf_fourier_loss: 2.0164\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6700 - out_loss: 1.3515 - rbf_fourier_loss: 1.9886\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6649 - out_loss: 1.3563 - rbf_fourier_loss: 1.9735\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6684 - out_loss: 1.3557 - rbf_fourier_loss: 1.9811\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6808 - out_loss: 1.3631 - rbf_fourier_loss: 1.9985\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6736 - out_loss: 1.3582 - rbf_fourier_loss: 1.9890\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6632 - out_loss: 1.3505 - rbf_fourier_loss: 1.9758\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6724 - out_loss: 1.3587 - rbf_fourier_loss: 1.9861\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6883 - out_loss: 1.3673 - rbf_fourier_loss: 2.0094\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6797 - out_loss: 1.3699 - rbf_fourier_loss: 1.9894\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6739 - out_loss: 1.3586 - rbf_fourier_loss: 1.9891\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6935 - out_loss: 1.3650 - rbf_fourier_loss: 2.0220\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6742 - out_loss: 1.3715 - rbf_fourier_loss: 1.9770\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6676 - out_loss: 1.3590 - rbf_fourier_loss: 1.9762\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 1.9980 - out_loss: 2.0515 - rbf_fourier_loss: 1.9445\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8073 - out_loss: 1.6803 - rbf_fourier_loss: 1.9343\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8293 - out_loss: 1.7035 - rbf_fourier_loss: 1.9551\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7863 - out_loss: 1.6289 - rbf_fourier_loss: 1.9437\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7943 - out_loss: 1.6236 - rbf_fourier_loss: 1.9649\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7679 - out_loss: 1.5934 - rbf_fourier_loss: 1.9425\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7502 - out_loss: 1.5845 - rbf_fourier_loss: 1.9159\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7460 - out_loss: 1.5356 - rbf_fourier_loss: 1.9565\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7235 - out_loss: 1.5222 - rbf_fourier_loss: 1.9247\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7144 - out_loss: 1.4936 - rbf_fourier_loss: 1.9353\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7170 - out_loss: 1.4982 - rbf_fourier_loss: 1.9359\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7345 - out_loss: 1.5226 - rbf_fourier_loss: 1.9465\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7434 - out_loss: 1.5403 - rbf_fourier_loss: 1.9466\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7170 - out_loss: 1.4993 - rbf_fourier_loss: 1.9347\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7313 - out_loss: 1.5240 - rbf_fourier_loss: 1.9386\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7144 - out_loss: 1.4957 - rbf_fourier_loss: 1.9331\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7090 - out_loss: 1.4965 - rbf_fourier_loss: 1.9215\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7180 - out_loss: 1.4854 - rbf_fourier_loss: 1.9506\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7050 - out_loss: 1.4917 - rbf_fourier_loss: 1.9183\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7295 - out_loss: 1.5255 - rbf_fourier_loss: 1.9336\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7212 - out_loss: 1.5001 - rbf_fourier_loss: 1.9424\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7182 - out_loss: 1.4857 - rbf_fourier_loss: 1.9507\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7056 - out_loss: 1.4844 - rbf_fourier_loss: 1.9267\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7100 - out_loss: 1.4971 - rbf_fourier_loss: 1.9228\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6983 - out_loss: 1.5100 - rbf_fourier_loss: 1.8867\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7322 - out_loss: 1.5247 - rbf_fourier_loss: 1.9396\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7149 - out_loss: 1.5079 - rbf_fourier_loss: 1.9219\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7169 - out_loss: 1.5290 - rbf_fourier_loss: 1.9048\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7235 - out_loss: 1.5133 - rbf_fourier_loss: 1.9337\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7269 - out_loss: 1.5105 - rbf_fourier_loss: 1.9433\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7080 - out_loss: 1.4922 - rbf_fourier_loss: 1.9238\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7120 - out_loss: 1.4964 - rbf_fourier_loss: 1.9277\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7484 - out_loss: 1.5213 - rbf_fourier_loss: 1.9755\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7278 - out_loss: 1.5138 - rbf_fourier_loss: 1.9418\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7158 - out_loss: 1.5074 - rbf_fourier_loss: 1.9241\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7043 - out_loss: 1.4866 - rbf_fourier_loss: 1.9220\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7475 - out_loss: 1.5356 - rbf_fourier_loss: 1.9593\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7185 - out_loss: 1.4965 - rbf_fourier_loss: 1.9405\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7339 - out_loss: 1.5174 - rbf_fourier_loss: 1.9503\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7278 - out_loss: 1.5066 - rbf_fourier_loss: 1.9490\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7183 - out_loss: 1.4973 - rbf_fourier_loss: 1.9392\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7660 - out_loss: 1.5477 - rbf_fourier_loss: 1.9844\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7049 - out_loss: 1.4910 - rbf_fourier_loss: 1.9188\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7045 - out_loss: 1.4890 - rbf_fourier_loss: 1.9201\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7165 - out_loss: 1.4928 - rbf_fourier_loss: 1.9402\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7110 - out_loss: 1.4943 - rbf_fourier_loss: 1.9276\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7250 - out_loss: 1.4981 - rbf_fourier_loss: 1.9519\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7129 - out_loss: 1.4929 - rbf_fourier_loss: 1.9330\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7242 - out_loss: 1.4990 - rbf_fourier_loss: 1.9493\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7120 - out_loss: 1.4892 - rbf_fourier_loss: 1.9347\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7257 - out_loss: 1.5134 - rbf_fourier_loss: 1.9381\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7223 - out_loss: 1.5034 - rbf_fourier_loss: 1.9413\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7198 - out_loss: 1.4876 - rbf_fourier_loss: 1.9519\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7224 - out_loss: 1.5231 - rbf_fourier_loss: 1.9217\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7379 - out_loss: 1.5082 - rbf_fourier_loss: 1.9676\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7007 - out_loss: 1.4899 - rbf_fourier_loss: 1.9115\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7117 - out_loss: 1.5093 - rbf_fourier_loss: 1.9142\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6953 - out_loss: 1.4883 - rbf_fourier_loss: 1.9022\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7635 - out_loss: 1.5528 - rbf_fourier_loss: 1.9743\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7224 - out_loss: 1.4924 - rbf_fourier_loss: 1.9525\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7222 - out_loss: 1.5181 - rbf_fourier_loss: 1.9263\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7163 - out_loss: 1.5010 - rbf_fourier_loss: 1.9317\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7061 - out_loss: 1.4971 - rbf_fourier_loss: 1.9151\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7145 - out_loss: 1.4995 - rbf_fourier_loss: 1.9295\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7175 - out_loss: 1.5188 - rbf_fourier_loss: 1.9162\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7019 - out_loss: 1.4867 - rbf_fourier_loss: 1.9172\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7145 - out_loss: 1.5004 - rbf_fourier_loss: 1.9286\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7017 - out_loss: 1.4902 - rbf_fourier_loss: 1.9132\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7316 - out_loss: 1.5120 - rbf_fourier_loss: 1.9512\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7240 - out_loss: 1.4900 - rbf_fourier_loss: 1.9580\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7079 - out_loss: 1.4908 - rbf_fourier_loss: 1.9251\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7132 - out_loss: 1.4872 - rbf_fourier_loss: 1.9392\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8062 - out_loss: 1.6372 - rbf_fourier_loss: 1.9751\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7196 - out_loss: 1.5124 - rbf_fourier_loss: 1.9267\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7104 - out_loss: 1.4944 - rbf_fourier_loss: 1.9264\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7029 - out_loss: 1.4872 - rbf_fourier_loss: 1.9186\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7600 - out_loss: 1.5152 - rbf_fourier_loss: 2.0048\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6981 - out_loss: 1.4846 - rbf_fourier_loss: 1.9116\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7205 - out_loss: 1.4812 - rbf_fourier_loss: 1.9599\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.7176 - out_loss: 1.4953 - rbf_fourier_loss: 1.9400\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7256 - out_loss: 1.5065 - rbf_fourier_loss: 1.9447\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7223 - out_loss: 1.5114 - rbf_fourier_loss: 1.9332\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7292 - out_loss: 1.4921 - rbf_fourier_loss: 1.9662\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7234 - out_loss: 1.5078 - rbf_fourier_loss: 1.9390\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7148 - out_loss: 1.4950 - rbf_fourier_loss: 1.9346\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7210 - out_loss: 1.4997 - rbf_fourier_loss: 1.9422\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7215 - out_loss: 1.4949 - rbf_fourier_loss: 1.9481\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7211 - out_loss: 1.5029 - rbf_fourier_loss: 1.9393\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7022 - out_loss: 1.4946 - rbf_fourier_loss: 1.9098\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7319 - out_loss: 1.5126 - rbf_fourier_loss: 1.9512\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7379 - out_loss: 1.5266 - rbf_fourier_loss: 1.9492\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7318 - out_loss: 1.5238 - rbf_fourier_loss: 1.9398\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7307 - out_loss: 1.5127 - rbf_fourier_loss: 1.9488\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7258 - out_loss: 1.5355 - rbf_fourier_loss: 1.9160\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7271 - out_loss: 1.5211 - rbf_fourier_loss: 1.9330\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7180 - out_loss: 1.4937 - rbf_fourier_loss: 1.9424\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7090 - out_loss: 1.5001 - rbf_fourier_loss: 1.9180\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7163 - out_loss: 1.5057 - rbf_fourier_loss: 1.9268\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7095 - out_loss: 1.4920 - rbf_fourier_loss: 1.9271\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7239 - out_loss: 1.5192 - rbf_fourier_loss: 1.9286\n",
            "it 1/10\n",
            "acc: 72.55639097744361\n",
            "ari: 69.01583700375393\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 2.3573 - out_loss: 2.3722 - rbf_fourier_loss: 2.3424\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2117 - out_loss: 2.1168 - rbf_fourier_loss: 2.3065\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2091 - out_loss: 2.0520 - rbf_fourier_loss: 2.3662\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1972 - out_loss: 2.0577 - rbf_fourier_loss: 2.3366\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2385 - out_loss: 2.1357 - rbf_fourier_loss: 2.3413\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1965 - out_loss: 2.0385 - rbf_fourier_loss: 2.3545\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2417 - out_loss: 2.1770 - rbf_fourier_loss: 2.3065\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1957 - out_loss: 2.0509 - rbf_fourier_loss: 2.3405\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2027 - out_loss: 2.0878 - rbf_fourier_loss: 2.3175\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1543 - out_loss: 1.9924 - rbf_fourier_loss: 2.3163\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2038 - out_loss: 2.0512 - rbf_fourier_loss: 2.3565\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2104 - out_loss: 2.0818 - rbf_fourier_loss: 2.3391\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1922 - out_loss: 2.0470 - rbf_fourier_loss: 2.3373\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1914 - out_loss: 2.0299 - rbf_fourier_loss: 2.3528\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2034 - out_loss: 2.0050 - rbf_fourier_loss: 2.4018\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2365 - out_loss: 2.1241 - rbf_fourier_loss: 2.3488\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2160 - out_loss: 2.1096 - rbf_fourier_loss: 2.3224\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1863 - out_loss: 2.0315 - rbf_fourier_loss: 2.3411\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2221 - out_loss: 2.0960 - rbf_fourier_loss: 2.3483\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1659 - out_loss: 1.9650 - rbf_fourier_loss: 2.3668\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1692 - out_loss: 2.0092 - rbf_fourier_loss: 2.3292\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1945 - out_loss: 2.0312 - rbf_fourier_loss: 2.3579\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2215 - out_loss: 2.1007 - rbf_fourier_loss: 2.3422\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1557 - out_loss: 1.9949 - rbf_fourier_loss: 2.3164\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1678 - out_loss: 1.9983 - rbf_fourier_loss: 2.3373\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2290 - out_loss: 2.1282 - rbf_fourier_loss: 2.3298\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1774 - out_loss: 2.0051 - rbf_fourier_loss: 2.3498\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1907 - out_loss: 2.0486 - rbf_fourier_loss: 2.3328\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1615 - out_loss: 1.9869 - rbf_fourier_loss: 2.3361\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1498 - out_loss: 1.9951 - rbf_fourier_loss: 2.3044\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2150 - out_loss: 2.0997 - rbf_fourier_loss: 2.3302\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1571 - out_loss: 1.9757 - rbf_fourier_loss: 2.3385\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1632 - out_loss: 1.9716 - rbf_fourier_loss: 2.3548\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1749 - out_loss: 1.9935 - rbf_fourier_loss: 2.3562\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2022 - out_loss: 2.0724 - rbf_fourier_loss: 2.3319\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1804 - out_loss: 2.0123 - rbf_fourier_loss: 2.3484\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1454 - out_loss: 1.9579 - rbf_fourier_loss: 2.3329\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1412 - out_loss: 1.9582 - rbf_fourier_loss: 2.3242\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1554 - out_loss: 1.9118 - rbf_fourier_loss: 2.3989\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1658 - out_loss: 1.9670 - rbf_fourier_loss: 2.3646\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1275 - out_loss: 1.9157 - rbf_fourier_loss: 2.3393\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1919 - out_loss: 2.0188 - rbf_fourier_loss: 2.3651\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1274 - out_loss: 1.9179 - rbf_fourier_loss: 2.3369\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1848 - out_loss: 1.9996 - rbf_fourier_loss: 2.3700\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1136 - out_loss: 1.8739 - rbf_fourier_loss: 2.3533\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0804 - out_loss: 1.8557 - rbf_fourier_loss: 2.3052\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1084 - out_loss: 1.8582 - rbf_fourier_loss: 2.3586\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0632 - out_loss: 1.7383 - rbf_fourier_loss: 2.3880\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9819 - out_loss: 1.6203 - rbf_fourier_loss: 2.3435\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9472 - out_loss: 1.5398 - rbf_fourier_loss: 2.3546\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9606 - out_loss: 1.5485 - rbf_fourier_loss: 2.3727\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9348 - out_loss: 1.5454 - rbf_fourier_loss: 2.3242\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9483 - out_loss: 1.5351 - rbf_fourier_loss: 2.3616\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9264 - out_loss: 1.5068 - rbf_fourier_loss: 2.3460\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9435 - out_loss: 1.5156 - rbf_fourier_loss: 2.3714\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9081 - out_loss: 1.4979 - rbf_fourier_loss: 2.3182\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9272 - out_loss: 1.5191 - rbf_fourier_loss: 2.3352\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9250 - out_loss: 1.4797 - rbf_fourier_loss: 2.3702\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9170 - out_loss: 1.4947 - rbf_fourier_loss: 2.3393\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9209 - out_loss: 1.5045 - rbf_fourier_loss: 2.3372\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9133 - out_loss: 1.4961 - rbf_fourier_loss: 2.3305\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9130 - out_loss: 1.5023 - rbf_fourier_loss: 2.3237\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9376 - out_loss: 1.5203 - rbf_fourier_loss: 2.3549\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9114 - out_loss: 1.4873 - rbf_fourier_loss: 2.3355\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9119 - out_loss: 1.4963 - rbf_fourier_loss: 2.3276\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9195 - out_loss: 1.4875 - rbf_fourier_loss: 2.3516\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9141 - out_loss: 1.5018 - rbf_fourier_loss: 2.3264\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9043 - out_loss: 1.4936 - rbf_fourier_loss: 2.3149\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9182 - out_loss: 1.4971 - rbf_fourier_loss: 2.3393\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9142 - out_loss: 1.5034 - rbf_fourier_loss: 2.3249\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9574 - out_loss: 1.4831 - rbf_fourier_loss: 2.4317\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9229 - out_loss: 1.5045 - rbf_fourier_loss: 2.3414\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9233 - out_loss: 1.4922 - rbf_fourier_loss: 2.3544\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9029 - out_loss: 1.4950 - rbf_fourier_loss: 2.3108\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9300 - out_loss: 1.4959 - rbf_fourier_loss: 2.3641\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9258 - out_loss: 1.5069 - rbf_fourier_loss: 2.3448\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9223 - out_loss: 1.5149 - rbf_fourier_loss: 2.3297\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9302 - out_loss: 1.5312 - rbf_fourier_loss: 2.3291\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8882 - out_loss: 1.4730 - rbf_fourier_loss: 2.3034\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9151 - out_loss: 1.5116 - rbf_fourier_loss: 2.3185\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9261 - out_loss: 1.5170 - rbf_fourier_loss: 2.3352\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9151 - out_loss: 1.5122 - rbf_fourier_loss: 2.3181\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9210 - out_loss: 1.4903 - rbf_fourier_loss: 2.3517\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9370 - out_loss: 1.5225 - rbf_fourier_loss: 2.3515\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9174 - out_loss: 1.4940 - rbf_fourier_loss: 2.3409\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9204 - out_loss: 1.4952 - rbf_fourier_loss: 2.3455\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9073 - out_loss: 1.4960 - rbf_fourier_loss: 2.3185\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9477 - out_loss: 1.5258 - rbf_fourier_loss: 2.3697\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9172 - out_loss: 1.4909 - rbf_fourier_loss: 2.3435\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9238 - out_loss: 1.5136 - rbf_fourier_loss: 2.3339\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9406 - out_loss: 1.5042 - rbf_fourier_loss: 2.3769\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9208 - out_loss: 1.4834 - rbf_fourier_loss: 2.3583\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9183 - out_loss: 1.5038 - rbf_fourier_loss: 2.3328\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9123 - out_loss: 1.4985 - rbf_fourier_loss: 2.3260\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9668 - out_loss: 1.5697 - rbf_fourier_loss: 2.3639\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9311 - out_loss: 1.5129 - rbf_fourier_loss: 2.3493\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9149 - out_loss: 1.4920 - rbf_fourier_loss: 2.3378\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9689 - out_loss: 1.5500 - rbf_fourier_loss: 2.3879\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9184 - out_loss: 1.5113 - rbf_fourier_loss: 2.3254\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9011 - out_loss: 1.4901 - rbf_fourier_loss: 2.3120\n",
            "it 1/10\n",
            "acc: 72.55639097744361\n",
            "ari: 69.01583700375393\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 4.6744 - out_loss: 4.3177 - rbf_fourier_loss: 5.0312\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.2884 - out_loss: 3.5178 - rbf_fourier_loss: 5.0591\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2871 - out_loss: 3.5426 - rbf_fourier_loss: 5.0317\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2154 - out_loss: 3.3829 - rbf_fourier_loss: 5.0478\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1972 - out_loss: 3.3622 - rbf_fourier_loss: 5.0322\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1349 - out_loss: 3.2919 - rbf_fourier_loss: 4.9779\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1827 - out_loss: 3.3111 - rbf_fourier_loss: 5.0543\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2310 - out_loss: 3.4583 - rbf_fourier_loss: 5.0037\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1898 - out_loss: 3.3859 - rbf_fourier_loss: 4.9937\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1699 - out_loss: 3.3345 - rbf_fourier_loss: 5.0053\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1454 - out_loss: 3.3120 - rbf_fourier_loss: 4.9789\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2043 - out_loss: 3.4342 - rbf_fourier_loss: 4.9744\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1512 - out_loss: 3.3004 - rbf_fourier_loss: 5.0020\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1397 - out_loss: 3.2365 - rbf_fourier_loss: 5.0429\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1129 - out_loss: 3.1880 - rbf_fourier_loss: 5.0378\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1010 - out_loss: 3.2517 - rbf_fourier_loss: 4.9503\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2349 - out_loss: 3.4034 - rbf_fourier_loss: 5.0664\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0846 - out_loss: 3.1968 - rbf_fourier_loss: 4.9724\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1124 - out_loss: 3.1582 - rbf_fourier_loss: 5.0665\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1251 - out_loss: 3.2302 - rbf_fourier_loss: 5.0200\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0905 - out_loss: 3.1998 - rbf_fourier_loss: 4.9813\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0976 - out_loss: 3.1537 - rbf_fourier_loss: 5.0414\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1566 - out_loss: 3.2511 - rbf_fourier_loss: 5.0620\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1230 - out_loss: 3.1840 - rbf_fourier_loss: 5.0619\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1944 - out_loss: 3.3634 - rbf_fourier_loss: 5.0254\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0805 - out_loss: 3.1240 - rbf_fourier_loss: 5.0369\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0905 - out_loss: 3.1712 - rbf_fourier_loss: 5.0098\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0977 - out_loss: 3.1319 - rbf_fourier_loss: 5.0635\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4166 - out_loss: 3.7738 - rbf_fourier_loss: 5.0594\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1618 - out_loss: 3.3677 - rbf_fourier_loss: 4.9559\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0805 - out_loss: 3.1632 - rbf_fourier_loss: 4.9979\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1100 - out_loss: 3.1913 - rbf_fourier_loss: 5.0288\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1230 - out_loss: 3.2471 - rbf_fourier_loss: 4.9989\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0434 - out_loss: 3.0793 - rbf_fourier_loss: 5.0076\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0761 - out_loss: 3.1352 - rbf_fourier_loss: 5.0170\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1438 - out_loss: 3.2827 - rbf_fourier_loss: 5.0050\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0675 - out_loss: 3.1347 - rbf_fourier_loss: 5.0003\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0735 - out_loss: 3.1634 - rbf_fourier_loss: 4.9837\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1440 - out_loss: 3.2541 - rbf_fourier_loss: 5.0338\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0695 - out_loss: 3.2221 - rbf_fourier_loss: 4.9169\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0616 - out_loss: 3.0761 - rbf_fourier_loss: 5.0471\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0881 - out_loss: 3.1143 - rbf_fourier_loss: 5.0619\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0853 - out_loss: 3.2360 - rbf_fourier_loss: 4.9347\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0919 - out_loss: 3.2059 - rbf_fourier_loss: 4.9779\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1177 - out_loss: 3.2133 - rbf_fourier_loss: 5.0221\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0940 - out_loss: 3.1553 - rbf_fourier_loss: 5.0327\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0704 - out_loss: 3.1903 - rbf_fourier_loss: 4.9505\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0826 - out_loss: 3.1508 - rbf_fourier_loss: 5.0143\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0899 - out_loss: 3.1283 - rbf_fourier_loss: 5.0515\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0919 - out_loss: 3.1364 - rbf_fourier_loss: 5.0474\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0648 - out_loss: 3.1106 - rbf_fourier_loss: 5.0190\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1777 - out_loss: 3.3102 - rbf_fourier_loss: 5.0452\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0431 - out_loss: 3.0710 - rbf_fourier_loss: 5.0151\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0890 - out_loss: 3.1605 - rbf_fourier_loss: 5.0175\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0936 - out_loss: 3.1823 - rbf_fourier_loss: 5.0048\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0728 - out_loss: 3.1249 - rbf_fourier_loss: 5.0206\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0792 - out_loss: 3.1406 - rbf_fourier_loss: 5.0178\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0707 - out_loss: 3.1332 - rbf_fourier_loss: 5.0081\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0863 - out_loss: 3.2213 - rbf_fourier_loss: 4.9513\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1493 - out_loss: 3.3145 - rbf_fourier_loss: 4.9842\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0610 - out_loss: 3.0835 - rbf_fourier_loss: 5.0385\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0451 - out_loss: 3.0714 - rbf_fourier_loss: 5.0189\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1075 - out_loss: 3.2116 - rbf_fourier_loss: 5.0035\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0896 - out_loss: 3.1876 - rbf_fourier_loss: 4.9917\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0582 - out_loss: 3.0750 - rbf_fourier_loss: 5.0414\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0674 - out_loss: 3.1566 - rbf_fourier_loss: 4.9782\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0864 - out_loss: 3.1391 - rbf_fourier_loss: 5.0337\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1550 - out_loss: 3.2928 - rbf_fourier_loss: 5.0171\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1076 - out_loss: 3.2083 - rbf_fourier_loss: 5.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0630 - out_loss: 3.0868 - rbf_fourier_loss: 5.0392\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0705 - out_loss: 3.1231 - rbf_fourier_loss: 5.0179\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0504 - out_loss: 3.0926 - rbf_fourier_loss: 5.0082\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0787 - out_loss: 3.1396 - rbf_fourier_loss: 5.0178\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0967 - out_loss: 3.2152 - rbf_fourier_loss: 4.9782\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0826 - out_loss: 3.1581 - rbf_fourier_loss: 5.0070\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0689 - out_loss: 3.1584 - rbf_fourier_loss: 4.9794\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0590 - out_loss: 3.0849 - rbf_fourier_loss: 5.0331\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0790 - out_loss: 3.1326 - rbf_fourier_loss: 5.0254\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1025 - out_loss: 3.1752 - rbf_fourier_loss: 5.0297\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0865 - out_loss: 3.1668 - rbf_fourier_loss: 5.0061\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0699 - out_loss: 3.1104 - rbf_fourier_loss: 5.0294\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1437 - out_loss: 3.2446 - rbf_fourier_loss: 5.0428\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0787 - out_loss: 3.1077 - rbf_fourier_loss: 5.0497\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0613 - out_loss: 3.0683 - rbf_fourier_loss: 5.0542\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0490 - out_loss: 3.0420 - rbf_fourier_loss: 5.0560\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1018 - out_loss: 3.1996 - rbf_fourier_loss: 5.0041\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0625 - out_loss: 3.1041 - rbf_fourier_loss: 5.0210\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0850 - out_loss: 3.1338 - rbf_fourier_loss: 5.0362\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0544 - out_loss: 3.0358 - rbf_fourier_loss: 5.0730\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0619 - out_loss: 3.0778 - rbf_fourier_loss: 5.0460\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3378 - out_loss: 3.5860 - rbf_fourier_loss: 5.0896\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3147 - out_loss: 3.6438 - rbf_fourier_loss: 4.9856\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2219 - out_loss: 3.4364 - rbf_fourier_loss: 5.0075\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2619 - out_loss: 3.5033 - rbf_fourier_loss: 5.0205\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1573 - out_loss: 3.3453 - rbf_fourier_loss: 4.9693\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0456 - out_loss: 3.0617 - rbf_fourier_loss: 5.0296\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.0700 - out_loss: 3.1289 - rbf_fourier_loss: 5.0111\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1130 - out_loss: 3.2366 - rbf_fourier_loss: 4.9895\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0829 - out_loss: 3.1565 - rbf_fourier_loss: 5.0093\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.0323 - out_loss: 3.1482 - rbf_fourier_loss: 4.9164\n",
            "it 1/10\n",
            "acc: 61.278195488721806\n",
            "ari: 36.83340664663127\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 0.8215 - out_loss: 0.9779 - rbf_fourier_loss: 0.6650\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7353 - out_loss: 0.8029 - rbf_fourier_loss: 0.6677\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6619 - out_loss: 0.6678 - rbf_fourier_loss: 0.6559\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6647 - out_loss: 0.6651 - rbf_fourier_loss: 0.6642\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6160 - out_loss: 0.5725 - rbf_fourier_loss: 0.6596\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6251 - out_loss: 0.5920 - rbf_fourier_loss: 0.6581\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6179 - out_loss: 0.5683 - rbf_fourier_loss: 0.6674\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6056 - out_loss: 0.5528 - rbf_fourier_loss: 0.6585\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5963 - out_loss: 0.5337 - rbf_fourier_loss: 0.6589\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6080 - out_loss: 0.5535 - rbf_fourier_loss: 0.6625\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6005 - out_loss: 0.5338 - rbf_fourier_loss: 0.6672\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5806 - out_loss: 0.4945 - rbf_fourier_loss: 0.6667\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5827 - out_loss: 0.4952 - rbf_fourier_loss: 0.6701\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5768 - out_loss: 0.4882 - rbf_fourier_loss: 0.6655\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5793 - out_loss: 0.4879 - rbf_fourier_loss: 0.6708\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5459 - out_loss: 0.4456 - rbf_fourier_loss: 0.6462\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5436 - out_loss: 0.4272 - rbf_fourier_loss: 0.6600\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5526 - out_loss: 0.4344 - rbf_fourier_loss: 0.6708\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5465 - out_loss: 0.4289 - rbf_fourier_loss: 0.6641\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5516 - out_loss: 0.4243 - rbf_fourier_loss: 0.6789\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5481 - out_loss: 0.4221 - rbf_fourier_loss: 0.6741\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5461 - out_loss: 0.4272 - rbf_fourier_loss: 0.6650\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5447 - out_loss: 0.4180 - rbf_fourier_loss: 0.6715\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5411 - out_loss: 0.4286 - rbf_fourier_loss: 0.6537\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5402 - out_loss: 0.4162 - rbf_fourier_loss: 0.6643\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5395 - out_loss: 0.4128 - rbf_fourier_loss: 0.6662\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5454 - out_loss: 0.4279 - rbf_fourier_loss: 0.6629\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5340 - out_loss: 0.4017 - rbf_fourier_loss: 0.6663\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5375 - out_loss: 0.4034 - rbf_fourier_loss: 0.6716\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5360 - out_loss: 0.4074 - rbf_fourier_loss: 0.6646\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5364 - out_loss: 0.4129 - rbf_fourier_loss: 0.6598\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5346 - out_loss: 0.4063 - rbf_fourier_loss: 0.6629\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5394 - out_loss: 0.4053 - rbf_fourier_loss: 0.6736\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5377 - out_loss: 0.4044 - rbf_fourier_loss: 0.6710\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5288 - out_loss: 0.3880 - rbf_fourier_loss: 0.6697\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5323 - out_loss: 0.3901 - rbf_fourier_loss: 0.6745\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5299 - out_loss: 0.3884 - rbf_fourier_loss: 0.6714\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5328 - out_loss: 0.3942 - rbf_fourier_loss: 0.6714\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5265 - out_loss: 0.3840 - rbf_fourier_loss: 0.6691\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5261 - out_loss: 0.3860 - rbf_fourier_loss: 0.6661\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5337 - out_loss: 0.3979 - rbf_fourier_loss: 0.6696\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5259 - out_loss: 0.3860 - rbf_fourier_loss: 0.6659\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5204 - out_loss: 0.3846 - rbf_fourier_loss: 0.6563\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5320 - out_loss: 0.3936 - rbf_fourier_loss: 0.6704\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5240 - out_loss: 0.3877 - rbf_fourier_loss: 0.6603\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5229 - out_loss: 0.3856 - rbf_fourier_loss: 0.6601\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5293 - out_loss: 0.3891 - rbf_fourier_loss: 0.6696\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5251 - out_loss: 0.3869 - rbf_fourier_loss: 0.6633\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5346 - out_loss: 0.3932 - rbf_fourier_loss: 0.6760\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5251 - out_loss: 0.3874 - rbf_fourier_loss: 0.6628\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5307 - out_loss: 0.3908 - rbf_fourier_loss: 0.6705\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5236 - out_loss: 0.3843 - rbf_fourier_loss: 0.6629\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5259 - out_loss: 0.3856 - rbf_fourier_loss: 0.6661\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5240 - out_loss: 0.3840 - rbf_fourier_loss: 0.6640\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5285 - out_loss: 0.3904 - rbf_fourier_loss: 0.6666\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5329 - out_loss: 0.3910 - rbf_fourier_loss: 0.6747\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5205 - out_loss: 0.3840 - rbf_fourier_loss: 0.6571\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5251 - out_loss: 0.3849 - rbf_fourier_loss: 0.6653\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5268 - out_loss: 0.3855 - rbf_fourier_loss: 0.6681\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5262 - out_loss: 0.3852 - rbf_fourier_loss: 0.6673\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5301 - out_loss: 0.3878 - rbf_fourier_loss: 0.6724\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5607 - out_loss: 0.4518 - rbf_fourier_loss: 0.6697\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5264 - out_loss: 0.3845 - rbf_fourier_loss: 0.6683\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5240 - out_loss: 0.3847 - rbf_fourier_loss: 0.6634\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5248 - out_loss: 0.3849 - rbf_fourier_loss: 0.6647\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5271 - out_loss: 0.3862 - rbf_fourier_loss: 0.6680\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5248 - out_loss: 0.3843 - rbf_fourier_loss: 0.6653\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5199 - out_loss: 0.3851 - rbf_fourier_loss: 0.6548\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5256 - out_loss: 0.3882 - rbf_fourier_loss: 0.6630\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5224 - out_loss: 0.3854 - rbf_fourier_loss: 0.6594\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5281 - out_loss: 0.3864 - rbf_fourier_loss: 0.6698\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5286 - out_loss: 0.3890 - rbf_fourier_loss: 0.6681\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5334 - out_loss: 0.3997 - rbf_fourier_loss: 0.6671\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5303 - out_loss: 0.3917 - rbf_fourier_loss: 0.6689\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5329 - out_loss: 0.3940 - rbf_fourier_loss: 0.6717\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5233 - out_loss: 0.3857 - rbf_fourier_loss: 0.6610\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5325 - out_loss: 0.3964 - rbf_fourier_loss: 0.6686\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5250 - out_loss: 0.3841 - rbf_fourier_loss: 0.6659\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5254 - out_loss: 0.3874 - rbf_fourier_loss: 0.6635\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5277 - out_loss: 0.3860 - rbf_fourier_loss: 0.6695\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5255 - out_loss: 0.3869 - rbf_fourier_loss: 0.6641\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5262 - out_loss: 0.3882 - rbf_fourier_loss: 0.6641\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5300 - out_loss: 0.3868 - rbf_fourier_loss: 0.6732\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5180 - out_loss: 0.3843 - rbf_fourier_loss: 0.6518\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5274 - out_loss: 0.3904 - rbf_fourier_loss: 0.6645\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5281 - out_loss: 0.3878 - rbf_fourier_loss: 0.6684\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5281 - out_loss: 0.3903 - rbf_fourier_loss: 0.6658\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5368 - out_loss: 0.3955 - rbf_fourier_loss: 0.6781\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5320 - out_loss: 0.3965 - rbf_fourier_loss: 0.6675\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5345 - out_loss: 0.3923 - rbf_fourier_loss: 0.6768\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5333 - out_loss: 0.3914 - rbf_fourier_loss: 0.6753\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5254 - out_loss: 0.3907 - rbf_fourier_loss: 0.6601\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5257 - out_loss: 0.3876 - rbf_fourier_loss: 0.6638\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5277 - out_loss: 0.3872 - rbf_fourier_loss: 0.6681\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5316 - out_loss: 0.3895 - rbf_fourier_loss: 0.6738\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5322 - out_loss: 0.3883 - rbf_fourier_loss: 0.6761\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5270 - out_loss: 0.3897 - rbf_fourier_loss: 0.6642\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5316 - out_loss: 0.3915 - rbf_fourier_loss: 0.6717\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5287 - out_loss: 0.3895 - rbf_fourier_loss: 0.6679\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5237 - out_loss: 0.3848 - rbf_fourier_loss: 0.6627\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 0.8078 - out_loss: 0.9281 - rbf_fourier_loss: 0.6876\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7588 - out_loss: 0.8388 - rbf_fourier_loss: 0.6787\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7346 - out_loss: 0.7973 - rbf_fourier_loss: 0.6719\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7238 - out_loss: 0.7685 - rbf_fourier_loss: 0.6790\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7290 - out_loss: 0.7844 - rbf_fourier_loss: 0.6735\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6894 - out_loss: 0.7073 - rbf_fourier_loss: 0.6715\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6503 - out_loss: 0.6332 - rbf_fourier_loss: 0.6674\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6230 - out_loss: 0.5572 - rbf_fourier_loss: 0.6887\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6150 - out_loss: 0.5634 - rbf_fourier_loss: 0.6665\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6293 - out_loss: 0.5715 - rbf_fourier_loss: 0.6871\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6134 - out_loss: 0.5490 - rbf_fourier_loss: 0.6777\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6031 - out_loss: 0.5283 - rbf_fourier_loss: 0.6779\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6120 - out_loss: 0.5333 - rbf_fourier_loss: 0.6907\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6020 - out_loss: 0.5178 - rbf_fourier_loss: 0.6863\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5967 - out_loss: 0.5126 - rbf_fourier_loss: 0.6807\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5956 - out_loss: 0.5066 - rbf_fourier_loss: 0.6846\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6007 - out_loss: 0.5254 - rbf_fourier_loss: 0.6759\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5905 - out_loss: 0.4962 - rbf_fourier_loss: 0.6848\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5908 - out_loss: 0.4915 - rbf_fourier_loss: 0.6902\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5817 - out_loss: 0.4921 - rbf_fourier_loss: 0.6712\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5891 - out_loss: 0.4933 - rbf_fourier_loss: 0.6849\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5870 - out_loss: 0.4981 - rbf_fourier_loss: 0.6759\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5848 - out_loss: 0.5040 - rbf_fourier_loss: 0.6655\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5844 - out_loss: 0.4910 - rbf_fourier_loss: 0.6779\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5802 - out_loss: 0.4938 - rbf_fourier_loss: 0.6666\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5921 - out_loss: 0.4943 - rbf_fourier_loss: 0.6899\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5969 - out_loss: 0.4960 - rbf_fourier_loss: 0.6977\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5863 - out_loss: 0.4957 - rbf_fourier_loss: 0.6769\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5904 - out_loss: 0.5070 - rbf_fourier_loss: 0.6737\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5949 - out_loss: 0.5019 - rbf_fourier_loss: 0.6879\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5929 - out_loss: 0.5036 - rbf_fourier_loss: 0.6823\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5904 - out_loss: 0.4994 - rbf_fourier_loss: 0.6815\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5926 - out_loss: 0.4988 - rbf_fourier_loss: 0.6864\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5865 - out_loss: 0.4986 - rbf_fourier_loss: 0.6743\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5868 - out_loss: 0.4978 - rbf_fourier_loss: 0.6758\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5915 - out_loss: 0.4987 - rbf_fourier_loss: 0.6842\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5867 - out_loss: 0.4985 - rbf_fourier_loss: 0.6749\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5818 - out_loss: 0.4946 - rbf_fourier_loss: 0.6690\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5843 - out_loss: 0.4972 - rbf_fourier_loss: 0.6714\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5906 - out_loss: 0.5109 - rbf_fourier_loss: 0.6704\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5862 - out_loss: 0.4922 - rbf_fourier_loss: 0.6802\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5903 - out_loss: 0.5053 - rbf_fourier_loss: 0.6754\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5855 - out_loss: 0.4998 - rbf_fourier_loss: 0.6713\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5926 - out_loss: 0.4936 - rbf_fourier_loss: 0.6916\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5942 - out_loss: 0.5000 - rbf_fourier_loss: 0.6884\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5861 - out_loss: 0.4947 - rbf_fourier_loss: 0.6775\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5868 - out_loss: 0.4887 - rbf_fourier_loss: 0.6848\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5858 - out_loss: 0.4939 - rbf_fourier_loss: 0.6777\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5889 - out_loss: 0.4968 - rbf_fourier_loss: 0.6810\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5927 - out_loss: 0.5062 - rbf_fourier_loss: 0.6792\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5875 - out_loss: 0.5028 - rbf_fourier_loss: 0.6723\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5936 - out_loss: 0.5019 - rbf_fourier_loss: 0.6852\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5970 - out_loss: 0.5092 - rbf_fourier_loss: 0.6849\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6213 - out_loss: 0.5594 - rbf_fourier_loss: 0.6833\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5872 - out_loss: 0.4979 - rbf_fourier_loss: 0.6765\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6100 - out_loss: 0.5257 - rbf_fourier_loss: 0.6943\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5942 - out_loss: 0.5152 - rbf_fourier_loss: 0.6733\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5811 - out_loss: 0.4879 - rbf_fourier_loss: 0.6743\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5847 - out_loss: 0.4934 - rbf_fourier_loss: 0.6761\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5862 - out_loss: 0.4994 - rbf_fourier_loss: 0.6729\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5937 - out_loss: 0.4936 - rbf_fourier_loss: 0.6938\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5856 - out_loss: 0.4889 - rbf_fourier_loss: 0.6823\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5950 - out_loss: 0.5068 - rbf_fourier_loss: 0.6833\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5902 - out_loss: 0.5002 - rbf_fourier_loss: 0.6803\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5960 - out_loss: 0.5087 - rbf_fourier_loss: 0.6832\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5934 - out_loss: 0.5115 - rbf_fourier_loss: 0.6752\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5868 - out_loss: 0.4957 - rbf_fourier_loss: 0.6780\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5913 - out_loss: 0.5003 - rbf_fourier_loss: 0.6822\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5923 - out_loss: 0.4978 - rbf_fourier_loss: 0.6868\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5847 - out_loss: 0.4948 - rbf_fourier_loss: 0.6747\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5921 - out_loss: 0.5035 - rbf_fourier_loss: 0.6807\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5848 - out_loss: 0.4919 - rbf_fourier_loss: 0.6777\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5842 - out_loss: 0.4856 - rbf_fourier_loss: 0.6828\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5897 - out_loss: 0.4972 - rbf_fourier_loss: 0.6822\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5909 - out_loss: 0.5000 - rbf_fourier_loss: 0.6818\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5921 - out_loss: 0.5057 - rbf_fourier_loss: 0.6784\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5850 - out_loss: 0.4835 - rbf_fourier_loss: 0.6865\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5940 - out_loss: 0.5043 - rbf_fourier_loss: 0.6838\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5831 - out_loss: 0.4878 - rbf_fourier_loss: 0.6785\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5936 - out_loss: 0.5038 - rbf_fourier_loss: 0.6834\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5988 - out_loss: 0.5125 - rbf_fourier_loss: 0.6852\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5998 - out_loss: 0.5123 - rbf_fourier_loss: 0.6873\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5874 - out_loss: 0.4949 - rbf_fourier_loss: 0.6800\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5827 - out_loss: 0.4935 - rbf_fourier_loss: 0.6719\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5919 - out_loss: 0.5061 - rbf_fourier_loss: 0.6777\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5875 - out_loss: 0.4932 - rbf_fourier_loss: 0.6818\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5856 - out_loss: 0.4982 - rbf_fourier_loss: 0.6730\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5893 - out_loss: 0.4984 - rbf_fourier_loss: 0.6801\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5908 - out_loss: 0.5007 - rbf_fourier_loss: 0.6809\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5854 - out_loss: 0.4851 - rbf_fourier_loss: 0.6857\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5902 - out_loss: 0.5002 - rbf_fourier_loss: 0.6801\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5930 - out_loss: 0.5053 - rbf_fourier_loss: 0.6807\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5925 - out_loss: 0.4994 - rbf_fourier_loss: 0.6857\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5937 - out_loss: 0.5044 - rbf_fourier_loss: 0.6830\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5864 - out_loss: 0.4957 - rbf_fourier_loss: 0.6770\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5885 - out_loss: 0.4923 - rbf_fourier_loss: 0.6847\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5888 - out_loss: 0.4968 - rbf_fourier_loss: 0.6808\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5928 - out_loss: 0.5074 - rbf_fourier_loss: 0.6783\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5878 - out_loss: 0.5003 - rbf_fourier_loss: 0.6753\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5902 - out_loss: 0.4910 - rbf_fourier_loss: 0.6894\n",
            "it 1/10\n",
            "acc: 72.55639097744361\n",
            "ari: 69.01583700375393\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 0.8565 - out_loss: 0.8333 - rbf_fourier_loss: 0.8796\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8327 - out_loss: 0.7920 - rbf_fourier_loss: 0.8735\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7148 - out_loss: 0.5398 - rbf_fourier_loss: 0.8897\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7093 - out_loss: 0.5279 - rbf_fourier_loss: 0.8906\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6973 - out_loss: 0.5143 - rbf_fourier_loss: 0.8802\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6796 - out_loss: 0.4844 - rbf_fourier_loss: 0.8748\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6828 - out_loss: 0.4863 - rbf_fourier_loss: 0.8793\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6927 - out_loss: 0.4867 - rbf_fourier_loss: 0.8986\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6684 - out_loss: 0.4501 - rbf_fourier_loss: 0.8867\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6609 - out_loss: 0.4473 - rbf_fourier_loss: 0.8745\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6540 - out_loss: 0.4450 - rbf_fourier_loss: 0.8630\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6503 - out_loss: 0.4153 - rbf_fourier_loss: 0.8853\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6498 - out_loss: 0.4089 - rbf_fourier_loss: 0.8906\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6579 - out_loss: 0.4426 - rbf_fourier_loss: 0.8731\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6457 - out_loss: 0.3986 - rbf_fourier_loss: 0.8928\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6459 - out_loss: 0.4024 - rbf_fourier_loss: 0.8894\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6572 - out_loss: 0.4219 - rbf_fourier_loss: 0.8926\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6290 - out_loss: 0.3956 - rbf_fourier_loss: 0.8624\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6388 - out_loss: 0.3928 - rbf_fourier_loss: 0.8849\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6394 - out_loss: 0.3936 - rbf_fourier_loss: 0.8853\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6518 - out_loss: 0.4070 - rbf_fourier_loss: 0.8967\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6387 - out_loss: 0.4002 - rbf_fourier_loss: 0.8771\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6340 - out_loss: 0.3894 - rbf_fourier_loss: 0.8786\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6407 - out_loss: 0.4097 - rbf_fourier_loss: 0.8717\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6393 - out_loss: 0.3893 - rbf_fourier_loss: 0.8894\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6367 - out_loss: 0.3906 - rbf_fourier_loss: 0.8828\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6344 - out_loss: 0.3899 - rbf_fourier_loss: 0.8788\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6356 - out_loss: 0.3874 - rbf_fourier_loss: 0.8838\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6433 - out_loss: 0.3885 - rbf_fourier_loss: 0.8982\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6339 - out_loss: 0.3932 - rbf_fourier_loss: 0.8745\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6336 - out_loss: 0.3977 - rbf_fourier_loss: 0.8695\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6388 - out_loss: 0.3919 - rbf_fourier_loss: 0.8858\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6365 - out_loss: 0.3986 - rbf_fourier_loss: 0.8743\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6269 - out_loss: 0.3918 - rbf_fourier_loss: 0.8620\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6545 - out_loss: 0.4099 - rbf_fourier_loss: 0.8992\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6385 - out_loss: 0.3879 - rbf_fourier_loss: 0.8891\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6326 - out_loss: 0.3875 - rbf_fourier_loss: 0.8776\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6289 - out_loss: 0.3950 - rbf_fourier_loss: 0.8629\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6292 - out_loss: 0.3865 - rbf_fourier_loss: 0.8719\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6450 - out_loss: 0.3994 - rbf_fourier_loss: 0.8906\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6377 - out_loss: 0.3937 - rbf_fourier_loss: 0.8817\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6422 - out_loss: 0.3881 - rbf_fourier_loss: 0.8963\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6364 - out_loss: 0.3984 - rbf_fourier_loss: 0.8744\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6359 - out_loss: 0.3873 - rbf_fourier_loss: 0.8844\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6367 - out_loss: 0.3984 - rbf_fourier_loss: 0.8751\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6363 - out_loss: 0.3851 - rbf_fourier_loss: 0.8874\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6304 - out_loss: 0.3961 - rbf_fourier_loss: 0.8646\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6347 - out_loss: 0.3886 - rbf_fourier_loss: 0.8808\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6420 - out_loss: 0.3874 - rbf_fourier_loss: 0.8966\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6370 - out_loss: 0.3920 - rbf_fourier_loss: 0.8820\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6372 - out_loss: 0.3929 - rbf_fourier_loss: 0.8815\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6348 - out_loss: 0.3910 - rbf_fourier_loss: 0.8786\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6344 - out_loss: 0.3944 - rbf_fourier_loss: 0.8743\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6319 - out_loss: 0.3867 - rbf_fourier_loss: 0.8770\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6260 - out_loss: 0.3879 - rbf_fourier_loss: 0.8640\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6348 - out_loss: 0.3908 - rbf_fourier_loss: 0.8787\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6274 - out_loss: 0.3859 - rbf_fourier_loss: 0.8690\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6424 - out_loss: 0.3872 - rbf_fourier_loss: 0.8975\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6299 - out_loss: 0.3852 - rbf_fourier_loss: 0.8746\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6370 - out_loss: 0.4061 - rbf_fourier_loss: 0.8680\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6307 - out_loss: 0.3861 - rbf_fourier_loss: 0.8752\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6320 - out_loss: 0.3852 - rbf_fourier_loss: 0.8789\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6266 - out_loss: 0.3885 - rbf_fourier_loss: 0.8648\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6423 - out_loss: 0.3933 - rbf_fourier_loss: 0.8912\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6357 - out_loss: 0.3875 - rbf_fourier_loss: 0.8838\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6341 - out_loss: 0.3896 - rbf_fourier_loss: 0.8786\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6287 - out_loss: 0.3938 - rbf_fourier_loss: 0.8637\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6330 - out_loss: 0.3955 - rbf_fourier_loss: 0.8705\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6328 - out_loss: 0.3886 - rbf_fourier_loss: 0.8771\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6376 - out_loss: 0.3890 - rbf_fourier_loss: 0.8861\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6360 - out_loss: 0.3880 - rbf_fourier_loss: 0.8841\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6300 - out_loss: 0.3880 - rbf_fourier_loss: 0.8721\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6349 - out_loss: 0.3945 - rbf_fourier_loss: 0.8752\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6306 - out_loss: 0.3929 - rbf_fourier_loss: 0.8684\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6297 - out_loss: 0.3919 - rbf_fourier_loss: 0.8676\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6340 - out_loss: 0.3850 - rbf_fourier_loss: 0.8831\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6392 - out_loss: 0.3839 - rbf_fourier_loss: 0.8944\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6313 - out_loss: 0.3945 - rbf_fourier_loss: 0.8681\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6315 - out_loss: 0.3877 - rbf_fourier_loss: 0.8752\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6330 - out_loss: 0.3939 - rbf_fourier_loss: 0.8721\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6353 - out_loss: 0.3843 - rbf_fourier_loss: 0.8863\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6299 - out_loss: 0.3851 - rbf_fourier_loss: 0.8747\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6351 - out_loss: 0.3898 - rbf_fourier_loss: 0.8804\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6386 - out_loss: 0.3878 - rbf_fourier_loss: 0.8895\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6386 - out_loss: 0.3874 - rbf_fourier_loss: 0.8898\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6350 - out_loss: 0.3836 - rbf_fourier_loss: 0.8863\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6294 - out_loss: 0.3843 - rbf_fourier_loss: 0.8746\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6322 - out_loss: 0.3860 - rbf_fourier_loss: 0.8783\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6271 - out_loss: 0.3956 - rbf_fourier_loss: 0.8585\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6332 - out_loss: 0.3905 - rbf_fourier_loss: 0.8758\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6303 - out_loss: 0.3872 - rbf_fourier_loss: 0.8733\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6355 - out_loss: 0.3895 - rbf_fourier_loss: 0.8816\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6333 - out_loss: 0.3846 - rbf_fourier_loss: 0.8821\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6324 - out_loss: 0.3884 - rbf_fourier_loss: 0.8764\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6294 - out_loss: 0.3876 - rbf_fourier_loss: 0.8713\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6418 - out_loss: 0.3843 - rbf_fourier_loss: 0.8994\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6303 - out_loss: 0.3845 - rbf_fourier_loss: 0.8761\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6253 - out_loss: 0.3850 - rbf_fourier_loss: 0.8657\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6445 - out_loss: 0.3955 - rbf_fourier_loss: 0.8935\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6372 - out_loss: 0.3847 - rbf_fourier_loss: 0.8897\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 2.0321 - out_loss: 1.6665 - rbf_fourier_loss: 2.3978\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8127 - out_loss: 1.2090 - rbf_fourier_loss: 2.4165\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8031 - out_loss: 1.1970 - rbf_fourier_loss: 2.4091\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7835 - out_loss: 1.1759 - rbf_fourier_loss: 2.3912\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7880 - out_loss: 1.1897 - rbf_fourier_loss: 2.3864\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7923 - out_loss: 1.1640 - rbf_fourier_loss: 2.4206\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0483 - out_loss: 1.6700 - rbf_fourier_loss: 2.4266\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7720 - out_loss: 1.1424 - rbf_fourier_loss: 2.4015\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9441 - out_loss: 1.4776 - rbf_fourier_loss: 2.4105\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9654 - out_loss: 1.4983 - rbf_fourier_loss: 2.4325\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8583 - out_loss: 1.3225 - rbf_fourier_loss: 2.3940\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7878 - out_loss: 1.1830 - rbf_fourier_loss: 2.3926\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7758 - out_loss: 1.1418 - rbf_fourier_loss: 2.4097\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7757 - out_loss: 1.1433 - rbf_fourier_loss: 2.4081\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8061 - out_loss: 1.2254 - rbf_fourier_loss: 2.3869\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7692 - out_loss: 1.1383 - rbf_fourier_loss: 2.4001\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7984 - out_loss: 1.1905 - rbf_fourier_loss: 2.4063\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7686 - out_loss: 1.1465 - rbf_fourier_loss: 2.3907\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7643 - out_loss: 1.1465 - rbf_fourier_loss: 2.3822\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8035 - out_loss: 1.1797 - rbf_fourier_loss: 2.4273\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7710 - out_loss: 1.1433 - rbf_fourier_loss: 2.3986\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7832 - out_loss: 1.1792 - rbf_fourier_loss: 2.3871\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7967 - out_loss: 1.1821 - rbf_fourier_loss: 2.4114\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7760 - out_loss: 1.1625 - rbf_fourier_loss: 2.3895\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7756 - out_loss: 1.1661 - rbf_fourier_loss: 2.3851\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7633 - out_loss: 1.1381 - rbf_fourier_loss: 2.3885\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7652 - out_loss: 1.1412 - rbf_fourier_loss: 2.3891\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7916 - out_loss: 1.1730 - rbf_fourier_loss: 2.4102\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7658 - out_loss: 1.1397 - rbf_fourier_loss: 2.3920\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7738 - out_loss: 1.1452 - rbf_fourier_loss: 2.4024\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7800 - out_loss: 1.1485 - rbf_fourier_loss: 2.4115\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7898 - out_loss: 1.1593 - rbf_fourier_loss: 2.4204\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7993 - out_loss: 1.1872 - rbf_fourier_loss: 2.4114\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7893 - out_loss: 1.1711 - rbf_fourier_loss: 2.4075\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7772 - out_loss: 1.1487 - rbf_fourier_loss: 2.4058\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7660 - out_loss: 1.1338 - rbf_fourier_loss: 2.3982\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7926 - out_loss: 1.1894 - rbf_fourier_loss: 2.3958\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7819 - out_loss: 1.1637 - rbf_fourier_loss: 2.4001\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7660 - out_loss: 1.1313 - rbf_fourier_loss: 2.4006\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7957 - out_loss: 1.1859 - rbf_fourier_loss: 2.4055\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7736 - out_loss: 1.1399 - rbf_fourier_loss: 2.4073\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7681 - out_loss: 1.1412 - rbf_fourier_loss: 2.3949\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7668 - out_loss: 1.1571 - rbf_fourier_loss: 2.3765\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8084 - out_loss: 1.2510 - rbf_fourier_loss: 2.3657\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7662 - out_loss: 1.1342 - rbf_fourier_loss: 2.3983\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7746 - out_loss: 1.1356 - rbf_fourier_loss: 2.4136\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7781 - out_loss: 1.1568 - rbf_fourier_loss: 2.3995\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7689 - out_loss: 1.1400 - rbf_fourier_loss: 2.3978\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7758 - out_loss: 1.1459 - rbf_fourier_loss: 2.4057\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7860 - out_loss: 1.1673 - rbf_fourier_loss: 2.4047\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7635 - out_loss: 1.1345 - rbf_fourier_loss: 2.3926\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7767 - out_loss: 1.1448 - rbf_fourier_loss: 2.4085\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7661 - out_loss: 1.1324 - rbf_fourier_loss: 2.3999\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7866 - out_loss: 1.1724 - rbf_fourier_loss: 2.4009\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7739 - out_loss: 1.1471 - rbf_fourier_loss: 2.4007\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7631 - out_loss: 1.1492 - rbf_fourier_loss: 2.3771\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7655 - out_loss: 1.1395 - rbf_fourier_loss: 2.3916\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7657 - out_loss: 1.1472 - rbf_fourier_loss: 2.3843\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7829 - out_loss: 1.1641 - rbf_fourier_loss: 2.4016\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7718 - out_loss: 1.1526 - rbf_fourier_loss: 2.3910\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7562 - out_loss: 1.1395 - rbf_fourier_loss: 2.3729\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7899 - out_loss: 1.1562 - rbf_fourier_loss: 2.4235\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7603 - out_loss: 1.1319 - rbf_fourier_loss: 2.3887\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7696 - out_loss: 1.1300 - rbf_fourier_loss: 2.4093\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7830 - out_loss: 1.1686 - rbf_fourier_loss: 2.3973\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7623 - out_loss: 1.1287 - rbf_fourier_loss: 2.3960\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7782 - out_loss: 1.1496 - rbf_fourier_loss: 2.4068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7743 - out_loss: 1.1401 - rbf_fourier_loss: 2.4086\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7818 - out_loss: 1.1797 - rbf_fourier_loss: 2.3839\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7679 - out_loss: 1.1400 - rbf_fourier_loss: 2.3959\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7712 - out_loss: 1.1397 - rbf_fourier_loss: 2.4027\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7657 - out_loss: 1.1352 - rbf_fourier_loss: 2.3963\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7592 - out_loss: 1.1359 - rbf_fourier_loss: 2.3824\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7627 - out_loss: 1.1341 - rbf_fourier_loss: 2.3913\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7894 - out_loss: 1.1842 - rbf_fourier_loss: 2.3945\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7953 - out_loss: 1.1627 - rbf_fourier_loss: 2.4280\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7934 - out_loss: 1.1631 - rbf_fourier_loss: 2.4237\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7807 - out_loss: 1.1602 - rbf_fourier_loss: 2.4011\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7629 - out_loss: 1.1307 - rbf_fourier_loss: 2.3951\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7940 - out_loss: 1.1921 - rbf_fourier_loss: 2.3959\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7684 - out_loss: 1.1646 - rbf_fourier_loss: 2.3722\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7656 - out_loss: 1.1411 - rbf_fourier_loss: 2.3902\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7679 - out_loss: 1.1450 - rbf_fourier_loss: 2.3908\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7653 - out_loss: 1.1459 - rbf_fourier_loss: 2.3847\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7670 - out_loss: 1.1346 - rbf_fourier_loss: 2.3993\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7737 - out_loss: 1.1651 - rbf_fourier_loss: 2.3822\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7579 - out_loss: 1.1384 - rbf_fourier_loss: 2.3774\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7826 - out_loss: 1.1489 - rbf_fourier_loss: 2.4162\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7709 - out_loss: 1.1409 - rbf_fourier_loss: 2.4009\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7813 - out_loss: 1.1455 - rbf_fourier_loss: 2.4170\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7550 - out_loss: 1.1386 - rbf_fourier_loss: 2.3713\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7619 - out_loss: 1.1490 - rbf_fourier_loss: 2.3748\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7738 - out_loss: 1.1539 - rbf_fourier_loss: 2.3937\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7632 - out_loss: 1.1296 - rbf_fourier_loss: 2.3969\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7793 - out_loss: 1.1510 - rbf_fourier_loss: 2.4077\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7731 - out_loss: 1.1487 - rbf_fourier_loss: 2.3975\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7751 - out_loss: 1.1508 - rbf_fourier_loss: 2.3995\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7620 - out_loss: 1.1458 - rbf_fourier_loss: 2.3783\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7679 - out_loss: 1.1368 - rbf_fourier_loss: 2.3991\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8172 - out_loss: 1.2337 - rbf_fourier_loss: 2.4008\n",
            "it 1/10\n",
            "acc: 44.3609022556391\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 302ms/step - loss: 0.0596 - out_loss: 0.3280 - rbf_fourier_loss: -0.2089\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1187 - out_loss: -0.0315 - rbf_fourier_loss: -0.2060\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1292 - out_loss: -0.0446 - rbf_fourier_loss: -0.2138\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1478 - out_loss: -0.0896 - rbf_fourier_loss: -0.2059\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1559 - out_loss: -0.1036 - rbf_fourier_loss: -0.2083\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1794 - out_loss: -0.1508 - rbf_fourier_loss: -0.2080\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1856 - out_loss: -0.1586 - rbf_fourier_loss: -0.2126\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1704 - out_loss: -0.1281 - rbf_fourier_loss: -0.2128\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1623 - out_loss: -0.1190 - rbf_fourier_loss: -0.2056\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1709 - out_loss: -0.1274 - rbf_fourier_loss: -0.2143\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1759 - out_loss: -0.1448 - rbf_fourier_loss: -0.2070\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1762 - out_loss: -0.1424 - rbf_fourier_loss: -0.2100\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1758 - out_loss: -0.1468 - rbf_fourier_loss: -0.2048\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1866 - out_loss: -0.1667 - rbf_fourier_loss: -0.2065\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1890 - out_loss: -0.1732 - rbf_fourier_loss: -0.2047\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1868 - out_loss: -0.1625 - rbf_fourier_loss: -0.2111\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1940 - out_loss: -0.1769 - rbf_fourier_loss: -0.2110\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1940 - out_loss: -0.1779 - rbf_fourier_loss: -0.2101\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1995 - out_loss: -0.1861 - rbf_fourier_loss: -0.2129\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1850 - out_loss: -0.1578 - rbf_fourier_loss: -0.2122\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1958 - out_loss: -0.1782 - rbf_fourier_loss: -0.2134\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1968 - out_loss: -0.1882 - rbf_fourier_loss: -0.2054\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1923 - out_loss: -0.1747 - rbf_fourier_loss: -0.2098\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1900 - out_loss: -0.1787 - rbf_fourier_loss: -0.2013\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1948 - out_loss: -0.1841 - rbf_fourier_loss: -0.2055\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1967 - out_loss: -0.1873 - rbf_fourier_loss: -0.2062\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1972 - out_loss: -0.1849 - rbf_fourier_loss: -0.2094\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1836 - out_loss: -0.1622 - rbf_fourier_loss: -0.2050\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.2033 - out_loss: -0.1979 - rbf_fourier_loss: -0.2087\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1869 - out_loss: -0.1656 - rbf_fourier_loss: -0.2083\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1923 - out_loss: -0.1764 - rbf_fourier_loss: -0.2082\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1977 - out_loss: -0.1816 - rbf_fourier_loss: -0.2139\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1965 - out_loss: -0.1797 - rbf_fourier_loss: -0.2132\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.2018 - out_loss: -0.1952 - rbf_fourier_loss: -0.2084\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1914 - out_loss: -0.1701 - rbf_fourier_loss: -0.2126\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1936 - out_loss: -0.1765 - rbf_fourier_loss: -0.2106\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1944 - out_loss: -0.1758 - rbf_fourier_loss: -0.2131\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.1990 - out_loss: -0.1860 - rbf_fourier_loss: -0.2121\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.2239 - out_loss: -0.2402 - rbf_fourier_loss: -0.2076\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.2132 - out_loss: -0.2133 - rbf_fourier_loss: -0.2132\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.2389 - out_loss: -0.2668 - rbf_fourier_loss: -0.2110\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.2269 - out_loss: -0.2439 - rbf_fourier_loss: -0.2098\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.2727 - out_loss: -0.3330 - rbf_fourier_loss: -0.2123\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.3181 - out_loss: -0.4211 - rbf_fourier_loss: -0.2151\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.5669 - out_loss: -0.9261 - rbf_fourier_loss: -0.2077\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.1712 - out_loss: -2.1306 - rbf_fourier_loss: -0.2118\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6883 - out_loss: -3.1686 - rbf_fourier_loss: -0.2080\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5563 - out_loss: -2.9047 - rbf_fourier_loss: -0.2078\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5894 - out_loss: -2.9637 - rbf_fourier_loss: -0.2152\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5909 - out_loss: -2.9751 - rbf_fourier_loss: -0.2067\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7139 - out_loss: -3.2188 - rbf_fourier_loss: -0.2090\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.5871 - out_loss: -2.9622 - rbf_fourier_loss: -0.2119\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6930 - out_loss: -3.1756 - rbf_fourier_loss: -0.2103\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3747 - out_loss: -2.5361 - rbf_fourier_loss: -0.2132\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6338 - out_loss: -3.0547 - rbf_fourier_loss: -0.2130\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7025 - out_loss: -3.2030 - rbf_fourier_loss: -0.2020\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6029 - out_loss: -2.9959 - rbf_fourier_loss: -0.2099\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5148 - out_loss: -2.8149 - rbf_fourier_loss: -0.2146\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7479 - out_loss: -3.2811 - rbf_fourier_loss: -0.2147\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6988 - out_loss: -3.1855 - rbf_fourier_loss: -0.2121\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.4733 - out_loss: -2.7356 - rbf_fourier_loss: -0.2110\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7779 - out_loss: -3.3440 - rbf_fourier_loss: -0.2119\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7029 - out_loss: -3.1948 - rbf_fourier_loss: -0.2110\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7065 - out_loss: -3.2042 - rbf_fourier_loss: -0.2087\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7356 - out_loss: -3.2609 - rbf_fourier_loss: -0.2102\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7813 - out_loss: -3.3557 - rbf_fourier_loss: -0.2068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7865 - out_loss: -3.3603 - rbf_fourier_loss: -0.2128\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7363 - out_loss: -3.2603 - rbf_fourier_loss: -0.2123\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7587 - out_loss: -3.3020 - rbf_fourier_loss: -0.2155\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8052 - out_loss: -3.3971 - rbf_fourier_loss: -0.2132\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7051 - out_loss: -3.2040 - rbf_fourier_loss: -0.2061\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7848 - out_loss: -3.3546 - rbf_fourier_loss: -0.2149\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.4917 - out_loss: -2.7700 - rbf_fourier_loss: -0.2134\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3912 - out_loss: -2.5747 - rbf_fourier_loss: -0.2077\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7023 - out_loss: -3.1996 - rbf_fourier_loss: -0.2049\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6572 - out_loss: -3.1103 - rbf_fourier_loss: -0.2042\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7037 - out_loss: -3.1948 - rbf_fourier_loss: -0.2125\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7136 - out_loss: -3.2143 - rbf_fourier_loss: -0.2130\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7761 - out_loss: -3.3443 - rbf_fourier_loss: -0.2080\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.4463 - out_loss: -2.6822 - rbf_fourier_loss: -0.2104\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6577 - out_loss: -3.1004 - rbf_fourier_loss: -0.2150\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7907 - out_loss: -3.3709 - rbf_fourier_loss: -0.2106\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7614 - out_loss: -3.3092 - rbf_fourier_loss: -0.2136\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6408 - out_loss: -3.0705 - rbf_fourier_loss: -0.2112\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6754 - out_loss: -3.1397 - rbf_fourier_loss: -0.2111\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: nan - out_loss: nan - rbf_fourier_loss: -0.2120    \n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8333 - out_loss: -3.4590 - rbf_fourier_loss: -0.2076\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8386 - out_loss: -3.4685 - rbf_fourier_loss: -0.2087\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7782 - out_loss: -3.3460 - rbf_fourier_loss: -0.2105\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8320 - out_loss: -3.4521 - rbf_fourier_loss: -0.2118\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8799 - out_loss: -3.5502 - rbf_fourier_loss: -0.2096\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8562 - out_loss: -3.5092 - rbf_fourier_loss: -0.2032\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7233 - out_loss: -3.2426 - rbf_fourier_loss: -0.2040\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8253 - out_loss: -3.4349 - rbf_fourier_loss: -0.2158\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7442 - out_loss: -3.2737 - rbf_fourier_loss: -0.2147\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3650 - out_loss: -2.5244 - rbf_fourier_loss: -0.2055\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7889 - out_loss: -3.3624 - rbf_fourier_loss: -0.2153\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7254 - out_loss: -3.2370 - rbf_fourier_loss: -0.2137\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.5546 - out_loss: -2.9027 - rbf_fourier_loss: -0.2064\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7108 - out_loss: -3.2164 - rbf_fourier_loss: -0.2053\n",
            "it 1/10\n",
            "acc: 44.3609022556391\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: -0.0517 - out_loss: 0.0400 - rbf_fourier_loss: -0.1433\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0776 - out_loss: -0.0121 - rbf_fourier_loss: -0.1430\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1150 - out_loss: -0.0862 - rbf_fourier_loss: -0.1439\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1235 - out_loss: -0.1034 - rbf_fourier_loss: -0.1436\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1349 - out_loss: -0.1266 - rbf_fourier_loss: -0.1432\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1551 - out_loss: -0.1632 - rbf_fourier_loss: -0.1469\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1370 - out_loss: -0.1291 - rbf_fourier_loss: -0.1449\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1594 - out_loss: -0.1739 - rbf_fourier_loss: -0.1449\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1430 - out_loss: -0.1412 - rbf_fourier_loss: -0.1448\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1620 - out_loss: -0.1810 - rbf_fourier_loss: -0.1429\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1590 - out_loss: -0.1730 - rbf_fourier_loss: -0.1449\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1633 - out_loss: -0.1853 - rbf_fourier_loss: -0.1412\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1539 - out_loss: -0.1622 - rbf_fourier_loss: -0.1457\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1446 - out_loss: -0.1434 - rbf_fourier_loss: -0.1458\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1715 - out_loss: -0.1961 - rbf_fourier_loss: -0.1470\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1637 - out_loss: -0.1830 - rbf_fourier_loss: -0.1445\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.1614 - out_loss: -0.1780 - rbf_fourier_loss: -0.1447\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.3316 - out_loss: -0.5164 - rbf_fourier_loss: -0.1467\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.4301 - out_loss: -2.7144 - rbf_fourier_loss: -0.1459\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.4823 - out_loss: -2.8173 - rbf_fourier_loss: -0.1474\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5389 - out_loss: -2.9326 - rbf_fourier_loss: -0.1452\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6152 - out_loss: -3.0860 - rbf_fourier_loss: -0.1444\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.4436 - out_loss: -2.7393 - rbf_fourier_loss: -0.1479\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8192 - out_loss: -3.4961 - rbf_fourier_loss: -0.1423\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5585 - out_loss: -2.9754 - rbf_fourier_loss: -0.1416\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6496 - out_loss: -3.1541 - rbf_fourier_loss: -0.1450\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7194 - out_loss: -3.2944 - rbf_fourier_loss: -0.1444\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6898 - out_loss: -3.2368 - rbf_fourier_loss: -0.1428\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2997 - out_loss: -2.4555 - rbf_fourier_loss: -0.1439\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7243 - out_loss: -3.3021 - rbf_fourier_loss: -0.1464\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.8533 - out_loss: -3.5596 - rbf_fourier_loss: -0.1470\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5980 - out_loss: -3.0513 - rbf_fourier_loss: -0.1447\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7075 - out_loss: -3.2637 - rbf_fourier_loss: -0.1513\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8550 - out_loss: -3.5654 - rbf_fourier_loss: -0.1446\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8046 - out_loss: -3.4630 - rbf_fourier_loss: -0.1463\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6885 - out_loss: -3.2326 - rbf_fourier_loss: -0.1444\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8097 - out_loss: -3.4763 - rbf_fourier_loss: -0.1430\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6928 - out_loss: -3.2432 - rbf_fourier_loss: -0.1423\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6484 - out_loss: -3.1476 - rbf_fourier_loss: -0.1492\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8562 - out_loss: -3.5693 - rbf_fourier_loss: -0.1430\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7092 - out_loss: -3.2720 - rbf_fourier_loss: -0.1464\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7473 - out_loss: -3.3494 - rbf_fourier_loss: -0.1452\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8401 - out_loss: -3.5357 - rbf_fourier_loss: -0.1445\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7486 - out_loss: -3.3551 - rbf_fourier_loss: -0.1422\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6532 - out_loss: -3.1610 - rbf_fourier_loss: -0.1454\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.5927 - out_loss: -3.0394 - rbf_fourier_loss: -0.1460\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8095 - out_loss: -3.4789 - rbf_fourier_loss: -0.1401\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6587 - out_loss: -3.1722 - rbf_fourier_loss: -0.1451\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8123 - out_loss: -3.4767 - rbf_fourier_loss: -0.1478\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6988 - out_loss: -3.2541 - rbf_fourier_loss: -0.1435\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7376 - out_loss: -3.3306 - rbf_fourier_loss: -0.1445\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8256 - out_loss: -3.5103 - rbf_fourier_loss: -0.1409\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6339 - out_loss: -3.1232 - rbf_fourier_loss: -0.1446\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6080 - out_loss: -3.0751 - rbf_fourier_loss: -0.1410\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7440 - out_loss: -3.3446 - rbf_fourier_loss: -0.1434\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8515 - out_loss: -3.5608 - rbf_fourier_loss: -0.1422\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5301 - out_loss: -2.9123 - rbf_fourier_loss: -0.1479\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6622 - out_loss: -3.1803 - rbf_fourier_loss: -0.1440\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6366 - out_loss: -3.1285 - rbf_fourier_loss: -0.1447\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8550 - out_loss: -3.5675 - rbf_fourier_loss: -0.1426\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7067 - out_loss: -3.2709 - rbf_fourier_loss: -0.1425\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.5363 - out_loss: -2.9286 - rbf_fourier_loss: -0.1441\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7888 - out_loss: -3.4352 - rbf_fourier_loss: -0.1424\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6663 - out_loss: -3.1862 - rbf_fourier_loss: -0.1464\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7949 - out_loss: -3.4479 - rbf_fourier_loss: -0.1420\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7177 - out_loss: -3.2898 - rbf_fourier_loss: -0.1456\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8185 - out_loss: -3.4955 - rbf_fourier_loss: -0.1416\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.9697 - out_loss: -3.7957 - rbf_fourier_loss: -0.1436\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8308 - out_loss: -3.5156 - rbf_fourier_loss: -0.1460\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5785 - out_loss: -3.0127 - rbf_fourier_loss: -0.1443\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6761 - out_loss: -3.2086 - rbf_fourier_loss: -0.1436\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7870 - out_loss: -3.4306 - rbf_fourier_loss: -0.1435\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6553 - out_loss: -3.1658 - rbf_fourier_loss: -0.1449\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6444 - out_loss: -3.1449 - rbf_fourier_loss: -0.1438\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8637 - out_loss: -3.5835 - rbf_fourier_loss: -0.1440\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6912 - out_loss: -3.2380 - rbf_fourier_loss: -0.1445\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8161 - out_loss: -3.4850 - rbf_fourier_loss: -0.1472\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7623 - out_loss: -3.3823 - rbf_fourier_loss: -0.1422\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9412 - out_loss: -3.7374 - rbf_fourier_loss: -0.1449\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.7499 - out_loss: -3.3586 - rbf_fourier_loss: -0.1411\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7555 - out_loss: -3.3655 - rbf_fourier_loss: -0.1456\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6857 - out_loss: -3.2261 - rbf_fourier_loss: -0.1453\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6836 - out_loss: -3.2208 - rbf_fourier_loss: -0.1464\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7709 - out_loss: -3.4014 - rbf_fourier_loss: -0.1404\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7636 - out_loss: -3.3799 - rbf_fourier_loss: -0.1473\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.9067 - out_loss: -3.6708 - rbf_fourier_loss: -0.1427\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8864 - out_loss: -3.6241 - rbf_fourier_loss: -0.1486\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5911 - out_loss: -3.0395 - rbf_fourier_loss: -0.1427\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8788 - out_loss: -3.6135 - rbf_fourier_loss: -0.1441\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9748 - out_loss: -3.8056 - rbf_fourier_loss: -0.1440\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7191 - out_loss: -3.2907 - rbf_fourier_loss: -0.1475\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8367 - out_loss: -3.5303 - rbf_fourier_loss: -0.1430\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8644 - out_loss: -3.5862 - rbf_fourier_loss: -0.1426\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9207 - out_loss: -3.6947 - rbf_fourier_loss: -0.1466\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.6468 - out_loss: -3.1482 - rbf_fourier_loss: -0.1454\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5043 - out_loss: -2.8661 - rbf_fourier_loss: -0.1425\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7635 - out_loss: -3.3812 - rbf_fourier_loss: -0.1457\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8560 - out_loss: -3.5681 - rbf_fourier_loss: -0.1440\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8996 - out_loss: -3.6562 - rbf_fourier_loss: -0.1430\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9392 - out_loss: -3.7353 - rbf_fourier_loss: -0.1431\n",
            "it 1/10\n",
            "acc: 44.3609022556391\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 374ms/step - loss: -0.6737 - out_loss: -1.2045 - rbf_fourier_loss: -0.1430\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.5897 - out_loss: -3.0351 - rbf_fourier_loss: -0.1443\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3922 - out_loss: -2.6462 - rbf_fourier_loss: -0.1382\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7539 - out_loss: -3.3690 - rbf_fourier_loss: -0.1389\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8156 - out_loss: -3.4886 - rbf_fourier_loss: -0.1425\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7117 - out_loss: -3.2840 - rbf_fourier_loss: -0.1395\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7000 - out_loss: -3.2508 - rbf_fourier_loss: -0.1491\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8684 - out_loss: -3.5976 - rbf_fourier_loss: -0.1392\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8158 - out_loss: -3.4950 - rbf_fourier_loss: -0.1365\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7563 - out_loss: -3.3752 - rbf_fourier_loss: -0.1373\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7892 - out_loss: -3.4351 - rbf_fourier_loss: -0.1433\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7886 - out_loss: -3.4324 - rbf_fourier_loss: -0.1448\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7574 - out_loss: -3.3771 - rbf_fourier_loss: -0.1377\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8997 - out_loss: -3.6598 - rbf_fourier_loss: -0.1396\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8792 - out_loss: -3.6169 - rbf_fourier_loss: -0.1415\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7639 - out_loss: -3.3887 - rbf_fourier_loss: -0.1391\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8610 - out_loss: -3.5841 - rbf_fourier_loss: -0.1379\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7905 - out_loss: -3.4420 - rbf_fourier_loss: -0.1390\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7846 - out_loss: -3.4269 - rbf_fourier_loss: -0.1423\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8136 - out_loss: -3.4868 - rbf_fourier_loss: -0.1405\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8467 - out_loss: -3.5498 - rbf_fourier_loss: -0.1436\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8020 - out_loss: -3.4652 - rbf_fourier_loss: -0.1389\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7616 - out_loss: -3.3807 - rbf_fourier_loss: -0.1426\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: -1.8936 - out_loss: -3.6436 - rbf_fourier_loss: -0.1436\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9013 - out_loss: -3.6593 - rbf_fourier_loss: -0.1432\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9123 - out_loss: -3.6840 - rbf_fourier_loss: -0.1405\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8209 - out_loss: -3.5025 - rbf_fourier_loss: -0.1394\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8678 - out_loss: -3.5949 - rbf_fourier_loss: -0.1407\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8132 - out_loss: -3.4902 - rbf_fourier_loss: -0.1362\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8695 - out_loss: -3.5986 - rbf_fourier_loss: -0.1404\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8522 - out_loss: -3.5628 - rbf_fourier_loss: -0.1416\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.8796 - out_loss: -3.6222 - rbf_fourier_loss: -0.1370\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8233 - out_loss: -3.5015 - rbf_fourier_loss: -0.1450\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8141 - out_loss: -3.4851 - rbf_fourier_loss: -0.1430\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8377 - out_loss: -3.5324 - rbf_fourier_loss: -0.1429\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8673 - out_loss: -3.6009 - rbf_fourier_loss: -0.1336\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8314 - out_loss: -3.5243 - rbf_fourier_loss: -0.1384\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8864 - out_loss: -3.6350 - rbf_fourier_loss: -0.1378\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8269 - out_loss: -3.5104 - rbf_fourier_loss: -0.1434\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8051 - out_loss: -3.4627 - rbf_fourier_loss: -0.1474\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8453 - out_loss: -3.5504 - rbf_fourier_loss: -0.1401\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8885 - out_loss: -3.6350 - rbf_fourier_loss: -0.1420\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8132 - out_loss: -3.4878 - rbf_fourier_loss: -0.1386\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9115 - out_loss: -3.6823 - rbf_fourier_loss: -0.1407\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8022 - out_loss: -3.4634 - rbf_fourier_loss: -0.1411\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9112 - out_loss: -3.6826 - rbf_fourier_loss: -0.1399\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8044 - out_loss: -3.4708 - rbf_fourier_loss: -0.1380\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8471 - out_loss: -3.5530 - rbf_fourier_loss: -0.1412\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8113 - out_loss: -3.4833 - rbf_fourier_loss: -0.1393\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8828 - out_loss: -3.6266 - rbf_fourier_loss: -0.1390\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8635 - out_loss: -3.5865 - rbf_fourier_loss: -0.1405\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.9051 - out_loss: -3.6704 - rbf_fourier_loss: -0.1398\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8065 - out_loss: -3.4794 - rbf_fourier_loss: -0.1337\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8851 - out_loss: -3.6266 - rbf_fourier_loss: -0.1437\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8184 - out_loss: -3.4997 - rbf_fourier_loss: -0.1370\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.7920 - out_loss: -3.4426 - rbf_fourier_loss: -0.1413\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8360 - out_loss: -3.5287 - rbf_fourier_loss: -0.1433\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8614 - out_loss: -3.5850 - rbf_fourier_loss: -0.1377\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8450 - out_loss: -3.5422 - rbf_fourier_loss: -0.1478\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8297 - out_loss: -3.5207 - rbf_fourier_loss: -0.1388\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8730 - out_loss: -3.6003 - rbf_fourier_loss: -0.1458\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8644 - out_loss: -3.5821 - rbf_fourier_loss: -0.1466\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8347 - out_loss: -3.5283 - rbf_fourier_loss: -0.1412\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7586 - out_loss: -3.3738 - rbf_fourier_loss: -0.1435\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8451 - out_loss: -3.5477 - rbf_fourier_loss: -0.1425\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8501 - out_loss: -3.5589 - rbf_fourier_loss: -0.1413\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8455 - out_loss: -3.5480 - rbf_fourier_loss: -0.1431\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8835 - out_loss: -3.6353 - rbf_fourier_loss: -0.1318\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8279 - out_loss: -3.5118 - rbf_fourier_loss: -0.1440\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.9056 - out_loss: -3.6722 - rbf_fourier_loss: -0.1389\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9030 - out_loss: -3.6628 - rbf_fourier_loss: -0.1432\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8206 - out_loss: -3.5025 - rbf_fourier_loss: -0.1387\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8691 - out_loss: -3.5965 - rbf_fourier_loss: -0.1416\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8671 - out_loss: -3.5917 - rbf_fourier_loss: -0.1425\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9842 - out_loss: -3.8244 - rbf_fourier_loss: -0.1441\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9221 - out_loss: -3.7005 - rbf_fourier_loss: -0.1437\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8265 - out_loss: -3.5004 - rbf_fourier_loss: -0.1527\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.6123 - out_loss: -3.0812 - rbf_fourier_loss: -0.1434\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.8346 - out_loss: -3.5250 - rbf_fourier_loss: -0.1442\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.5642 - out_loss: -2.9878 - rbf_fourier_loss: -0.1406\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9677 - out_loss: -3.7954 - rbf_fourier_loss: -0.1401\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8191 - out_loss: -3.4972 - rbf_fourier_loss: -0.1410\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8727 - out_loss: -3.6080 - rbf_fourier_loss: -0.1375\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8587 - out_loss: -3.5739 - rbf_fourier_loss: -0.1434\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7968 - out_loss: -3.4541 - rbf_fourier_loss: -0.1396\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8409 - out_loss: -3.5416 - rbf_fourier_loss: -0.1403\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9001 - out_loss: -3.6607 - rbf_fourier_loss: -0.1394\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.9794 - out_loss: -3.8249 - rbf_fourier_loss: -0.1339\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8754 - out_loss: -3.6085 - rbf_fourier_loss: -0.1422\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8240 - out_loss: -3.5043 - rbf_fourier_loss: -0.1437\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8313 - out_loss: -3.5216 - rbf_fourier_loss: -0.1411\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8479 - out_loss: -3.5515 - rbf_fourier_loss: -0.1442\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8336 - out_loss: -3.5228 - rbf_fourier_loss: -0.1444\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8522 - out_loss: -3.5625 - rbf_fourier_loss: -0.1419\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.8459 - out_loss: -3.5475 - rbf_fourier_loss: -0.1442\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8362 - out_loss: -3.5289 - rbf_fourier_loss: -0.1436\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8738 - out_loss: -3.5997 - rbf_fourier_loss: -0.1479\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.8460 - out_loss: -3.5465 - rbf_fourier_loss: -0.1455\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.9191 - out_loss: -3.7007 - rbf_fourier_loss: -0.1374\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.7948 - out_loss: -3.4417 - rbf_fourier_loss: -0.1478\n",
            "it 1/10\n",
            "acc: 44.3609022556391\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: -0.5359 - out_loss: -1.7133 - rbf_fourier_loss: 0.6415\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3365 - out_loss: -3.3100 - rbf_fourier_loss: 0.6371\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.0373 - out_loss: -2.7073 - rbf_fourier_loss: 0.6327\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2445 - out_loss: -3.1247 - rbf_fourier_loss: 0.6357\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2569 - out_loss: -3.1575 - rbf_fourier_loss: 0.6437\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.1190 - out_loss: -2.8738 - rbf_fourier_loss: 0.6358\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2297 - out_loss: -3.0966 - rbf_fourier_loss: 0.6372\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.0811 - out_loss: -2.8012 - rbf_fourier_loss: 0.6391\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2219 - out_loss: -3.0719 - rbf_fourier_loss: 0.6280\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2549 - out_loss: -3.1471 - rbf_fourier_loss: 0.6373\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2513 - out_loss: -3.1339 - rbf_fourier_loss: 0.6313\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2231 - out_loss: -3.0797 - rbf_fourier_loss: 0.6335\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2641 - out_loss: -3.1579 - rbf_fourier_loss: 0.6298\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.3387 - out_loss: -3.3083 - rbf_fourier_loss: 0.6310\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2178 - out_loss: -3.0678 - rbf_fourier_loss: 0.6323\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.2441 - out_loss: -3.1276 - rbf_fourier_loss: 0.6393\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2076 - out_loss: -3.0495 - rbf_fourier_loss: 0.6342\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2653 - out_loss: -3.1699 - rbf_fourier_loss: 0.6393\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2378 - out_loss: -3.1115 - rbf_fourier_loss: 0.6359\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2736 - out_loss: -3.1874 - rbf_fourier_loss: 0.6402\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2240 - out_loss: -3.0848 - rbf_fourier_loss: 0.6367\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2323 - out_loss: -3.1002 - rbf_fourier_loss: 0.6355\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2429 - out_loss: -3.1216 - rbf_fourier_loss: 0.6359\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2780 - out_loss: -3.1850 - rbf_fourier_loss: 0.6289\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.1958 - out_loss: -3.0201 - rbf_fourier_loss: 0.6285\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3015 - out_loss: -3.2381 - rbf_fourier_loss: 0.6351\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2215 - out_loss: -3.0741 - rbf_fourier_loss: 0.6310\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3112 - out_loss: -3.2491 - rbf_fourier_loss: 0.6266\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2386 - out_loss: -3.1122 - rbf_fourier_loss: 0.6350\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2920 - out_loss: -3.2255 - rbf_fourier_loss: 0.6416\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2482 - out_loss: -3.1286 - rbf_fourier_loss: 0.6322\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2696 - out_loss: -3.1787 - rbf_fourier_loss: 0.6395\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2423 - out_loss: -3.1162 - rbf_fourier_loss: 0.6317\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2855 - out_loss: -3.2036 - rbf_fourier_loss: 0.6326\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2261 - out_loss: -3.0846 - rbf_fourier_loss: 0.6325\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2609 - out_loss: -3.1540 - rbf_fourier_loss: 0.6322\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2328 - out_loss: -3.1005 - rbf_fourier_loss: 0.6348\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.3103 - out_loss: -3.2511 - rbf_fourier_loss: 0.6305\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2409 - out_loss: -3.1134 - rbf_fourier_loss: 0.6316\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2887 - out_loss: -3.2094 - rbf_fourier_loss: 0.6320\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2459 - out_loss: -3.1398 - rbf_fourier_loss: 0.6481\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.2490 - out_loss: -3.1362 - rbf_fourier_loss: 0.6382\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2753 - out_loss: -3.1808 - rbf_fourier_loss: 0.6302\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2838 - out_loss: -3.1990 - rbf_fourier_loss: 0.6314\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2508 - out_loss: -3.1370 - rbf_fourier_loss: 0.6354\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2851 - out_loss: -3.2048 - rbf_fourier_loss: 0.6347\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2559 - out_loss: -3.1411 - rbf_fourier_loss: 0.6292\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.3147 - out_loss: -3.2618 - rbf_fourier_loss: 0.6325\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2189 - out_loss: -3.0720 - rbf_fourier_loss: 0.6343\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2769 - out_loss: -3.1938 - rbf_fourier_loss: 0.6399\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2538 - out_loss: -3.1432 - rbf_fourier_loss: 0.6357\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2942 - out_loss: -3.2202 - rbf_fourier_loss: 0.6319\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2376 - out_loss: -3.1137 - rbf_fourier_loss: 0.6385\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2838 - out_loss: -3.2000 - rbf_fourier_loss: 0.6324\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2576 - out_loss: -3.1499 - rbf_fourier_loss: 0.6347\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: -1.2208 - out_loss: -3.0800 - rbf_fourier_loss: 0.6385\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2264 - out_loss: -3.0843 - rbf_fourier_loss: 0.6316\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2915 - out_loss: -3.2164 - rbf_fourier_loss: 0.6335\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2356 - out_loss: -3.1007 - rbf_fourier_loss: 0.6295\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2838 - out_loss: -3.2042 - rbf_fourier_loss: 0.6366\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2961 - out_loss: -3.2244 - rbf_fourier_loss: 0.6321\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3311 - out_loss: -3.2939 - rbf_fourier_loss: 0.6316\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2406 - out_loss: -3.1231 - rbf_fourier_loss: 0.6418\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.3012 - out_loss: -3.2346 - rbf_fourier_loss: 0.6322\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2702 - out_loss: -3.1681 - rbf_fourier_loss: 0.6277\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3095 - out_loss: -3.2482 - rbf_fourier_loss: 0.6292\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2054 - out_loss: -3.0549 - rbf_fourier_loss: 0.6441\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2902 - out_loss: -3.2040 - rbf_fourier_loss: 0.6236\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2409 - out_loss: -3.1109 - rbf_fourier_loss: 0.6292\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.3168 - out_loss: -3.2701 - rbf_fourier_loss: 0.6365\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2309 - out_loss: -3.0939 - rbf_fourier_loss: 0.6322\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3023 - out_loss: -3.2361 - rbf_fourier_loss: 0.6315\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2592 - out_loss: -3.1574 - rbf_fourier_loss: 0.6390\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2667 - out_loss: -3.1748 - rbf_fourier_loss: 0.6415\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2332 - out_loss: -3.1054 - rbf_fourier_loss: 0.6390\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3306 - out_loss: -3.2938 - rbf_fourier_loss: 0.6326\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2663 - out_loss: -3.1703 - rbf_fourier_loss: 0.6377\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2846 - out_loss: -3.2024 - rbf_fourier_loss: 0.6332\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3243 - out_loss: -3.2844 - rbf_fourier_loss: 0.6357\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2345 - out_loss: -3.0991 - rbf_fourier_loss: 0.6300\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3053 - out_loss: -3.2458 - rbf_fourier_loss: 0.6353\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2444 - out_loss: -3.1241 - rbf_fourier_loss: 0.6352\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2621 - out_loss: -3.1577 - rbf_fourier_loss: 0.6336\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2574 - out_loss: -3.1505 - rbf_fourier_loss: 0.6358\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2961 - out_loss: -3.2213 - rbf_fourier_loss: 0.6291\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2982 - out_loss: -3.2336 - rbf_fourier_loss: 0.6372\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2953 - out_loss: -3.2231 - rbf_fourier_loss: 0.6325\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2804 - out_loss: -3.1980 - rbf_fourier_loss: 0.6373\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2500 - out_loss: -3.1362 - rbf_fourier_loss: 0.6362\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -1.2292 - out_loss: -3.0973 - rbf_fourier_loss: 0.6390\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2831 - out_loss: -3.2041 - rbf_fourier_loss: 0.6379\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2677 - out_loss: -3.1613 - rbf_fourier_loss: 0.6259\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2998 - out_loss: -3.2331 - rbf_fourier_loss: 0.6335\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2763 - out_loss: -3.1864 - rbf_fourier_loss: 0.6339\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.3108 - out_loss: -3.2519 - rbf_fourier_loss: 0.6303\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2630 - out_loss: -3.1582 - rbf_fourier_loss: 0.6322\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2958 - out_loss: -3.2260 - rbf_fourier_loss: 0.6344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2410 - out_loss: -3.1093 - rbf_fourier_loss: 0.6274\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2950 - out_loss: -3.2180 - rbf_fourier_loss: 0.6281\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -1.2497 - out_loss: -3.1350 - rbf_fourier_loss: 0.6357\n",
            "it 1/10\n",
            "acc: 44.3609022556391\n",
            "ari: 0.0\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 308ms/step - loss: 2.2201 - out_loss: 2.4132 - rbf_fourier_loss: 2.0271\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0866 - out_loss: 2.1533 - rbf_fourier_loss: 2.0199\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0709 - out_loss: 2.1056 - rbf_fourier_loss: 2.0363\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0974 - out_loss: 2.1582 - rbf_fourier_loss: 2.0366\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9590 - out_loss: 1.9269 - rbf_fourier_loss: 1.9910\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9615 - out_loss: 1.9015 - rbf_fourier_loss: 2.0216\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9391 - out_loss: 1.8406 - rbf_fourier_loss: 2.0376\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9201 - out_loss: 1.8288 - rbf_fourier_loss: 2.0114\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9467 - out_loss: 1.8592 - rbf_fourier_loss: 2.0342\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8933 - out_loss: 1.7645 - rbf_fourier_loss: 2.0222\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9473 - out_loss: 1.8488 - rbf_fourier_loss: 2.0459\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8999 - out_loss: 1.7793 - rbf_fourier_loss: 2.0205\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9180 - out_loss: 1.8202 - rbf_fourier_loss: 2.0158\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9793 - out_loss: 1.9218 - rbf_fourier_loss: 2.0369\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9236 - out_loss: 1.8455 - rbf_fourier_loss: 2.0017\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8821 - out_loss: 1.7452 - rbf_fourier_loss: 2.0190\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9235 - out_loss: 1.8257 - rbf_fourier_loss: 2.0214\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9066 - out_loss: 1.8053 - rbf_fourier_loss: 2.0079\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9316 - out_loss: 1.8189 - rbf_fourier_loss: 2.0442\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9398 - out_loss: 1.8540 - rbf_fourier_loss: 2.0256\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9787 - out_loss: 1.9098 - rbf_fourier_loss: 2.0476\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9273 - out_loss: 1.8326 - rbf_fourier_loss: 2.0220\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9322 - out_loss: 1.8481 - rbf_fourier_loss: 2.0163\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9113 - out_loss: 1.7767 - rbf_fourier_loss: 2.0459\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8968 - out_loss: 1.7485 - rbf_fourier_loss: 2.0451\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8973 - out_loss: 1.7806 - rbf_fourier_loss: 2.0140\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9027 - out_loss: 1.7899 - rbf_fourier_loss: 2.0155\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9503 - out_loss: 1.8651 - rbf_fourier_loss: 2.0356\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9441 - out_loss: 1.8683 - rbf_fourier_loss: 2.0199\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9490 - out_loss: 1.8706 - rbf_fourier_loss: 2.0273\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9126 - out_loss: 1.8049 - rbf_fourier_loss: 2.0202\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8788 - out_loss: 1.7675 - rbf_fourier_loss: 1.9901\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8823 - out_loss: 1.7668 - rbf_fourier_loss: 1.9978\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0197 - out_loss: 1.9788 - rbf_fourier_loss: 2.0606\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8752 - out_loss: 1.7562 - rbf_fourier_loss: 1.9942\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8925 - out_loss: 1.7492 - rbf_fourier_loss: 2.0359\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8857 - out_loss: 1.7372 - rbf_fourier_loss: 2.0342\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9165 - out_loss: 1.8284 - rbf_fourier_loss: 2.0046\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9481 - out_loss: 1.8792 - rbf_fourier_loss: 2.0170\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8824 - out_loss: 1.7567 - rbf_fourier_loss: 2.0080\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8997 - out_loss: 1.7960 - rbf_fourier_loss: 2.0034\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8877 - out_loss: 1.7754 - rbf_fourier_loss: 2.0000\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9406 - out_loss: 1.8308 - rbf_fourier_loss: 2.0504\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9172 - out_loss: 1.7922 - rbf_fourier_loss: 2.0421\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9165 - out_loss: 1.8186 - rbf_fourier_loss: 2.0143\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9146 - out_loss: 1.8117 - rbf_fourier_loss: 2.0176\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9073 - out_loss: 1.7964 - rbf_fourier_loss: 2.0181\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9154 - out_loss: 1.7964 - rbf_fourier_loss: 2.0344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8718 - out_loss: 1.7220 - rbf_fourier_loss: 2.0216\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9461 - out_loss: 1.8422 - rbf_fourier_loss: 2.0501\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9586 - out_loss: 1.9207 - rbf_fourier_loss: 1.9964\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8877 - out_loss: 1.7411 - rbf_fourier_loss: 2.0344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8979 - out_loss: 1.7614 - rbf_fourier_loss: 2.0343\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8936 - out_loss: 1.7750 - rbf_fourier_loss: 2.0123\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8689 - out_loss: 1.7349 - rbf_fourier_loss: 2.0030\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9750 - out_loss: 1.9275 - rbf_fourier_loss: 2.0224\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9264 - out_loss: 1.8179 - rbf_fourier_loss: 2.0348\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8832 - out_loss: 1.7453 - rbf_fourier_loss: 2.0212\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8850 - out_loss: 1.7507 - rbf_fourier_loss: 2.0194\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8982 - out_loss: 1.7891 - rbf_fourier_loss: 2.0074\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9371 - out_loss: 1.8298 - rbf_fourier_loss: 2.0444\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8770 - out_loss: 1.7483 - rbf_fourier_loss: 2.0058\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8989 - out_loss: 1.7772 - rbf_fourier_loss: 2.0207\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8854 - out_loss: 1.7483 - rbf_fourier_loss: 2.0224\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9366 - out_loss: 1.8405 - rbf_fourier_loss: 2.0327\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9117 - out_loss: 1.8026 - rbf_fourier_loss: 2.0208\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9170 - out_loss: 1.7817 - rbf_fourier_loss: 2.0523\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9373 - out_loss: 1.8427 - rbf_fourier_loss: 2.0319\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8784 - out_loss: 1.7461 - rbf_fourier_loss: 2.0107\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9058 - out_loss: 1.7857 - rbf_fourier_loss: 2.0260\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9481 - out_loss: 1.8951 - rbf_fourier_loss: 2.0011\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8877 - out_loss: 1.7824 - rbf_fourier_loss: 1.9930\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9393 - out_loss: 1.8151 - rbf_fourier_loss: 2.0635\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9160 - out_loss: 1.7999 - rbf_fourier_loss: 2.0322\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8973 - out_loss: 1.7741 - rbf_fourier_loss: 2.0205\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9071 - out_loss: 1.7831 - rbf_fourier_loss: 2.0310\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9227 - out_loss: 1.7947 - rbf_fourier_loss: 2.0507\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9047 - out_loss: 1.7808 - rbf_fourier_loss: 2.0286\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8841 - out_loss: 1.7495 - rbf_fourier_loss: 2.0187\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9250 - out_loss: 1.8237 - rbf_fourier_loss: 2.0264\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9262 - out_loss: 1.8176 - rbf_fourier_loss: 2.0348\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9122 - out_loss: 1.8087 - rbf_fourier_loss: 2.0157\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8959 - out_loss: 1.7581 - rbf_fourier_loss: 2.0336\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9208 - out_loss: 1.8088 - rbf_fourier_loss: 2.0329\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9028 - out_loss: 1.7634 - rbf_fourier_loss: 2.0423\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9313 - out_loss: 1.8274 - rbf_fourier_loss: 2.0352\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9666 - out_loss: 1.8981 - rbf_fourier_loss: 2.0351\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9748 - out_loss: 1.9109 - rbf_fourier_loss: 2.0387\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8936 - out_loss: 1.7800 - rbf_fourier_loss: 2.0073\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9108 - out_loss: 1.7975 - rbf_fourier_loss: 2.0241\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9139 - out_loss: 1.8059 - rbf_fourier_loss: 2.0219\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9180 - out_loss: 1.7932 - rbf_fourier_loss: 2.0429\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9148 - out_loss: 1.8123 - rbf_fourier_loss: 2.0174\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8793 - out_loss: 1.7439 - rbf_fourier_loss: 2.0147\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9202 - out_loss: 1.8374 - rbf_fourier_loss: 2.0031\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8826 - out_loss: 1.7557 - rbf_fourier_loss: 2.0095\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9003 - out_loss: 1.7617 - rbf_fourier_loss: 2.0389\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8979 - out_loss: 1.7685 - rbf_fourier_loss: 2.0273\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9221 - out_loss: 1.8058 - rbf_fourier_loss: 2.0384\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9230 - out_loss: 1.8151 - rbf_fourier_loss: 2.0310\n",
            "it 2/10\n",
            "acc: 71.80451127819549\n",
            "ari: 52.64471303204618\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 2.1229 - out_loss: 2.2752 - rbf_fourier_loss: 1.9706\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0092 - out_loss: 2.0007 - rbf_fourier_loss: 2.0177\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1189 - out_loss: 2.2698 - rbf_fourier_loss: 1.9680\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0549 - out_loss: 2.1345 - rbf_fourier_loss: 1.9754\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0095 - out_loss: 2.0038 - rbf_fourier_loss: 2.0151\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9668 - out_loss: 1.9317 - rbf_fourier_loss: 2.0019\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9223 - out_loss: 1.8715 - rbf_fourier_loss: 1.9731\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9322 - out_loss: 1.8650 - rbf_fourier_loss: 1.9994\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9860 - out_loss: 1.9977 - rbf_fourier_loss: 1.9744\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9832 - out_loss: 2.0054 - rbf_fourier_loss: 1.9610\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9263 - out_loss: 1.8455 - rbf_fourier_loss: 2.0071\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8745 - out_loss: 1.7490 - rbf_fourier_loss: 2.0000\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8808 - out_loss: 1.8011 - rbf_fourier_loss: 1.9606\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8870 - out_loss: 1.7714 - rbf_fourier_loss: 2.0026\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8876 - out_loss: 1.7910 - rbf_fourier_loss: 1.9842\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9300 - out_loss: 1.8563 - rbf_fourier_loss: 2.0038\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8685 - out_loss: 1.7468 - rbf_fourier_loss: 1.9901\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9242 - out_loss: 1.8548 - rbf_fourier_loss: 1.9937\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9118 - out_loss: 1.8146 - rbf_fourier_loss: 2.0090\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9082 - out_loss: 1.8205 - rbf_fourier_loss: 1.9958\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9014 - out_loss: 1.7924 - rbf_fourier_loss: 2.0103\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8897 - out_loss: 1.7840 - rbf_fourier_loss: 1.9955\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8795 - out_loss: 1.7424 - rbf_fourier_loss: 2.0166\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9004 - out_loss: 1.8251 - rbf_fourier_loss: 1.9756\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9071 - out_loss: 1.8209 - rbf_fourier_loss: 1.9932\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8905 - out_loss: 1.7906 - rbf_fourier_loss: 1.9903\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9580 - out_loss: 1.9015 - rbf_fourier_loss: 2.0145\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8988 - out_loss: 1.8271 - rbf_fourier_loss: 1.9704\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8645 - out_loss: 1.7588 - rbf_fourier_loss: 1.9701\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8816 - out_loss: 1.7533 - rbf_fourier_loss: 2.0099\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9841 - out_loss: 1.9486 - rbf_fourier_loss: 2.0196\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9101 - out_loss: 1.8377 - rbf_fourier_loss: 1.9824\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9785 - out_loss: 1.9553 - rbf_fourier_loss: 2.0017\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8930 - out_loss: 1.8030 - rbf_fourier_loss: 1.9831\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8961 - out_loss: 1.8197 - rbf_fourier_loss: 1.9725\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8695 - out_loss: 1.7655 - rbf_fourier_loss: 1.9735\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9089 - out_loss: 1.8226 - rbf_fourier_loss: 1.9953\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8957 - out_loss: 1.7884 - rbf_fourier_loss: 2.0031\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9098 - out_loss: 1.8236 - rbf_fourier_loss: 1.9961\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8815 - out_loss: 1.7576 - rbf_fourier_loss: 2.0055\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9093 - out_loss: 1.8267 - rbf_fourier_loss: 1.9919\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9084 - out_loss: 1.8398 - rbf_fourier_loss: 1.9769\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8735 - out_loss: 1.7732 - rbf_fourier_loss: 1.9738\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8940 - out_loss: 1.7780 - rbf_fourier_loss: 2.0100\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9106 - out_loss: 1.8395 - rbf_fourier_loss: 1.9817\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8783 - out_loss: 1.7601 - rbf_fourier_loss: 1.9965\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8838 - out_loss: 1.7570 - rbf_fourier_loss: 2.0105\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9322 - out_loss: 1.8795 - rbf_fourier_loss: 1.9848\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8721 - out_loss: 1.7750 - rbf_fourier_loss: 1.9692\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8948 - out_loss: 1.7747 - rbf_fourier_loss: 2.0149\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8766 - out_loss: 1.7345 - rbf_fourier_loss: 2.0188\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8964 - out_loss: 1.8429 - rbf_fourier_loss: 1.9500\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8981 - out_loss: 1.8289 - rbf_fourier_loss: 1.9673\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9125 - out_loss: 1.8471 - rbf_fourier_loss: 1.9779\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8813 - out_loss: 1.7764 - rbf_fourier_loss: 1.9862\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8920 - out_loss: 1.7452 - rbf_fourier_loss: 2.0389\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8862 - out_loss: 1.7628 - rbf_fourier_loss: 2.0096\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9049 - out_loss: 1.8009 - rbf_fourier_loss: 2.0089\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9149 - out_loss: 1.8419 - rbf_fourier_loss: 1.9879\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9195 - out_loss: 1.8250 - rbf_fourier_loss: 2.0140\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8731 - out_loss: 1.7378 - rbf_fourier_loss: 2.0085\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9187 - out_loss: 1.8577 - rbf_fourier_loss: 1.9796\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8785 - out_loss: 1.7535 - rbf_fourier_loss: 2.0036\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8939 - out_loss: 1.7910 - rbf_fourier_loss: 1.9968\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9000 - out_loss: 1.8045 - rbf_fourier_loss: 1.9956\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9056 - out_loss: 1.8172 - rbf_fourier_loss: 1.9940\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8651 - out_loss: 1.7509 - rbf_fourier_loss: 1.9794\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9378 - out_loss: 1.9253 - rbf_fourier_loss: 1.9503\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8822 - out_loss: 1.7710 - rbf_fourier_loss: 1.9935\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8837 - out_loss: 1.7652 - rbf_fourier_loss: 2.0021\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8991 - out_loss: 1.8019 - rbf_fourier_loss: 1.9963\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8644 - out_loss: 1.7585 - rbf_fourier_loss: 1.9703\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9091 - out_loss: 1.8671 - rbf_fourier_loss: 1.9510\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8878 - out_loss: 1.7807 - rbf_fourier_loss: 1.9949\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8835 - out_loss: 1.7543 - rbf_fourier_loss: 2.0127\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9006 - out_loss: 1.8093 - rbf_fourier_loss: 1.9918\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9007 - out_loss: 1.8154 - rbf_fourier_loss: 1.9859\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8966 - out_loss: 1.7880 - rbf_fourier_loss: 2.0052\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8796 - out_loss: 1.7612 - rbf_fourier_loss: 1.9981\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9325 - out_loss: 1.8584 - rbf_fourier_loss: 2.0066\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8849 - out_loss: 1.7606 - rbf_fourier_loss: 2.0092\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9032 - out_loss: 1.7979 - rbf_fourier_loss: 2.0085\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9077 - out_loss: 1.8320 - rbf_fourier_loss: 1.9835\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8799 - out_loss: 1.7858 - rbf_fourier_loss: 1.9740\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8937 - out_loss: 1.7895 - rbf_fourier_loss: 1.9979\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8990 - out_loss: 1.8274 - rbf_fourier_loss: 1.9706\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8754 - out_loss: 1.7453 - rbf_fourier_loss: 2.0054\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9214 - out_loss: 1.8479 - rbf_fourier_loss: 1.9949\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9088 - out_loss: 1.8047 - rbf_fourier_loss: 2.0129\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9035 - out_loss: 1.7950 - rbf_fourier_loss: 2.0120\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9272 - out_loss: 1.8151 - rbf_fourier_loss: 2.0393\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9020 - out_loss: 1.8153 - rbf_fourier_loss: 1.9888\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8843 - out_loss: 1.7773 - rbf_fourier_loss: 1.9913\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8832 - out_loss: 1.7958 - rbf_fourier_loss: 1.9705\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9535 - out_loss: 1.9198 - rbf_fourier_loss: 1.9873\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8910 - out_loss: 1.7683 - rbf_fourier_loss: 2.0138\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8958 - out_loss: 1.7978 - rbf_fourier_loss: 1.9937\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9077 - out_loss: 1.8054 - rbf_fourier_loss: 2.0100\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8994 - out_loss: 1.7865 - rbf_fourier_loss: 2.0124\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9546 - out_loss: 1.9236 - rbf_fourier_loss: 1.9856\n",
            "it 2/10\n",
            "acc: 71.80451127819549\n",
            "ari: 52.64471303204618\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 2.3859 - out_loss: 2.3974 - rbf_fourier_loss: 2.3745\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2443 - out_loss: 2.1345 - rbf_fourier_loss: 2.3541\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2458 - out_loss: 2.1541 - rbf_fourier_loss: 2.3374\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2410 - out_loss: 2.1327 - rbf_fourier_loss: 2.3492\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2113 - out_loss: 2.0454 - rbf_fourier_loss: 2.3772\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2320 - out_loss: 2.1223 - rbf_fourier_loss: 2.3416\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2116 - out_loss: 2.0264 - rbf_fourier_loss: 2.3968\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1974 - out_loss: 2.0853 - rbf_fourier_loss: 2.3095\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2207 - out_loss: 2.0924 - rbf_fourier_loss: 2.3489\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2077 - out_loss: 2.0716 - rbf_fourier_loss: 2.3439\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1891 - out_loss: 1.9851 - rbf_fourier_loss: 2.3931\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2042 - out_loss: 2.0505 - rbf_fourier_loss: 2.3578\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1612 - out_loss: 1.9744 - rbf_fourier_loss: 2.3481\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2025 - out_loss: 2.0469 - rbf_fourier_loss: 2.3581\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2268 - out_loss: 2.0782 - rbf_fourier_loss: 2.3754\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1899 - out_loss: 1.9603 - rbf_fourier_loss: 2.4195\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2688 - out_loss: 2.1429 - rbf_fourier_loss: 2.3947\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2002 - out_loss: 2.0171 - rbf_fourier_loss: 2.3832\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1983 - out_loss: 2.0452 - rbf_fourier_loss: 2.3513\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1891 - out_loss: 2.0354 - rbf_fourier_loss: 2.3429\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2121 - out_loss: 2.0944 - rbf_fourier_loss: 2.3298\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1832 - out_loss: 2.0061 - rbf_fourier_loss: 2.3602\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1945 - out_loss: 2.0361 - rbf_fourier_loss: 2.3530\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1817 - out_loss: 1.9748 - rbf_fourier_loss: 2.3887\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1907 - out_loss: 2.0381 - rbf_fourier_loss: 2.3434\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1928 - out_loss: 2.0575 - rbf_fourier_loss: 2.3281\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2198 - out_loss: 2.0493 - rbf_fourier_loss: 2.3903\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1908 - out_loss: 2.0073 - rbf_fourier_loss: 2.3744\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1870 - out_loss: 2.0577 - rbf_fourier_loss: 2.3163\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1878 - out_loss: 2.0209 - rbf_fourier_loss: 2.3548\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1822 - out_loss: 2.0239 - rbf_fourier_loss: 2.3405\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1884 - out_loss: 2.0593 - rbf_fourier_loss: 2.3176\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2219 - out_loss: 2.0731 - rbf_fourier_loss: 2.3707\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1959 - out_loss: 2.0775 - rbf_fourier_loss: 2.3143\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1940 - out_loss: 2.0221 - rbf_fourier_loss: 2.3660\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1465 - out_loss: 1.9042 - rbf_fourier_loss: 2.3887\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1815 - out_loss: 1.9843 - rbf_fourier_loss: 2.3788\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1664 - out_loss: 1.9560 - rbf_fourier_loss: 2.3768\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1776 - out_loss: 1.9750 - rbf_fourier_loss: 2.3803\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1947 - out_loss: 2.0484 - rbf_fourier_loss: 2.3410\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1275 - out_loss: 1.8623 - rbf_fourier_loss: 2.3926\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1963 - out_loss: 2.0306 - rbf_fourier_loss: 2.3621\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1607 - out_loss: 1.9515 - rbf_fourier_loss: 2.3699\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1183 - out_loss: 1.8560 - rbf_fourier_loss: 2.3806\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1714 - out_loss: 1.9935 - rbf_fourier_loss: 2.3492\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1457 - out_loss: 1.9188 - rbf_fourier_loss: 2.3726\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1644 - out_loss: 1.9621 - rbf_fourier_loss: 2.3668\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1758 - out_loss: 1.9635 - rbf_fourier_loss: 2.3881\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1979 - out_loss: 2.0200 - rbf_fourier_loss: 2.3758\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1360 - out_loss: 1.8849 - rbf_fourier_loss: 2.3872\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1154 - out_loss: 1.8411 - rbf_fourier_loss: 2.3897\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1077 - out_loss: 1.8615 - rbf_fourier_loss: 2.3539\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0587 - out_loss: 1.7715 - rbf_fourier_loss: 2.3459\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0055 - out_loss: 1.6578 - rbf_fourier_loss: 2.3532\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0063 - out_loss: 1.6189 - rbf_fourier_loss: 2.3937\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9869 - out_loss: 1.6043 - rbf_fourier_loss: 2.3695\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9538 - out_loss: 1.5581 - rbf_fourier_loss: 2.3496\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9541 - out_loss: 1.5360 - rbf_fourier_loss: 2.3722\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9638 - out_loss: 1.5612 - rbf_fourier_loss: 2.3664\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9345 - out_loss: 1.5438 - rbf_fourier_loss: 2.3252\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9701 - out_loss: 1.5896 - rbf_fourier_loss: 2.3507\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9614 - out_loss: 1.5441 - rbf_fourier_loss: 2.3786\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9319 - out_loss: 1.5060 - rbf_fourier_loss: 2.3577\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9602 - out_loss: 1.5353 - rbf_fourier_loss: 2.3852\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9248 - out_loss: 1.5125 - rbf_fourier_loss: 2.3371\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9354 - out_loss: 1.5135 - rbf_fourier_loss: 2.3573\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9346 - out_loss: 1.5044 - rbf_fourier_loss: 2.3647\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9742 - out_loss: 1.5440 - rbf_fourier_loss: 2.4044\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9351 - out_loss: 1.5214 - rbf_fourier_loss: 2.3488\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9226 - out_loss: 1.5045 - rbf_fourier_loss: 2.3408\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9596 - out_loss: 1.5368 - rbf_fourier_loss: 2.3823\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9681 - out_loss: 1.5530 - rbf_fourier_loss: 2.3833\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9224 - out_loss: 1.5047 - rbf_fourier_loss: 2.3401\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9305 - out_loss: 1.5126 - rbf_fourier_loss: 2.3484\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9354 - out_loss: 1.5123 - rbf_fourier_loss: 2.3585\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9632 - out_loss: 1.5558 - rbf_fourier_loss: 2.3706\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9250 - out_loss: 1.4913 - rbf_fourier_loss: 2.3587\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9118 - out_loss: 1.4953 - rbf_fourier_loss: 2.3283\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9421 - out_loss: 1.5313 - rbf_fourier_loss: 2.3528\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9176 - out_loss: 1.4999 - rbf_fourier_loss: 2.3353\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9543 - out_loss: 1.5126 - rbf_fourier_loss: 2.3960\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9265 - out_loss: 1.5052 - rbf_fourier_loss: 2.3478\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9474 - out_loss: 1.5051 - rbf_fourier_loss: 2.3896\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9293 - out_loss: 1.5062 - rbf_fourier_loss: 2.3523\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9347 - out_loss: 1.5095 - rbf_fourier_loss: 2.3598\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9380 - out_loss: 1.5089 - rbf_fourier_loss: 2.3672\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9243 - out_loss: 1.5078 - rbf_fourier_loss: 2.3409\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9200 - out_loss: 1.4998 - rbf_fourier_loss: 2.3402\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9326 - out_loss: 1.4928 - rbf_fourier_loss: 2.3724\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9444 - out_loss: 1.5175 - rbf_fourier_loss: 2.3712\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9174 - out_loss: 1.5001 - rbf_fourier_loss: 2.3346\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8921 - out_loss: 1.4909 - rbf_fourier_loss: 2.2933\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9113 - out_loss: 1.5130 - rbf_fourier_loss: 2.3096\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9221 - out_loss: 1.4933 - rbf_fourier_loss: 2.3510\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9176 - out_loss: 1.5005 - rbf_fourier_loss: 2.3348\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9341 - out_loss: 1.5063 - rbf_fourier_loss: 2.3619\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9219 - out_loss: 1.4890 - rbf_fourier_loss: 2.3547\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9213 - out_loss: 1.4921 - rbf_fourier_loss: 2.3505\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9094 - out_loss: 1.5088 - rbf_fourier_loss: 2.3100\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9385 - out_loss: 1.4978 - rbf_fourier_loss: 2.3792\n",
            "it 2/10\n",
            "acc: 72.55639097744361\n",
            "ari: 69.01583700375393\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 9.2260 - out_loss: 13.2532 - rbf_fourier_loss: 5.1988\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.5980 - out_loss: 3.9748 - rbf_fourier_loss: 5.2211\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.5841 - out_loss: 3.9160 - rbf_fourier_loss: 5.2521\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.4957 - out_loss: 3.7524 - rbf_fourier_loss: 5.2391\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3637 - out_loss: 3.4942 - rbf_fourier_loss: 5.2332\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.5998 - out_loss: 4.0128 - rbf_fourier_loss: 5.1868\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3263 - out_loss: 3.4417 - rbf_fourier_loss: 5.2110\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3716 - out_loss: 3.5533 - rbf_fourier_loss: 5.1899\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.4706 - out_loss: 3.7537 - rbf_fourier_loss: 5.1876\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3192 - out_loss: 3.3912 - rbf_fourier_loss: 5.2472\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3681 - out_loss: 3.5215 - rbf_fourier_loss: 5.2147\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3036 - out_loss: 3.3816 - rbf_fourier_loss: 5.2256\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3018 - out_loss: 3.4524 - rbf_fourier_loss: 5.1512\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3018 - out_loss: 3.3960 - rbf_fourier_loss: 5.2077\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2563 - out_loss: 3.2937 - rbf_fourier_loss: 5.2189\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3108 - out_loss: 3.4078 - rbf_fourier_loss: 5.2138\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2242 - out_loss: 3.2691 - rbf_fourier_loss: 5.1792\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.2873 - out_loss: 3.3590 - rbf_fourier_loss: 5.2157\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3395 - out_loss: 3.4250 - rbf_fourier_loss: 5.2540\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2306 - out_loss: 3.1817 - rbf_fourier_loss: 5.2794\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3554 - out_loss: 3.4934 - rbf_fourier_loss: 5.2174\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2375 - out_loss: 3.2619 - rbf_fourier_loss: 5.2131\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2244 - out_loss: 3.2973 - rbf_fourier_loss: 5.1516\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2237 - out_loss: 3.2740 - rbf_fourier_loss: 5.1734\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2472 - out_loss: 3.2504 - rbf_fourier_loss: 5.2439\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3247 - out_loss: 3.4003 - rbf_fourier_loss: 5.2492\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2900 - out_loss: 3.3735 - rbf_fourier_loss: 5.2065\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2271 - out_loss: 3.2437 - rbf_fourier_loss: 5.2105\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2101 - out_loss: 3.1531 - rbf_fourier_loss: 5.2671\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2582 - out_loss: 3.2992 - rbf_fourier_loss: 5.2172\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2219 - out_loss: 3.2344 - rbf_fourier_loss: 5.2094\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1765 - out_loss: 3.1442 - rbf_fourier_loss: 5.2087\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1742 - out_loss: 3.1147 - rbf_fourier_loss: 5.2337\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3827 - out_loss: 3.4911 - rbf_fourier_loss: 5.2743\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1641 - out_loss: 3.1172 - rbf_fourier_loss: 5.2109\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2309 - out_loss: 3.2616 - rbf_fourier_loss: 5.2003\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1920 - out_loss: 3.1247 - rbf_fourier_loss: 5.2593\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 4.1844 - out_loss: 3.1605 - rbf_fourier_loss: 5.2083\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1990 - out_loss: 3.1697 - rbf_fourier_loss: 5.2284\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2771 - out_loss: 3.4074 - rbf_fourier_loss: 5.1467\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.3028 - out_loss: 3.3954 - rbf_fourier_loss: 5.2101\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1822 - out_loss: 3.1171 - rbf_fourier_loss: 5.2472\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1879 - out_loss: 3.1501 - rbf_fourier_loss: 5.2257\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4063 - out_loss: 3.6160 - rbf_fourier_loss: 5.1966\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.2038 - out_loss: 3.2108 - rbf_fourier_loss: 5.1968\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 4.1264 - out_loss: 3.0352 - rbf_fourier_loss: 5.2176\n",
            "Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 4.2623 - out_loss: 3.3161 - rbf_fourier_loss: 5.2085"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ffba12815d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 24\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhappy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 _r=1):\n\u001b[1;32m   1067\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    811\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2926\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3287\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3288\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3289\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2694\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2695\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   2731\u001b[0m   \u001b[0;31m# are eventually passed to ConcreteFunction()._filtered_call, which requires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;31m# expanded composites.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2733\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m   \u001b[0;31m# Check for NumPy arrays in arguments and convert them to Tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_to_components\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    904\u001b[0m     )\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deleter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9C2XTxDuUj0",
        "colab_type": "text"
      },
      "source": [
        "**Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuornJyHvSoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=2\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjUE8T1vSww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/moonsp1' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_moonso))\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(moons.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl(lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(moons, [labels_moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(moons)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_moonso)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_moonso,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_moonso,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_moonso,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_moonso,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtnB-U5CwaeQ",
        "colab_type": "text"
      },
      "source": [
        "**Mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkYoL9Y-wamt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=10\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=256\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL_vQ2Znwawz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f7502c3-95cb-4890-fc64-35620b528c9b"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/mnistp1' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(ytrain))\n",
        "lpri=PRICKA()\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl(lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(Xtrain, [ytrain,Xtrain], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0.3)\n",
        "      [y_pred,_] = model.predict(Xtrain)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=lpri.Lconvert(y_pred,ytraino)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(ytraino,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(ytraino,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(ytraino,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(ytraino,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 20ms/step - loss: 4.4988 - out_loss: 4.7692 - rbf_fourier_loss: 4.2284 - val_loss: 4.4625 - val_out_loss: 4.7002 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4697 - out_loss: 4.7108 - rbf_fourier_loss: 4.2285 - val_loss: 4.4623 - val_out_loss: 4.6998 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4783 - out_loss: 4.7259 - rbf_fourier_loss: 4.2307 - val_loss: 4.4687 - val_out_loss: 4.7126 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4762 - out_loss: 4.7214 - rbf_fourier_loss: 4.2309 - val_loss: 4.4686 - val_out_loss: 4.7124 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4839 - out_loss: 4.7391 - rbf_fourier_loss: 4.2286 - val_loss: 4.4693 - val_out_loss: 4.7139 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4725 - out_loss: 4.7171 - rbf_fourier_loss: 4.2279 - val_loss: 4.4724 - val_out_loss: 4.7199 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4730 - out_loss: 4.7173 - rbf_fourier_loss: 4.2287 - val_loss: 4.4713 - val_out_loss: 4.7178 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4654 - out_loss: 4.7022 - rbf_fourier_loss: 4.2285 - val_loss: 4.4675 - val_out_loss: 4.7102 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4675 - out_loss: 4.7089 - rbf_fourier_loss: 4.2260 - val_loss: 4.4685 - val_out_loss: 4.7122 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4669 - out_loss: 4.7039 - rbf_fourier_loss: 4.2299 - val_loss: 4.4670 - val_out_loss: 4.7093 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4736 - out_loss: 4.7199 - rbf_fourier_loss: 4.2274 - val_loss: 4.4714 - val_out_loss: 4.7179 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4695 - out_loss: 4.7095 - rbf_fourier_loss: 4.2295 - val_loss: 4.4717 - val_out_loss: 4.7185 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4630 - out_loss: 4.6973 - rbf_fourier_loss: 4.2286 - val_loss: 4.4659 - val_out_loss: 4.7070 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4682 - out_loss: 4.7066 - rbf_fourier_loss: 4.2298 - val_loss: 4.4683 - val_out_loss: 4.7117 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4724 - out_loss: 4.7179 - rbf_fourier_loss: 4.2270 - val_loss: 4.4667 - val_out_loss: 4.7085 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4654 - out_loss: 4.7013 - rbf_fourier_loss: 4.2295 - val_loss: 4.4639 - val_out_loss: 4.7030 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4714 - out_loss: 4.7141 - rbf_fourier_loss: 4.2286 - val_loss: 4.4653 - val_out_loss: 4.7058 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4597 - out_loss: 4.6917 - rbf_fourier_loss: 4.2277 - val_loss: 4.4686 - val_out_loss: 4.7124 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4704 - out_loss: 4.7104 - rbf_fourier_loss: 4.2304 - val_loss: 4.4727 - val_out_loss: 4.7207 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4741 - out_loss: 4.7170 - rbf_fourier_loss: 4.2313 - val_loss: 4.4705 - val_out_loss: 4.7162 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4594 - out_loss: 4.6925 - rbf_fourier_loss: 4.2263 - val_loss: 4.4695 - val_out_loss: 4.7142 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4548 - out_loss: 4.6781 - rbf_fourier_loss: 4.2316 - val_loss: 4.4645 - val_out_loss: 4.7042 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4520 - out_loss: 4.6761 - rbf_fourier_loss: 4.2280 - val_loss: 4.4643 - val_out_loss: 4.7038 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4627 - out_loss: 4.6977 - rbf_fourier_loss: 4.2277 - val_loss: 4.4652 - val_out_loss: 4.7056 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4640 - out_loss: 4.6998 - rbf_fourier_loss: 4.2281 - val_loss: 4.4648 - val_out_loss: 4.7048 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4677 - out_loss: 4.7058 - rbf_fourier_loss: 4.2295 - val_loss: 4.4624 - val_out_loss: 4.7000 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4524 - out_loss: 4.6759 - rbf_fourier_loss: 4.2289 - val_loss: 4.4649 - val_out_loss: 4.7049 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4641 - out_loss: 4.6982 - rbf_fourier_loss: 4.2300 - val_loss: 4.4643 - val_out_loss: 4.7038 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4576 - out_loss: 4.6880 - rbf_fourier_loss: 4.2273 - val_loss: 4.4665 - val_out_loss: 4.7082 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4479 - out_loss: 4.6686 - rbf_fourier_loss: 4.2273 - val_loss: 4.4667 - val_out_loss: 4.7085 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4480 - out_loss: 4.6677 - rbf_fourier_loss: 4.2283 - val_loss: 4.4683 - val_out_loss: 4.7118 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4629 - out_loss: 4.6985 - rbf_fourier_loss: 4.2272 - val_loss: 4.4653 - val_out_loss: 4.7057 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4588 - out_loss: 4.6902 - rbf_fourier_loss: 4.2274 - val_loss: 4.4662 - val_out_loss: 4.7077 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4592 - out_loss: 4.6870 - rbf_fourier_loss: 4.2314 - val_loss: 4.4653 - val_out_loss: 4.7058 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4637 - out_loss: 4.6973 - rbf_fourier_loss: 4.2301 - val_loss: 4.4638 - val_out_loss: 4.7027 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4601 - out_loss: 4.6907 - rbf_fourier_loss: 4.2295 - val_loss: 4.4615 - val_out_loss: 4.6981 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4543 - out_loss: 4.6785 - rbf_fourier_loss: 4.2300 - val_loss: 4.4605 - val_out_loss: 4.6963 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4448 - out_loss: 4.6610 - rbf_fourier_loss: 4.2286 - val_loss: 4.4604 - val_out_loss: 4.6960 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4528 - out_loss: 4.6748 - rbf_fourier_loss: 4.2307 - val_loss: 4.4584 - val_out_loss: 4.6920 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4533 - out_loss: 4.6804 - rbf_fourier_loss: 4.2262 - val_loss: 4.4564 - val_out_loss: 4.6881 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4433 - out_loss: 4.6547 - rbf_fourier_loss: 4.2319 - val_loss: 4.4591 - val_out_loss: 4.6935 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4626 - out_loss: 4.6958 - rbf_fourier_loss: 4.2293 - val_loss: 4.4617 - val_out_loss: 4.6985 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4671 - out_loss: 4.7061 - rbf_fourier_loss: 4.2281 - val_loss: 4.4622 - val_out_loss: 4.6996 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4422 - out_loss: 4.6535 - rbf_fourier_loss: 4.2309 - val_loss: 4.4609 - val_out_loss: 4.6970 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4491 - out_loss: 4.6688 - rbf_fourier_loss: 4.2293 - val_loss: 4.4641 - val_out_loss: 4.7034 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4445 - out_loss: 4.6585 - rbf_fourier_loss: 4.2304 - val_loss: 4.4621 - val_out_loss: 4.6994 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4586 - out_loss: 4.6898 - rbf_fourier_loss: 4.2275 - val_loss: 4.4632 - val_out_loss: 4.7016 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4539 - out_loss: 4.6778 - rbf_fourier_loss: 4.2301 - val_loss: 4.4650 - val_out_loss: 4.7052 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4398 - out_loss: 4.6512 - rbf_fourier_loss: 4.2285 - val_loss: 4.4659 - val_out_loss: 4.7070 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4427 - out_loss: 4.6574 - rbf_fourier_loss: 4.2280 - val_loss: 4.4677 - val_out_loss: 4.7106 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4448 - out_loss: 4.6586 - rbf_fourier_loss: 4.2310 - val_loss: 4.4671 - val_out_loss: 4.7094 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4395 - out_loss: 4.6503 - rbf_fourier_loss: 4.2287 - val_loss: 4.4671 - val_out_loss: 4.7094 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4466 - out_loss: 4.6658 - rbf_fourier_loss: 4.2274 - val_loss: 4.4642 - val_out_loss: 4.7036 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4537 - out_loss: 4.6768 - rbf_fourier_loss: 4.2306 - val_loss: 4.4654 - val_out_loss: 4.7061 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4423 - out_loss: 4.6558 - rbf_fourier_loss: 4.2288 - val_loss: 4.4646 - val_out_loss: 4.7045 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4359 - out_loss: 4.6438 - rbf_fourier_loss: 4.2280 - val_loss: 4.4623 - val_out_loss: 4.6998 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4463 - out_loss: 4.6666 - rbf_fourier_loss: 4.2260 - val_loss: 4.4636 - val_out_loss: 4.7024 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4402 - out_loss: 4.6506 - rbf_fourier_loss: 4.2297 - val_loss: 4.4602 - val_out_loss: 4.6955 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4438 - out_loss: 4.6589 - rbf_fourier_loss: 4.2287 - val_loss: 4.4599 - val_out_loss: 4.6951 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4463 - out_loss: 4.6643 - rbf_fourier_loss: 4.2282 - val_loss: 4.4592 - val_out_loss: 4.6936 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4489 - out_loss: 4.6685 - rbf_fourier_loss: 4.2292 - val_loss: 4.4553 - val_out_loss: 4.6858 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4283 - out_loss: 4.6277 - rbf_fourier_loss: 4.2289 - val_loss: 4.4575 - val_out_loss: 4.6902 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4314 - out_loss: 4.6330 - rbf_fourier_loss: 4.2298 - val_loss: 4.4587 - val_out_loss: 4.6927 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4452 - out_loss: 4.6597 - rbf_fourier_loss: 4.2306 - val_loss: 4.4570 - val_out_loss: 4.6891 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4367 - out_loss: 4.6449 - rbf_fourier_loss: 4.2286 - val_loss: 4.4563 - val_out_loss: 4.6878 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4409 - out_loss: 4.6529 - rbf_fourier_loss: 4.2290 - val_loss: 4.4564 - val_out_loss: 4.6880 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4582 - out_loss: 4.6864 - rbf_fourier_loss: 4.2300 - val_loss: 4.4556 - val_out_loss: 4.6864 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4486 - out_loss: 4.6673 - rbf_fourier_loss: 4.2299 - val_loss: 4.4562 - val_out_loss: 4.6877 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4215 - out_loss: 4.6148 - rbf_fourier_loss: 4.2283 - val_loss: 4.4622 - val_out_loss: 4.6996 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4446 - out_loss: 4.6624 - rbf_fourier_loss: 4.2267 - val_loss: 4.4597 - val_out_loss: 4.6946 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4483 - out_loss: 4.6656 - rbf_fourier_loss: 4.2310 - val_loss: 4.4632 - val_out_loss: 4.7015 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4422 - out_loss: 4.6543 - rbf_fourier_loss: 4.2301 - val_loss: 4.4609 - val_out_loss: 4.6970 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4359 - out_loss: 4.6423 - rbf_fourier_loss: 4.2296 - val_loss: 4.4607 - val_out_loss: 4.6967 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4320 - out_loss: 4.6362 - rbf_fourier_loss: 4.2279 - val_loss: 4.4635 - val_out_loss: 4.7022 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4352 - out_loss: 4.6406 - rbf_fourier_loss: 4.2297 - val_loss: 4.4626 - val_out_loss: 4.7003 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4276 - out_loss: 4.6248 - rbf_fourier_loss: 4.2304 - val_loss: 4.4612 - val_out_loss: 4.6975 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4413 - out_loss: 4.6546 - rbf_fourier_loss: 4.2280 - val_loss: 4.4619 - val_out_loss: 4.6990 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4327 - out_loss: 4.6376 - rbf_fourier_loss: 4.2278 - val_loss: 4.4624 - val_out_loss: 4.7000 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4406 - out_loss: 4.6522 - rbf_fourier_loss: 4.2289 - val_loss: 4.4629 - val_out_loss: 4.7010 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4299 - out_loss: 4.6285 - rbf_fourier_loss: 4.2312 - val_loss: 4.4627 - val_out_loss: 4.7006 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4425 - out_loss: 4.6561 - rbf_fourier_loss: 4.2290 - val_loss: 4.4619 - val_out_loss: 4.6990 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4340 - out_loss: 4.6382 - rbf_fourier_loss: 4.2298 - val_loss: 4.4622 - val_out_loss: 4.6995 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4349 - out_loss: 4.6408 - rbf_fourier_loss: 4.2290 - val_loss: 4.4599 - val_out_loss: 4.6950 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4166 - out_loss: 4.6042 - rbf_fourier_loss: 4.2290 - val_loss: 4.4631 - val_out_loss: 4.7014 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4346 - out_loss: 4.6388 - rbf_fourier_loss: 4.2304 - val_loss: 4.4592 - val_out_loss: 4.6935 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4290 - out_loss: 4.6284 - rbf_fourier_loss: 4.2295 - val_loss: 4.4607 - val_out_loss: 4.6966 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4225 - out_loss: 4.6161 - rbf_fourier_loss: 4.2289 - val_loss: 4.4595 - val_out_loss: 4.6943 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4330 - out_loss: 4.6366 - rbf_fourier_loss: 4.2294 - val_loss: 4.4578 - val_out_loss: 4.6907 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4379 - out_loss: 4.6479 - rbf_fourier_loss: 4.2278 - val_loss: 4.4583 - val_out_loss: 4.6919 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4287 - out_loss: 4.6286 - rbf_fourier_loss: 4.2288 - val_loss: 4.4587 - val_out_loss: 4.6926 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4218 - out_loss: 4.6149 - rbf_fourier_loss: 4.2288 - val_loss: 4.4566 - val_out_loss: 4.6883 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4179 - out_loss: 4.6082 - rbf_fourier_loss: 4.2275 - val_loss: 4.4554 - val_out_loss: 4.6859 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4296 - out_loss: 4.6299 - rbf_fourier_loss: 4.2293 - val_loss: 4.4545 - val_out_loss: 4.6841 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4253 - out_loss: 4.6228 - rbf_fourier_loss: 4.2277 - val_loss: 4.4542 - val_out_loss: 4.6836 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4354 - out_loss: 4.6402 - rbf_fourier_loss: 4.2307 - val_loss: 4.4572 - val_out_loss: 4.6895 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4363 - out_loss: 4.6425 - rbf_fourier_loss: 4.2301 - val_loss: 4.4578 - val_out_loss: 4.6908 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4350 - out_loss: 4.6398 - rbf_fourier_loss: 4.2303 - val_loss: 4.4563 - val_out_loss: 4.6878 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4230 - out_loss: 4.6171 - rbf_fourier_loss: 4.2288 - val_loss: 4.4570 - val_out_loss: 4.6893 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4292 - out_loss: 4.6291 - rbf_fourier_loss: 4.2292 - val_loss: 4.4589 - val_out_loss: 4.6931 - val_rbf_fourier_loss: 4.2248\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4308 - out_loss: 4.6337 - rbf_fourier_loss: 4.2279 - val_loss: 4.4566 - val_out_loss: 4.6885 - val_rbf_fourier_loss: 4.2248\n",
            "it 1/10\n",
            "acc: 11.236666666666666\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 4.4733 - out_loss: 4.7208 - rbf_fourier_loss: 4.2257 - val_loss: 4.4574 - val_out_loss: 4.6941 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4861 - out_loss: 4.7451 - rbf_fourier_loss: 4.2271 - val_loss: 4.4614 - val_out_loss: 4.7022 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4806 - out_loss: 4.7368 - rbf_fourier_loss: 4.2245 - val_loss: 4.4659 - val_out_loss: 4.7112 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4546 - out_loss: 4.6841 - rbf_fourier_loss: 4.2251 - val_loss: 4.4654 - val_out_loss: 4.7101 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4758 - out_loss: 4.7264 - rbf_fourier_loss: 4.2252 - val_loss: 4.4581 - val_out_loss: 4.6955 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4747 - out_loss: 4.7242 - rbf_fourier_loss: 4.2252 - val_loss: 4.4523 - val_out_loss: 4.6840 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4639 - out_loss: 4.7022 - rbf_fourier_loss: 4.2257 - val_loss: 4.4534 - val_out_loss: 4.6861 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4625 - out_loss: 4.6969 - rbf_fourier_loss: 4.2282 - val_loss: 4.4479 - val_out_loss: 4.6751 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4699 - out_loss: 4.7165 - rbf_fourier_loss: 4.2232 - val_loss: 4.4451 - val_out_loss: 4.6695 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4702 - out_loss: 4.7121 - rbf_fourier_loss: 4.2283 - val_loss: 4.4425 - val_out_loss: 4.6644 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4638 - out_loss: 4.7017 - rbf_fourier_loss: 4.2259 - val_loss: 4.4424 - val_out_loss: 4.6641 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4560 - out_loss: 4.6857 - rbf_fourier_loss: 4.2263 - val_loss: 4.4442 - val_out_loss: 4.6676 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4704 - out_loss: 4.7166 - rbf_fourier_loss: 4.2241 - val_loss: 4.4537 - val_out_loss: 4.6868 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4643 - out_loss: 4.7038 - rbf_fourier_loss: 4.2249 - val_loss: 4.4547 - val_out_loss: 4.6887 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4668 - out_loss: 4.7085 - rbf_fourier_loss: 4.2251 - val_loss: 4.4593 - val_out_loss: 4.6980 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4642 - out_loss: 4.7046 - rbf_fourier_loss: 4.2237 - val_loss: 4.4588 - val_out_loss: 4.6969 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4610 - out_loss: 4.6978 - rbf_fourier_loss: 4.2242 - val_loss: 4.4600 - val_out_loss: 4.6994 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4562 - out_loss: 4.6880 - rbf_fourier_loss: 4.2243 - val_loss: 4.4595 - val_out_loss: 4.6983 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4625 - out_loss: 4.7011 - rbf_fourier_loss: 4.2239 - val_loss: 4.4625 - val_out_loss: 4.7044 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4662 - out_loss: 4.7071 - rbf_fourier_loss: 4.2254 - val_loss: 4.4616 - val_out_loss: 4.7026 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4695 - out_loss: 4.7126 - rbf_fourier_loss: 4.2264 - val_loss: 4.4589 - val_out_loss: 4.6971 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4669 - out_loss: 4.7054 - rbf_fourier_loss: 4.2284 - val_loss: 4.4585 - val_out_loss: 4.6963 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4637 - out_loss: 4.7003 - rbf_fourier_loss: 4.2271 - val_loss: 4.4597 - val_out_loss: 4.6988 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4602 - out_loss: 4.6948 - rbf_fourier_loss: 4.2257 - val_loss: 4.4589 - val_out_loss: 4.6970 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4652 - out_loss: 4.7055 - rbf_fourier_loss: 4.2249 - val_loss: 4.4589 - val_out_loss: 4.6972 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4570 - out_loss: 4.6876 - rbf_fourier_loss: 4.2265 - val_loss: 4.4548 - val_out_loss: 4.6890 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4442 - out_loss: 4.6636 - rbf_fourier_loss: 4.2248 - val_loss: 4.4542 - val_out_loss: 4.6877 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4664 - out_loss: 4.7093 - rbf_fourier_loss: 4.2234 - val_loss: 4.4559 - val_out_loss: 4.6911 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4521 - out_loss: 4.6797 - rbf_fourier_loss: 4.2245 - val_loss: 4.4553 - val_out_loss: 4.6899 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4408 - out_loss: 4.6561 - rbf_fourier_loss: 4.2256 - val_loss: 4.4523 - val_out_loss: 4.6838 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4510 - out_loss: 4.6750 - rbf_fourier_loss: 4.2270 - val_loss: 4.4492 - val_out_loss: 4.6778 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4564 - out_loss: 4.6875 - rbf_fourier_loss: 4.2253 - val_loss: 4.4478 - val_out_loss: 4.6749 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4490 - out_loss: 4.6715 - rbf_fourier_loss: 4.2265 - val_loss: 4.4479 - val_out_loss: 4.6751 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4677 - out_loss: 4.7084 - rbf_fourier_loss: 4.2269 - val_loss: 4.4499 - val_out_loss: 4.6791 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4498 - out_loss: 4.6744 - rbf_fourier_loss: 4.2252 - val_loss: 4.4492 - val_out_loss: 4.6778 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4540 - out_loss: 4.6810 - rbf_fourier_loss: 4.2269 - val_loss: 4.4506 - val_out_loss: 4.6805 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4541 - out_loss: 4.6828 - rbf_fourier_loss: 4.2253 - val_loss: 4.4516 - val_out_loss: 4.6825 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4504 - out_loss: 4.6766 - rbf_fourier_loss: 4.2243 - val_loss: 4.4499 - val_out_loss: 4.6792 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4454 - out_loss: 4.6664 - rbf_fourier_loss: 4.2244 - val_loss: 4.4500 - val_out_loss: 4.6794 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4551 - out_loss: 4.6863 - rbf_fourier_loss: 4.2240 - val_loss: 4.4488 - val_out_loss: 4.6770 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4493 - out_loss: 4.6731 - rbf_fourier_loss: 4.2254 - val_loss: 4.4485 - val_out_loss: 4.6763 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4456 - out_loss: 4.6655 - rbf_fourier_loss: 4.2256 - val_loss: 4.4510 - val_out_loss: 4.6812 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4521 - out_loss: 4.6803 - rbf_fourier_loss: 4.2239 - val_loss: 4.4531 - val_out_loss: 4.6856 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4472 - out_loss: 4.6705 - rbf_fourier_loss: 4.2238 - val_loss: 4.4575 - val_out_loss: 4.6943 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4607 - out_loss: 4.6952 - rbf_fourier_loss: 4.2263 - val_loss: 4.4561 - val_out_loss: 4.6915 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4380 - out_loss: 4.6511 - rbf_fourier_loss: 4.2250 - val_loss: 4.4551 - val_out_loss: 4.6895 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4521 - out_loss: 4.6795 - rbf_fourier_loss: 4.2247 - val_loss: 4.4558 - val_out_loss: 4.6908 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4663 - out_loss: 4.7070 - rbf_fourier_loss: 4.2256 - val_loss: 4.4541 - val_out_loss: 4.6875 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4400 - out_loss: 4.6560 - rbf_fourier_loss: 4.2239 - val_loss: 4.4555 - val_out_loss: 4.6902 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4513 - out_loss: 4.6761 - rbf_fourier_loss: 4.2265 - val_loss: 4.4586 - val_out_loss: 4.6965 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4529 - out_loss: 4.6809 - rbf_fourier_loss: 4.2249 - val_loss: 4.4577 - val_out_loss: 4.6947 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4420 - out_loss: 4.6586 - rbf_fourier_loss: 4.2254 - val_loss: 4.4577 - val_out_loss: 4.6947 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4488 - out_loss: 4.6744 - rbf_fourier_loss: 4.2231 - val_loss: 4.4574 - val_out_loss: 4.6941 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4422 - out_loss: 4.6581 - rbf_fourier_loss: 4.2263 - val_loss: 4.4590 - val_out_loss: 4.6974 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4428 - out_loss: 4.6611 - rbf_fourier_loss: 4.2245 - val_loss: 4.4583 - val_out_loss: 4.6960 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4414 - out_loss: 4.6588 - rbf_fourier_loss: 4.2239 - val_loss: 4.4574 - val_out_loss: 4.6942 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4527 - out_loss: 4.6806 - rbf_fourier_loss: 4.2248 - val_loss: 4.4620 - val_out_loss: 4.7034 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4506 - out_loss: 4.6749 - rbf_fourier_loss: 4.2262 - val_loss: 4.4634 - val_out_loss: 4.7061 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4297 - out_loss: 4.6341 - rbf_fourier_loss: 4.2253 - val_loss: 4.4680 - val_out_loss: 4.7153 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4525 - out_loss: 4.6783 - rbf_fourier_loss: 4.2268 - val_loss: 4.4642 - val_out_loss: 4.7078 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4337 - out_loss: 4.6431 - rbf_fourier_loss: 4.2243 - val_loss: 4.4657 - val_out_loss: 4.7106 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4379 - out_loss: 4.6493 - rbf_fourier_loss: 4.2264 - val_loss: 4.4655 - val_out_loss: 4.7103 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4448 - out_loss: 4.6635 - rbf_fourier_loss: 4.2260 - val_loss: 4.4657 - val_out_loss: 4.7108 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4557 - out_loss: 4.6863 - rbf_fourier_loss: 4.2251 - val_loss: 4.4647 - val_out_loss: 4.7087 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4323 - out_loss: 4.6396 - rbf_fourier_loss: 4.2251 - val_loss: 4.4600 - val_out_loss: 4.6994 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4410 - out_loss: 4.6562 - rbf_fourier_loss: 4.2258 - val_loss: 4.4631 - val_out_loss: 4.7055 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4280 - out_loss: 4.6314 - rbf_fourier_loss: 4.2246 - val_loss: 4.4624 - val_out_loss: 4.7040 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4341 - out_loss: 4.6423 - rbf_fourier_loss: 4.2259 - val_loss: 4.4675 - val_out_loss: 4.7142 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4395 - out_loss: 4.6541 - rbf_fourier_loss: 4.2249 - val_loss: 4.4713 - val_out_loss: 4.7220 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4288 - out_loss: 4.6325 - rbf_fourier_loss: 4.2251 - val_loss: 4.4697 - val_out_loss: 4.7186 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4442 - out_loss: 4.6630 - rbf_fourier_loss: 4.2255 - val_loss: 4.4714 - val_out_loss: 4.7222 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4299 - out_loss: 4.6335 - rbf_fourier_loss: 4.2263 - val_loss: 4.4665 - val_out_loss: 4.7123 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4290 - out_loss: 4.6320 - rbf_fourier_loss: 4.2261 - val_loss: 4.4665 - val_out_loss: 4.7123 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4476 - out_loss: 4.6662 - rbf_fourier_loss: 4.2290 - val_loss: 4.4629 - val_out_loss: 4.7051 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4369 - out_loss: 4.6487 - rbf_fourier_loss: 4.2252 - val_loss: 4.4658 - val_out_loss: 4.7109 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4364 - out_loss: 4.6501 - rbf_fourier_loss: 4.2226 - val_loss: 4.4632 - val_out_loss: 4.7057 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4268 - out_loss: 4.6289 - rbf_fourier_loss: 4.2247 - val_loss: 4.4631 - val_out_loss: 4.7055 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4302 - out_loss: 4.6360 - rbf_fourier_loss: 4.2243 - val_loss: 4.4616 - val_out_loss: 4.7025 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4463 - out_loss: 4.6683 - rbf_fourier_loss: 4.2242 - val_loss: 4.4628 - val_out_loss: 4.7050 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4299 - out_loss: 4.6347 - rbf_fourier_loss: 4.2250 - val_loss: 4.4647 - val_out_loss: 4.7086 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4230 - out_loss: 4.6209 - rbf_fourier_loss: 4.2252 - val_loss: 4.4627 - val_out_loss: 4.7048 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4406 - out_loss: 4.6575 - rbf_fourier_loss: 4.2237 - val_loss: 4.4577 - val_out_loss: 4.6947 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4468 - out_loss: 4.6675 - rbf_fourier_loss: 4.2262 - val_loss: 4.4635 - val_out_loss: 4.7064 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4296 - out_loss: 4.6340 - rbf_fourier_loss: 4.2251 - val_loss: 4.4632 - val_out_loss: 4.7057 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4361 - out_loss: 4.6479 - rbf_fourier_loss: 4.2242 - val_loss: 4.4624 - val_out_loss: 4.7040 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4196 - out_loss: 4.6138 - rbf_fourier_loss: 4.2253 - val_loss: 4.4599 - val_out_loss: 4.6991 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4207 - out_loss: 4.6175 - rbf_fourier_loss: 4.2239 - val_loss: 4.4604 - val_out_loss: 4.7001 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4321 - out_loss: 4.6394 - rbf_fourier_loss: 4.2247 - val_loss: 4.4613 - val_out_loss: 4.7020 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4391 - out_loss: 4.6527 - rbf_fourier_loss: 4.2255 - val_loss: 4.4600 - val_out_loss: 4.6994 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4275 - out_loss: 4.6298 - rbf_fourier_loss: 4.2251 - val_loss: 4.4582 - val_out_loss: 4.6956 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4209 - out_loss: 4.6177 - rbf_fourier_loss: 4.2240 - val_loss: 4.4599 - val_out_loss: 4.6991 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4289 - out_loss: 4.6335 - rbf_fourier_loss: 4.2242 - val_loss: 4.4594 - val_out_loss: 4.6982 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4221 - out_loss: 4.6180 - rbf_fourier_loss: 4.2262 - val_loss: 4.4596 - val_out_loss: 4.6986 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4399 - out_loss: 4.6572 - rbf_fourier_loss: 4.2226 - val_loss: 4.4591 - val_out_loss: 4.6975 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4229 - out_loss: 4.6215 - rbf_fourier_loss: 4.2243 - val_loss: 4.4586 - val_out_loss: 4.6965 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4328 - out_loss: 4.6410 - rbf_fourier_loss: 4.2246 - val_loss: 4.4585 - val_out_loss: 4.6963 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4226 - out_loss: 4.6203 - rbf_fourier_loss: 4.2250 - val_loss: 4.4584 - val_out_loss: 4.6961 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4268 - out_loss: 4.6271 - rbf_fourier_loss: 4.2265 - val_loss: 4.4579 - val_out_loss: 4.6951 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4184 - out_loss: 4.6113 - rbf_fourier_loss: 4.2256 - val_loss: 4.4573 - val_out_loss: 4.6939 - val_rbf_fourier_loss: 4.2207\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4237 - out_loss: 4.6218 - rbf_fourier_loss: 4.2255 - val_loss: 4.4578 - val_out_loss: 4.6950 - val_rbf_fourier_loss: 4.2207\n",
            "it 1/10\n",
            "acc: 11.313333333333334\n",
            "ari: 0.000753827146037326\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 4.4741 - out_loss: 4.7229 - rbf_fourier_loss: 4.2252 - val_loss: 4.4862 - val_out_loss: 4.7482 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4734 - out_loss: 4.7204 - rbf_fourier_loss: 4.2263 - val_loss: 4.4773 - val_out_loss: 4.7305 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4840 - out_loss: 4.7426 - rbf_fourier_loss: 4.2254 - val_loss: 4.4775 - val_out_loss: 4.7309 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4740 - out_loss: 4.7201 - rbf_fourier_loss: 4.2279 - val_loss: 4.4751 - val_out_loss: 4.7261 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4654 - out_loss: 4.7059 - rbf_fourier_loss: 4.2248 - val_loss: 4.4797 - val_out_loss: 4.7354 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4747 - out_loss: 4.7212 - rbf_fourier_loss: 4.2281 - val_loss: 4.4746 - val_out_loss: 4.7251 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4611 - out_loss: 4.6967 - rbf_fourier_loss: 4.2255 - val_loss: 4.4730 - val_out_loss: 4.7219 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4817 - out_loss: 4.7363 - rbf_fourier_loss: 4.2272 - val_loss: 4.4712 - val_out_loss: 4.7182 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4650 - out_loss: 4.7050 - rbf_fourier_loss: 4.2250 - val_loss: 4.4721 - val_out_loss: 4.7200 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4601 - out_loss: 4.6925 - rbf_fourier_loss: 4.2276 - val_loss: 4.4678 - val_out_loss: 4.7115 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4679 - out_loss: 4.7086 - rbf_fourier_loss: 4.2272 - val_loss: 4.4666 - val_out_loss: 4.7091 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4531 - out_loss: 4.6800 - rbf_fourier_loss: 4.2261 - val_loss: 4.4723 - val_out_loss: 4.7204 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4723 - out_loss: 4.7180 - rbf_fourier_loss: 4.2265 - val_loss: 4.4697 - val_out_loss: 4.7152 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4664 - out_loss: 4.7063 - rbf_fourier_loss: 4.2264 - val_loss: 4.4690 - val_out_loss: 4.7138 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4451 - out_loss: 4.6649 - rbf_fourier_loss: 4.2253 - val_loss: 4.4711 - val_out_loss: 4.7182 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4739 - out_loss: 4.7220 - rbf_fourier_loss: 4.2258 - val_loss: 4.4691 - val_out_loss: 4.7142 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4536 - out_loss: 4.6809 - rbf_fourier_loss: 4.2263 - val_loss: 4.4760 - val_out_loss: 4.7279 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4661 - out_loss: 4.7059 - rbf_fourier_loss: 4.2263 - val_loss: 4.4763 - val_out_loss: 4.7286 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4650 - out_loss: 4.7026 - rbf_fourier_loss: 4.2275 - val_loss: 4.4758 - val_out_loss: 4.7275 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4613 - out_loss: 4.6985 - rbf_fourier_loss: 4.2242 - val_loss: 4.4730 - val_out_loss: 4.7220 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4556 - out_loss: 4.6844 - rbf_fourier_loss: 4.2268 - val_loss: 4.4742 - val_out_loss: 4.7243 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4627 - out_loss: 4.7007 - rbf_fourier_loss: 4.2247 - val_loss: 4.4700 - val_out_loss: 4.7159 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4716 - out_loss: 4.7153 - rbf_fourier_loss: 4.2280 - val_loss: 4.4721 - val_out_loss: 4.7202 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4560 - out_loss: 4.6864 - rbf_fourier_loss: 4.2257 - val_loss: 4.4777 - val_out_loss: 4.7312 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4557 - out_loss: 4.6851 - rbf_fourier_loss: 4.2264 - val_loss: 4.4782 - val_out_loss: 4.7324 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4514 - out_loss: 4.6774 - rbf_fourier_loss: 4.2254 - val_loss: 4.4725 - val_out_loss: 4.7210 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4598 - out_loss: 4.6929 - rbf_fourier_loss: 4.2266 - val_loss: 4.4759 - val_out_loss: 4.7277 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4561 - out_loss: 4.6863 - rbf_fourier_loss: 4.2258 - val_loss: 4.4781 - val_out_loss: 4.7321 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4436 - out_loss: 4.6611 - rbf_fourier_loss: 4.2261 - val_loss: 4.4766 - val_out_loss: 4.7292 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4539 - out_loss: 4.6795 - rbf_fourier_loss: 4.2283 - val_loss: 4.4737 - val_out_loss: 4.7233 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4464 - out_loss: 4.6681 - rbf_fourier_loss: 4.2248 - val_loss: 4.4733 - val_out_loss: 4.7224 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4556 - out_loss: 4.6847 - rbf_fourier_loss: 4.2266 - val_loss: 4.4701 - val_out_loss: 4.7161 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4447 - out_loss: 4.6631 - rbf_fourier_loss: 4.2263 - val_loss: 4.4674 - val_out_loss: 4.7108 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4552 - out_loss: 4.6843 - rbf_fourier_loss: 4.2261 - val_loss: 4.4711 - val_out_loss: 4.7182 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4600 - out_loss: 4.6941 - rbf_fourier_loss: 4.2259 - val_loss: 4.4685 - val_out_loss: 4.7129 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4550 - out_loss: 4.6838 - rbf_fourier_loss: 4.2263 - val_loss: 4.4699 - val_out_loss: 4.7158 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4627 - out_loss: 4.6982 - rbf_fourier_loss: 4.2272 - val_loss: 4.4659 - val_out_loss: 4.7078 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4544 - out_loss: 4.6833 - rbf_fourier_loss: 4.2255 - val_loss: 4.4641 - val_out_loss: 4.7041 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4535 - out_loss: 4.6782 - rbf_fourier_loss: 4.2287 - val_loss: 4.4611 - val_out_loss: 4.6981 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4472 - out_loss: 4.6681 - rbf_fourier_loss: 4.2264 - val_loss: 4.4601 - val_out_loss: 4.6961 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4387 - out_loss: 4.6518 - rbf_fourier_loss: 4.2257 - val_loss: 4.4591 - val_out_loss: 4.6942 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4387 - out_loss: 4.6496 - rbf_fourier_loss: 4.2278 - val_loss: 4.4593 - val_out_loss: 4.6946 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4373 - out_loss: 4.6479 - rbf_fourier_loss: 4.2268 - val_loss: 4.4601 - val_out_loss: 4.6961 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4528 - out_loss: 4.6802 - rbf_fourier_loss: 4.2254 - val_loss: 4.4607 - val_out_loss: 4.6972 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4293 - out_loss: 4.6319 - rbf_fourier_loss: 4.2267 - val_loss: 4.4643 - val_out_loss: 4.7044 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4453 - out_loss: 4.6648 - rbf_fourier_loss: 4.2257 - val_loss: 4.4646 - val_out_loss: 4.7051 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4517 - out_loss: 4.6777 - rbf_fourier_loss: 4.2256 - val_loss: 4.4679 - val_out_loss: 4.7118 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4403 - out_loss: 4.6549 - rbf_fourier_loss: 4.2256 - val_loss: 4.4639 - val_out_loss: 4.7038 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4364 - out_loss: 4.6466 - rbf_fourier_loss: 4.2262 - val_loss: 4.4590 - val_out_loss: 4.6939 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4480 - out_loss: 4.6678 - rbf_fourier_loss: 4.2283 - val_loss: 4.4610 - val_out_loss: 4.6979 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4438 - out_loss: 4.6595 - rbf_fourier_loss: 4.2281 - val_loss: 4.4611 - val_out_loss: 4.6982 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4471 - out_loss: 4.6670 - rbf_fourier_loss: 4.2273 - val_loss: 4.4600 - val_out_loss: 4.6960 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4412 - out_loss: 4.6537 - rbf_fourier_loss: 4.2287 - val_loss: 4.4626 - val_out_loss: 4.7011 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4446 - out_loss: 4.6625 - rbf_fourier_loss: 4.2267 - val_loss: 4.4602 - val_out_loss: 4.6963 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4478 - out_loss: 4.6711 - rbf_fourier_loss: 4.2245 - val_loss: 4.4572 - val_out_loss: 4.6903 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4578 - out_loss: 4.6872 - rbf_fourier_loss: 4.2284 - val_loss: 4.4620 - val_out_loss: 4.7000 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4465 - out_loss: 4.6671 - rbf_fourier_loss: 4.2259 - val_loss: 4.4616 - val_out_loss: 4.6991 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4385 - out_loss: 4.6509 - rbf_fourier_loss: 4.2261 - val_loss: 4.4593 - val_out_loss: 4.6946 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4387 - out_loss: 4.6515 - rbf_fourier_loss: 4.2259 - val_loss: 4.4582 - val_out_loss: 4.6924 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4358 - out_loss: 4.6430 - rbf_fourier_loss: 4.2285 - val_loss: 4.4580 - val_out_loss: 4.6919 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4403 - out_loss: 4.6556 - rbf_fourier_loss: 4.2249 - val_loss: 4.4573 - val_out_loss: 4.6905 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4414 - out_loss: 4.6577 - rbf_fourier_loss: 4.2251 - val_loss: 4.4599 - val_out_loss: 4.6958 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4356 - out_loss: 4.6438 - rbf_fourier_loss: 4.2273 - val_loss: 4.4552 - val_out_loss: 4.6864 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4293 - out_loss: 4.6315 - rbf_fourier_loss: 4.2272 - val_loss: 4.4534 - val_out_loss: 4.6828 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4367 - out_loss: 4.6457 - rbf_fourier_loss: 4.2278 - val_loss: 4.4539 - val_out_loss: 4.6837 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4342 - out_loss: 4.6400 - rbf_fourier_loss: 4.2284 - val_loss: 4.4534 - val_out_loss: 4.6827 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4289 - out_loss: 4.6327 - rbf_fourier_loss: 4.2251 - val_loss: 4.4560 - val_out_loss: 4.6880 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4297 - out_loss: 4.6321 - rbf_fourier_loss: 4.2273 - val_loss: 4.4564 - val_out_loss: 4.6888 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4278 - out_loss: 4.6291 - rbf_fourier_loss: 4.2265 - val_loss: 4.4572 - val_out_loss: 4.6904 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4260 - out_loss: 4.6265 - rbf_fourier_loss: 4.2254 - val_loss: 4.4554 - val_out_loss: 4.6867 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4254 - out_loss: 4.6249 - rbf_fourier_loss: 4.2260 - val_loss: 4.4547 - val_out_loss: 4.6853 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4244 - out_loss: 4.6218 - rbf_fourier_loss: 4.2269 - val_loss: 4.4517 - val_out_loss: 4.6794 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4312 - out_loss: 4.6367 - rbf_fourier_loss: 4.2258 - val_loss: 4.4530 - val_out_loss: 4.6819 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4247 - out_loss: 4.6236 - rbf_fourier_loss: 4.2258 - val_loss: 4.4523 - val_out_loss: 4.6805 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4489 - out_loss: 4.6705 - rbf_fourier_loss: 4.2273 - val_loss: 4.4550 - val_out_loss: 4.6858 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4269 - out_loss: 4.6272 - rbf_fourier_loss: 4.2265 - val_loss: 4.4476 - val_out_loss: 4.6711 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4461 - out_loss: 4.6663 - rbf_fourier_loss: 4.2259 - val_loss: 4.4494 - val_out_loss: 4.6747 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4420 - out_loss: 4.6567 - rbf_fourier_loss: 4.2272 - val_loss: 4.4478 - val_out_loss: 4.6714 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4209 - out_loss: 4.6128 - rbf_fourier_loss: 4.2290 - val_loss: 4.4487 - val_out_loss: 4.6734 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4192 - out_loss: 4.6107 - rbf_fourier_loss: 4.2276 - val_loss: 4.4488 - val_out_loss: 4.6736 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4224 - out_loss: 4.6192 - rbf_fourier_loss: 4.2256 - val_loss: 4.4512 - val_out_loss: 4.6782 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4240 - out_loss: 4.6237 - rbf_fourier_loss: 4.2242 - val_loss: 4.4481 - val_out_loss: 4.6721 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4303 - out_loss: 4.6349 - rbf_fourier_loss: 4.2256 - val_loss: 4.4458 - val_out_loss: 4.6675 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4299 - out_loss: 4.6329 - rbf_fourier_loss: 4.2269 - val_loss: 4.4464 - val_out_loss: 4.6688 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4292 - out_loss: 4.6298 - rbf_fourier_loss: 4.2286 - val_loss: 4.4476 - val_out_loss: 4.6711 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4315 - out_loss: 4.6376 - rbf_fourier_loss: 4.2255 - val_loss: 4.4478 - val_out_loss: 4.6715 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4134 - out_loss: 4.6015 - rbf_fourier_loss: 4.2252 - val_loss: 4.4479 - val_out_loss: 4.6717 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4319 - out_loss: 4.6359 - rbf_fourier_loss: 4.2278 - val_loss: 4.4458 - val_out_loss: 4.6676 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4101 - out_loss: 4.5922 - rbf_fourier_loss: 4.2279 - val_loss: 4.4443 - val_out_loss: 4.6645 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4112 - out_loss: 4.5964 - rbf_fourier_loss: 4.2261 - val_loss: 4.4437 - val_out_loss: 4.6633 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4235 - out_loss: 4.6186 - rbf_fourier_loss: 4.2285 - val_loss: 4.4418 - val_out_loss: 4.6596 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4331 - out_loss: 4.6376 - rbf_fourier_loss: 4.2286 - val_loss: 4.4426 - val_out_loss: 4.6611 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4198 - out_loss: 4.6128 - rbf_fourier_loss: 4.2268 - val_loss: 4.4449 - val_out_loss: 4.6657 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4314 - out_loss: 4.6348 - rbf_fourier_loss: 4.2280 - val_loss: 4.4449 - val_out_loss: 4.6658 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4153 - out_loss: 4.6050 - rbf_fourier_loss: 4.2255 - val_loss: 4.4449 - val_out_loss: 4.6657 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4158 - out_loss: 4.6035 - rbf_fourier_loss: 4.2281 - val_loss: 4.4441 - val_out_loss: 4.6641 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4283 - out_loss: 4.6284 - rbf_fourier_loss: 4.2282 - val_loss: 4.4463 - val_out_loss: 4.6685 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4266 - out_loss: 4.6269 - rbf_fourier_loss: 4.2264 - val_loss: 4.4470 - val_out_loss: 4.6699 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4245 - out_loss: 4.6250 - rbf_fourier_loss: 4.2241 - val_loss: 4.4477 - val_out_loss: 4.6712 - val_rbf_fourier_loss: 4.2241\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4107 - out_loss: 4.5972 - rbf_fourier_loss: 4.2241 - val_loss: 4.4449 - val_out_loss: 4.6658 - val_rbf_fourier_loss: 4.2241\n",
            "it 1/10\n",
            "acc: 11.26\n",
            "ari: 0.00484616031513153\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 20ms/step - loss: 4.9739 - out_loss: 5.7366 - rbf_fourier_loss: 4.2112 - val_loss: 4.9498 - val_out_loss: 5.6804 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9610 - out_loss: 5.7110 - rbf_fourier_loss: 4.2110 - val_loss: 4.9533 - val_out_loss: 5.6874 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9697 - out_loss: 5.7289 - rbf_fourier_loss: 4.2105 - val_loss: 4.9553 - val_out_loss: 5.6914 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9658 - out_loss: 5.7212 - rbf_fourier_loss: 4.2104 - val_loss: 4.9587 - val_out_loss: 5.6983 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9530 - out_loss: 5.6959 - rbf_fourier_loss: 4.2101 - val_loss: 4.9611 - val_out_loss: 5.7031 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9561 - out_loss: 5.7007 - rbf_fourier_loss: 4.2115 - val_loss: 4.9555 - val_out_loss: 5.6918 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9416 - out_loss: 5.6736 - rbf_fourier_loss: 4.2096 - val_loss: 4.9561 - val_out_loss: 5.6930 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9483 - out_loss: 5.6859 - rbf_fourier_loss: 4.2107 - val_loss: 4.9527 - val_out_loss: 5.6862 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9612 - out_loss: 5.7112 - rbf_fourier_loss: 4.2112 - val_loss: 4.9559 - val_out_loss: 5.6926 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9466 - out_loss: 5.6808 - rbf_fourier_loss: 4.2125 - val_loss: 4.9572 - val_out_loss: 5.6952 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9539 - out_loss: 5.6981 - rbf_fourier_loss: 4.2096 - val_loss: 4.9538 - val_out_loss: 5.6884 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9578 - out_loss: 5.7042 - rbf_fourier_loss: 4.2115 - val_loss: 4.9522 - val_out_loss: 5.6852 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9555 - out_loss: 5.7022 - rbf_fourier_loss: 4.2088 - val_loss: 4.9523 - val_out_loss: 5.6853 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9420 - out_loss: 5.6745 - rbf_fourier_loss: 4.2095 - val_loss: 4.9489 - val_out_loss: 5.6786 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9465 - out_loss: 5.6826 - rbf_fourier_loss: 4.2103 - val_loss: 4.9490 - val_out_loss: 5.6787 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9518 - out_loss: 5.6927 - rbf_fourier_loss: 4.2109 - val_loss: 4.9521 - val_out_loss: 5.6849 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9558 - out_loss: 5.7011 - rbf_fourier_loss: 4.2104 - val_loss: 4.9543 - val_out_loss: 5.6893 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9457 - out_loss: 5.6824 - rbf_fourier_loss: 4.2090 - val_loss: 4.9543 - val_out_loss: 5.6894 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9428 - out_loss: 5.6740 - rbf_fourier_loss: 4.2117 - val_loss: 4.9541 - val_out_loss: 5.6890 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9448 - out_loss: 5.6784 - rbf_fourier_loss: 4.2113 - val_loss: 4.9573 - val_out_loss: 5.6954 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9515 - out_loss: 5.6917 - rbf_fourier_loss: 4.2112 - val_loss: 4.9618 - val_out_loss: 5.7044 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.9301 - out_loss: 5.6479 - rbf_fourier_loss: 4.2123 - val_loss: 4.9642 - val_out_loss: 5.7091 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9419 - out_loss: 5.6739 - rbf_fourier_loss: 4.2099 - val_loss: 4.9613 - val_out_loss: 5.7033 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9429 - out_loss: 5.6713 - rbf_fourier_loss: 4.2145 - val_loss: 4.9577 - val_out_loss: 5.6962 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9474 - out_loss: 5.6831 - rbf_fourier_loss: 4.2118 - val_loss: 4.9530 - val_out_loss: 5.6868 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9457 - out_loss: 5.6807 - rbf_fourier_loss: 4.2107 - val_loss: 4.9487 - val_out_loss: 5.6782 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9245 - out_loss: 5.6381 - rbf_fourier_loss: 4.2108 - val_loss: 4.9491 - val_out_loss: 5.6789 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9459 - out_loss: 5.6795 - rbf_fourier_loss: 4.2122 - val_loss: 4.9503 - val_out_loss: 5.6813 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9408 - out_loss: 5.6709 - rbf_fourier_loss: 4.2107 - val_loss: 4.9476 - val_out_loss: 5.6760 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9437 - out_loss: 5.6783 - rbf_fourier_loss: 4.2092 - val_loss: 4.9493 - val_out_loss: 5.6794 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9387 - out_loss: 5.6674 - rbf_fourier_loss: 4.2099 - val_loss: 4.9465 - val_out_loss: 5.6737 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9384 - out_loss: 5.6686 - rbf_fourier_loss: 4.2083 - val_loss: 4.9454 - val_out_loss: 5.6715 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9435 - out_loss: 5.6772 - rbf_fourier_loss: 4.2098 - val_loss: 4.9457 - val_out_loss: 5.6721 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9539 - out_loss: 5.6957 - rbf_fourier_loss: 4.2120 - val_loss: 4.9471 - val_out_loss: 5.6749 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9464 - out_loss: 5.6818 - rbf_fourier_loss: 4.2110 - val_loss: 4.9484 - val_out_loss: 5.6776 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9464 - out_loss: 5.6814 - rbf_fourier_loss: 4.2114 - val_loss: 4.9509 - val_out_loss: 5.6826 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9374 - out_loss: 5.6623 - rbf_fourier_loss: 4.2124 - val_loss: 4.9457 - val_out_loss: 5.6721 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9369 - out_loss: 5.6628 - rbf_fourier_loss: 4.2109 - val_loss: 4.9438 - val_out_loss: 5.6684 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9170 - out_loss: 5.6242 - rbf_fourier_loss: 4.2098 - val_loss: 4.9432 - val_out_loss: 5.6672 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9313 - out_loss: 5.6501 - rbf_fourier_loss: 4.2125 - val_loss: 4.9438 - val_out_loss: 5.6684 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9302 - out_loss: 5.6488 - rbf_fourier_loss: 4.2115 - val_loss: 4.9404 - val_out_loss: 5.6616 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9300 - out_loss: 5.6472 - rbf_fourier_loss: 4.2127 - val_loss: 4.9401 - val_out_loss: 5.6610 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9312 - out_loss: 5.6523 - rbf_fourier_loss: 4.2102 - val_loss: 4.9406 - val_out_loss: 5.6621 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9227 - out_loss: 5.6345 - rbf_fourier_loss: 4.2108 - val_loss: 4.9374 - val_out_loss: 5.6556 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9224 - out_loss: 5.6335 - rbf_fourier_loss: 4.2113 - val_loss: 4.9354 - val_out_loss: 5.6516 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9309 - out_loss: 5.6512 - rbf_fourier_loss: 4.2106 - val_loss: 4.9356 - val_out_loss: 5.6520 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9333 - out_loss: 5.6562 - rbf_fourier_loss: 4.2105 - val_loss: 4.9383 - val_out_loss: 5.6573 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9459 - out_loss: 5.6800 - rbf_fourier_loss: 4.2118 - val_loss: 4.9399 - val_out_loss: 5.6605 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9287 - out_loss: 5.6470 - rbf_fourier_loss: 4.2104 - val_loss: 4.9365 - val_out_loss: 5.6539 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9296 - out_loss: 5.6462 - rbf_fourier_loss: 4.2130 - val_loss: 4.9373 - val_out_loss: 5.6554 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9265 - out_loss: 5.6415 - rbf_fourier_loss: 4.2115 - val_loss: 4.9387 - val_out_loss: 5.6583 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9244 - out_loss: 5.6356 - rbf_fourier_loss: 4.2131 - val_loss: 4.9460 - val_out_loss: 5.6728 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9245 - out_loss: 5.6375 - rbf_fourier_loss: 4.2115 - val_loss: 4.9452 - val_out_loss: 5.6713 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9357 - out_loss: 5.6636 - rbf_fourier_loss: 4.2078 - val_loss: 4.9453 - val_out_loss: 5.6713 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9273 - out_loss: 5.6442 - rbf_fourier_loss: 4.2105 - val_loss: 4.9438 - val_out_loss: 5.6683 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9305 - out_loss: 5.6493 - rbf_fourier_loss: 4.2117 - val_loss: 4.9448 - val_out_loss: 5.6703 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9370 - out_loss: 5.6639 - rbf_fourier_loss: 4.2100 - val_loss: 4.9416 - val_out_loss: 5.6639 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9393 - out_loss: 5.6685 - rbf_fourier_loss: 4.2102 - val_loss: 4.9392 - val_out_loss: 5.6592 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9243 - out_loss: 5.6366 - rbf_fourier_loss: 4.2121 - val_loss: 4.9411 - val_out_loss: 5.6631 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9311 - out_loss: 5.6514 - rbf_fourier_loss: 4.2108 - val_loss: 4.9429 - val_out_loss: 5.6665 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9345 - out_loss: 5.6580 - rbf_fourier_loss: 4.2111 - val_loss: 4.9449 - val_out_loss: 5.6705 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9359 - out_loss: 5.6599 - rbf_fourier_loss: 4.2118 - val_loss: 4.9413 - val_out_loss: 5.6634 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9145 - out_loss: 5.6206 - rbf_fourier_loss: 4.2085 - val_loss: 4.9392 - val_out_loss: 5.6591 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9307 - out_loss: 5.6501 - rbf_fourier_loss: 4.2112 - val_loss: 4.9381 - val_out_loss: 5.6570 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9157 - out_loss: 5.6208 - rbf_fourier_loss: 4.2105 - val_loss: 4.9414 - val_out_loss: 5.6637 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9326 - out_loss: 5.6535 - rbf_fourier_loss: 4.2116 - val_loss: 4.9445 - val_out_loss: 5.6698 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9301 - out_loss: 5.6502 - rbf_fourier_loss: 4.2100 - val_loss: 4.9457 - val_out_loss: 5.6722 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9109 - out_loss: 5.6116 - rbf_fourier_loss: 4.2103 - val_loss: 4.9455 - val_out_loss: 5.6718 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9220 - out_loss: 5.6364 - rbf_fourier_loss: 4.2075 - val_loss: 4.9470 - val_out_loss: 5.6748 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9244 - out_loss: 5.6384 - rbf_fourier_loss: 4.2104 - val_loss: 4.9487 - val_out_loss: 5.6783 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9254 - out_loss: 5.6404 - rbf_fourier_loss: 4.2103 - val_loss: 4.9472 - val_out_loss: 5.6753 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9182 - out_loss: 5.6252 - rbf_fourier_loss: 4.2112 - val_loss: 4.9488 - val_out_loss: 5.6783 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9146 - out_loss: 5.6191 - rbf_fourier_loss: 4.2101 - val_loss: 4.9465 - val_out_loss: 5.6738 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9191 - out_loss: 5.6265 - rbf_fourier_loss: 4.2118 - val_loss: 4.9413 - val_out_loss: 5.6635 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9231 - out_loss: 5.6358 - rbf_fourier_loss: 4.2104 - val_loss: 4.9391 - val_out_loss: 5.6591 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9147 - out_loss: 5.6202 - rbf_fourier_loss: 4.2092 - val_loss: 4.9400 - val_out_loss: 5.6607 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9107 - out_loss: 5.6118 - rbf_fourier_loss: 4.2097 - val_loss: 4.9396 - val_out_loss: 5.6599 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9195 - out_loss: 5.6295 - rbf_fourier_loss: 4.2095 - val_loss: 4.9370 - val_out_loss: 5.6548 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9140 - out_loss: 5.6167 - rbf_fourier_loss: 4.2113 - val_loss: 4.9364 - val_out_loss: 5.6535 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9105 - out_loss: 5.6089 - rbf_fourier_loss: 4.2120 - val_loss: 4.9394 - val_out_loss: 5.6596 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9158 - out_loss: 5.6207 - rbf_fourier_loss: 4.2110 - val_loss: 4.9398 - val_out_loss: 5.6604 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9226 - out_loss: 5.6338 - rbf_fourier_loss: 4.2115 - val_loss: 4.9396 - val_out_loss: 5.6599 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9180 - out_loss: 5.6255 - rbf_fourier_loss: 4.2105 - val_loss: 4.9385 - val_out_loss: 5.6579 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9259 - out_loss: 5.6429 - rbf_fourier_loss: 4.2089 - val_loss: 4.9421 - val_out_loss: 5.6649 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9168 - out_loss: 5.6212 - rbf_fourier_loss: 4.2124 - val_loss: 4.9396 - val_out_loss: 5.6600 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9136 - out_loss: 5.6156 - rbf_fourier_loss: 4.2116 - val_loss: 4.9398 - val_out_loss: 5.6604 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.9088 - out_loss: 5.6071 - rbf_fourier_loss: 4.2105 - val_loss: 4.9404 - val_out_loss: 5.6615 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9172 - out_loss: 5.6221 - rbf_fourier_loss: 4.2124 - val_loss: 4.9423 - val_out_loss: 5.6653 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9098 - out_loss: 5.6085 - rbf_fourier_loss: 4.2111 - val_loss: 4.9415 - val_out_loss: 5.6638 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9149 - out_loss: 5.6191 - rbf_fourier_loss: 4.2107 - val_loss: 4.9414 - val_out_loss: 5.6635 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9114 - out_loss: 5.6086 - rbf_fourier_loss: 4.2142 - val_loss: 4.9401 - val_out_loss: 5.6611 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9184 - out_loss: 5.6252 - rbf_fourier_loss: 4.2116 - val_loss: 4.9397 - val_out_loss: 5.6603 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9195 - out_loss: 5.6262 - rbf_fourier_loss: 4.2128 - val_loss: 4.9375 - val_out_loss: 5.6558 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9177 - out_loss: 5.6263 - rbf_fourier_loss: 4.2090 - val_loss: 4.9338 - val_out_loss: 5.6484 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9238 - out_loss: 5.6376 - rbf_fourier_loss: 4.2100 - val_loss: 4.9357 - val_out_loss: 5.6522 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9158 - out_loss: 5.6199 - rbf_fourier_loss: 4.2117 - val_loss: 4.9396 - val_out_loss: 5.6599 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9167 - out_loss: 5.6194 - rbf_fourier_loss: 4.2140 - val_loss: 4.9425 - val_out_loss: 5.6659 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9103 - out_loss: 5.6106 - rbf_fourier_loss: 4.2100 - val_loss: 4.9399 - val_out_loss: 5.6606 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9146 - out_loss: 5.6191 - rbf_fourier_loss: 4.2101 - val_loss: 4.9414 - val_out_loss: 5.6636 - val_rbf_fourier_loss: 4.2192\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9084 - out_loss: 5.6074 - rbf_fourier_loss: 4.2093 - val_loss: 4.9396 - val_out_loss: 5.6600 - val_rbf_fourier_loss: 4.2192\n",
            "it 1/10\n",
            "acc: 12.370000000000001\n",
            "ari: 0.16418848236819195\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 1.9560 - out_loss: 2.2754 - rbf_fourier_loss: 1.6366 - val_loss: 1.9555 - val_out_loss: 2.2763 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9534 - out_loss: 2.2704 - rbf_fourier_loss: 1.6364 - val_loss: 1.9534 - val_out_loss: 2.2722 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9538 - out_loss: 2.2710 - rbf_fourier_loss: 1.6365 - val_loss: 1.9520 - val_out_loss: 2.2694 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9559 - out_loss: 2.2754 - rbf_fourier_loss: 1.6365 - val_loss: 1.9501 - val_out_loss: 2.2657 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9579 - out_loss: 2.2793 - rbf_fourier_loss: 1.6365 - val_loss: 1.9541 - val_out_loss: 2.2736 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9596 - out_loss: 2.2831 - rbf_fourier_loss: 1.6362 - val_loss: 1.9534 - val_out_loss: 2.2722 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9530 - out_loss: 2.2695 - rbf_fourier_loss: 1.6366 - val_loss: 1.9522 - val_out_loss: 2.2698 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9532 - out_loss: 2.2697 - rbf_fourier_loss: 1.6366 - val_loss: 1.9546 - val_out_loss: 2.2746 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9556 - out_loss: 2.2750 - rbf_fourier_loss: 1.6362 - val_loss: 1.9530 - val_out_loss: 2.2715 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9492 - out_loss: 2.2622 - rbf_fourier_loss: 1.6363 - val_loss: 1.9527 - val_out_loss: 2.2708 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9534 - out_loss: 2.2703 - rbf_fourier_loss: 1.6365 - val_loss: 1.9510 - val_out_loss: 2.2674 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9503 - out_loss: 2.2640 - rbf_fourier_loss: 1.6366 - val_loss: 1.9518 - val_out_loss: 2.2690 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9494 - out_loss: 2.2624 - rbf_fourier_loss: 1.6365 - val_loss: 1.9537 - val_out_loss: 2.2727 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9518 - out_loss: 2.2671 - rbf_fourier_loss: 1.6366 - val_loss: 1.9510 - val_out_loss: 2.2673 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9509 - out_loss: 2.2654 - rbf_fourier_loss: 1.6365 - val_loss: 1.9519 - val_out_loss: 2.2692 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9536 - out_loss: 2.2705 - rbf_fourier_loss: 1.6366 - val_loss: 1.9485 - val_out_loss: 2.2625 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9486 - out_loss: 2.2604 - rbf_fourier_loss: 1.6368 - val_loss: 1.9480 - val_out_loss: 2.2615 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9554 - out_loss: 2.2742 - rbf_fourier_loss: 1.6366 - val_loss: 1.9476 - val_out_loss: 2.2606 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9561 - out_loss: 2.2756 - rbf_fourier_loss: 1.6365 - val_loss: 1.9497 - val_out_loss: 2.2649 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9520 - out_loss: 2.2677 - rbf_fourier_loss: 1.6364 - val_loss: 1.9535 - val_out_loss: 2.2725 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9553 - out_loss: 2.2743 - rbf_fourier_loss: 1.6363 - val_loss: 1.9554 - val_out_loss: 2.2762 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9453 - out_loss: 2.2540 - rbf_fourier_loss: 1.6367 - val_loss: 1.9556 - val_out_loss: 2.2767 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9469 - out_loss: 2.2573 - rbf_fourier_loss: 1.6366 - val_loss: 1.9567 - val_out_loss: 2.2789 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9484 - out_loss: 2.2604 - rbf_fourier_loss: 1.6363 - val_loss: 1.9559 - val_out_loss: 2.2773 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9475 - out_loss: 2.2584 - rbf_fourier_loss: 1.6365 - val_loss: 1.9531 - val_out_loss: 2.2716 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9526 - out_loss: 2.2686 - rbf_fourier_loss: 1.6365 - val_loss: 1.9508 - val_out_loss: 2.2669 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9550 - out_loss: 2.2731 - rbf_fourier_loss: 1.6369 - val_loss: 1.9545 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9515 - out_loss: 2.2665 - rbf_fourier_loss: 1.6364 - val_loss: 1.9544 - val_out_loss: 2.2741 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9499 - out_loss: 2.2632 - rbf_fourier_loss: 1.6365 - val_loss: 1.9533 - val_out_loss: 2.2720 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9406 - out_loss: 2.2445 - rbf_fourier_loss: 1.6366 - val_loss: 1.9536 - val_out_loss: 2.2726 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9489 - out_loss: 2.2615 - rbf_fourier_loss: 1.6364 - val_loss: 1.9523 - val_out_loss: 2.2699 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9453 - out_loss: 2.2542 - rbf_fourier_loss: 1.6365 - val_loss: 1.9498 - val_out_loss: 2.2650 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9493 - out_loss: 2.2620 - rbf_fourier_loss: 1.6366 - val_loss: 1.9508 - val_out_loss: 2.2671 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9468 - out_loss: 2.2572 - rbf_fourier_loss: 1.6365 - val_loss: 1.9505 - val_out_loss: 2.2664 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9589 - out_loss: 2.2812 - rbf_fourier_loss: 1.6367 - val_loss: 1.9517 - val_out_loss: 2.2688 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9460 - out_loss: 2.2556 - rbf_fourier_loss: 1.6364 - val_loss: 1.9487 - val_out_loss: 2.2628 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9508 - out_loss: 2.2651 - rbf_fourier_loss: 1.6366 - val_loss: 1.9471 - val_out_loss: 2.2596 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9500 - out_loss: 2.2636 - rbf_fourier_loss: 1.6364 - val_loss: 1.9490 - val_out_loss: 2.2635 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9578 - out_loss: 2.2789 - rbf_fourier_loss: 1.6367 - val_loss: 1.9476 - val_out_loss: 2.2607 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9470 - out_loss: 2.2574 - rbf_fourier_loss: 1.6367 - val_loss: 1.9473 - val_out_loss: 2.2599 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9472 - out_loss: 2.2579 - rbf_fourier_loss: 1.6365 - val_loss: 1.9467 - val_out_loss: 2.2588 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9502 - out_loss: 2.2641 - rbf_fourier_loss: 1.6363 - val_loss: 1.9449 - val_out_loss: 2.2553 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9473 - out_loss: 2.2580 - rbf_fourier_loss: 1.6365 - val_loss: 1.9483 - val_out_loss: 2.2620 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9461 - out_loss: 2.2555 - rbf_fourier_loss: 1.6367 - val_loss: 1.9472 - val_out_loss: 2.2598 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9424 - out_loss: 2.2484 - rbf_fourier_loss: 1.6363 - val_loss: 1.9467 - val_out_loss: 2.2588 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9393 - out_loss: 2.2420 - rbf_fourier_loss: 1.6366 - val_loss: 1.9458 - val_out_loss: 2.2571 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9508 - out_loss: 2.2650 - rbf_fourier_loss: 1.6366 - val_loss: 1.9481 - val_out_loss: 2.2616 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9393 - out_loss: 2.2421 - rbf_fourier_loss: 1.6366 - val_loss: 1.9503 - val_out_loss: 2.2660 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9449 - out_loss: 2.2533 - rbf_fourier_loss: 1.6365 - val_loss: 1.9526 - val_out_loss: 2.2706 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9417 - out_loss: 2.2468 - rbf_fourier_loss: 1.6366 - val_loss: 1.9523 - val_out_loss: 2.2700 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9493 - out_loss: 2.2622 - rbf_fourier_loss: 1.6365 - val_loss: 1.9524 - val_out_loss: 2.2703 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9390 - out_loss: 2.2415 - rbf_fourier_loss: 1.6364 - val_loss: 1.9493 - val_out_loss: 2.2640 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9489 - out_loss: 2.2614 - rbf_fourier_loss: 1.6364 - val_loss: 1.9538 - val_out_loss: 2.2730 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9530 - out_loss: 2.2697 - rbf_fourier_loss: 1.6363 - val_loss: 1.9536 - val_out_loss: 2.2727 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9381 - out_loss: 2.2394 - rbf_fourier_loss: 1.6367 - val_loss: 1.9547 - val_out_loss: 2.2748 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9457 - out_loss: 2.2552 - rbf_fourier_loss: 1.6363 - val_loss: 1.9537 - val_out_loss: 2.2728 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9390 - out_loss: 2.2413 - rbf_fourier_loss: 1.6366 - val_loss: 1.9530 - val_out_loss: 2.2715 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9341 - out_loss: 2.2318 - rbf_fourier_loss: 1.6365 - val_loss: 1.9534 - val_out_loss: 2.2723 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9460 - out_loss: 2.2557 - rbf_fourier_loss: 1.6363 - val_loss: 1.9532 - val_out_loss: 2.2717 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9455 - out_loss: 2.2543 - rbf_fourier_loss: 1.6366 - val_loss: 1.9496 - val_out_loss: 2.2647 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9458 - out_loss: 2.2548 - rbf_fourier_loss: 1.6368 - val_loss: 1.9483 - val_out_loss: 2.2621 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9416 - out_loss: 2.2468 - rbf_fourier_loss: 1.6364 - val_loss: 1.9505 - val_out_loss: 2.2665 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9385 - out_loss: 2.2404 - rbf_fourier_loss: 1.6366 - val_loss: 1.9533 - val_out_loss: 2.2721 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9386 - out_loss: 2.2405 - rbf_fourier_loss: 1.6366 - val_loss: 1.9520 - val_out_loss: 2.2694 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9425 - out_loss: 2.2486 - rbf_fourier_loss: 1.6365 - val_loss: 1.9539 - val_out_loss: 2.2732 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9430 - out_loss: 2.2497 - rbf_fourier_loss: 1.6363 - val_loss: 1.9530 - val_out_loss: 2.2714 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9356 - out_loss: 2.2348 - rbf_fourier_loss: 1.6364 - val_loss: 1.9544 - val_out_loss: 2.2742 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9354 - out_loss: 2.2341 - rbf_fourier_loss: 1.6367 - val_loss: 1.9545 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9317 - out_loss: 2.2272 - rbf_fourier_loss: 1.6363 - val_loss: 1.9524 - val_out_loss: 2.2703 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9335 - out_loss: 2.2305 - rbf_fourier_loss: 1.6366 - val_loss: 1.9546 - val_out_loss: 2.2746 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9371 - out_loss: 2.2377 - rbf_fourier_loss: 1.6364 - val_loss: 1.9551 - val_out_loss: 2.2757 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9337 - out_loss: 2.2308 - rbf_fourier_loss: 1.6365 - val_loss: 1.9553 - val_out_loss: 2.2760 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9363 - out_loss: 2.2361 - rbf_fourier_loss: 1.6364 - val_loss: 1.9563 - val_out_loss: 2.2780 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9332 - out_loss: 2.2299 - rbf_fourier_loss: 1.6365 - val_loss: 1.9546 - val_out_loss: 2.2746 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9426 - out_loss: 2.2489 - rbf_fourier_loss: 1.6363 - val_loss: 1.9524 - val_out_loss: 2.2703 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9450 - out_loss: 2.2535 - rbf_fourier_loss: 1.6364 - val_loss: 1.9525 - val_out_loss: 2.2705 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9372 - out_loss: 2.2379 - rbf_fourier_loss: 1.6365 - val_loss: 1.9525 - val_out_loss: 2.2704 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9397 - out_loss: 2.2428 - rbf_fourier_loss: 1.6366 - val_loss: 1.9542 - val_out_loss: 2.2739 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9392 - out_loss: 2.2420 - rbf_fourier_loss: 1.6365 - val_loss: 1.9550 - val_out_loss: 2.2755 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9334 - out_loss: 2.2301 - rbf_fourier_loss: 1.6366 - val_loss: 1.9586 - val_out_loss: 2.2826 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9406 - out_loss: 2.2446 - rbf_fourier_loss: 1.6365 - val_loss: 1.9571 - val_out_loss: 2.2796 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9341 - out_loss: 2.2316 - rbf_fourier_loss: 1.6365 - val_loss: 1.9557 - val_out_loss: 2.2767 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9369 - out_loss: 2.2375 - rbf_fourier_loss: 1.6364 - val_loss: 1.9545 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9306 - out_loss: 2.2248 - rbf_fourier_loss: 1.6363 - val_loss: 1.9562 - val_out_loss: 2.2777 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9373 - out_loss: 2.2383 - rbf_fourier_loss: 1.6364 - val_loss: 1.9549 - val_out_loss: 2.2752 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9368 - out_loss: 2.2371 - rbf_fourier_loss: 1.6366 - val_loss: 1.9565 - val_out_loss: 2.2784 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9325 - out_loss: 2.2281 - rbf_fourier_loss: 1.6368 - val_loss: 1.9590 - val_out_loss: 2.2834 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9400 - out_loss: 2.2435 - rbf_fourier_loss: 1.6364 - val_loss: 1.9572 - val_out_loss: 2.2798 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9371 - out_loss: 2.2378 - rbf_fourier_loss: 1.6364 - val_loss: 1.9551 - val_out_loss: 2.2757 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9467 - out_loss: 2.2570 - rbf_fourier_loss: 1.6363 - val_loss: 1.9508 - val_out_loss: 2.2670 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9351 - out_loss: 2.2334 - rbf_fourier_loss: 1.6369 - val_loss: 1.9521 - val_out_loss: 2.2696 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9312 - out_loss: 2.2261 - rbf_fourier_loss: 1.6364 - val_loss: 1.9520 - val_out_loss: 2.2695 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9372 - out_loss: 2.2380 - rbf_fourier_loss: 1.6365 - val_loss: 1.9536 - val_out_loss: 2.2726 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9357 - out_loss: 2.2348 - rbf_fourier_loss: 1.6365 - val_loss: 1.9525 - val_out_loss: 2.2704 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9325 - out_loss: 2.2284 - rbf_fourier_loss: 1.6367 - val_loss: 1.9537 - val_out_loss: 2.2728 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9305 - out_loss: 2.2244 - rbf_fourier_loss: 1.6367 - val_loss: 1.9518 - val_out_loss: 2.2690 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9423 - out_loss: 2.2482 - rbf_fourier_loss: 1.6364 - val_loss: 1.9547 - val_out_loss: 2.2747 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9289 - out_loss: 2.2213 - rbf_fourier_loss: 1.6365 - val_loss: 1.9571 - val_out_loss: 2.2795 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9378 - out_loss: 2.2392 - rbf_fourier_loss: 1.6364 - val_loss: 1.9570 - val_out_loss: 2.2794 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9395 - out_loss: 2.2427 - rbf_fourier_loss: 1.6363 - val_loss: 1.9564 - val_out_loss: 2.2782 - val_rbf_fourier_loss: 1.6346\n",
            "it 1/10\n",
            "acc: 11.338333333333333\n",
            "ari: 0.003864992794632605\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 1.9483 - out_loss: 2.2613 - rbf_fourier_loss: 1.6353 - val_loss: 1.9503 - val_out_loss: 2.2670 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9510 - out_loss: 2.2664 - rbf_fourier_loss: 1.6356 - val_loss: 1.9493 - val_out_loss: 2.2650 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2599 - rbf_fourier_loss: 1.6353 - val_loss: 1.9507 - val_out_loss: 2.2680 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9541 - out_loss: 2.2728 - rbf_fourier_loss: 1.6354 - val_loss: 1.9490 - val_out_loss: 2.2645 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9633 - out_loss: 2.2913 - rbf_fourier_loss: 1.6354 - val_loss: 1.9480 - val_out_loss: 2.2625 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9491 - out_loss: 2.2630 - rbf_fourier_loss: 1.6351 - val_loss: 1.9484 - val_out_loss: 2.2633 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9497 - out_loss: 2.2642 - rbf_fourier_loss: 1.6353 - val_loss: 1.9475 - val_out_loss: 2.2615 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9510 - out_loss: 2.2666 - rbf_fourier_loss: 1.6354 - val_loss: 1.9490 - val_out_loss: 2.2644 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9486 - out_loss: 2.2620 - rbf_fourier_loss: 1.6351 - val_loss: 1.9483 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9556 - out_loss: 2.2757 - rbf_fourier_loss: 1.6355 - val_loss: 1.9495 - val_out_loss: 2.2656 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9534 - out_loss: 2.2713 - rbf_fourier_loss: 1.6355 - val_loss: 1.9504 - val_out_loss: 2.2672 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9572 - out_loss: 2.2791 - rbf_fourier_loss: 1.6354 - val_loss: 1.9518 - val_out_loss: 2.2700 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9526 - out_loss: 2.2699 - rbf_fourier_loss: 1.6353 - val_loss: 1.9500 - val_out_loss: 2.2665 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2598 - rbf_fourier_loss: 1.6355 - val_loss: 1.9483 - val_out_loss: 2.2631 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9477 - out_loss: 2.2599 - rbf_fourier_loss: 1.6354 - val_loss: 1.9492 - val_out_loss: 2.2648 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9460 - out_loss: 2.2565 - rbf_fourier_loss: 1.6355 - val_loss: 1.9505 - val_out_loss: 2.2675 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9528 - out_loss: 2.2702 - rbf_fourier_loss: 1.6355 - val_loss: 1.9505 - val_out_loss: 2.2674 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9515 - out_loss: 2.2676 - rbf_fourier_loss: 1.6354 - val_loss: 1.9505 - val_out_loss: 2.2676 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9412 - out_loss: 2.2471 - rbf_fourier_loss: 1.6353 - val_loss: 1.9496 - val_out_loss: 2.2657 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9496 - out_loss: 2.2639 - rbf_fourier_loss: 1.6354 - val_loss: 1.9505 - val_out_loss: 2.2674 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9560 - out_loss: 2.2765 - rbf_fourier_loss: 1.6354 - val_loss: 1.9522 - val_out_loss: 2.2710 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9481 - out_loss: 2.2609 - rbf_fourier_loss: 1.6354 - val_loss: 1.9517 - val_out_loss: 2.2699 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9584 - out_loss: 2.2813 - rbf_fourier_loss: 1.6354 - val_loss: 1.9519 - val_out_loss: 2.2703 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9484 - out_loss: 2.2613 - rbf_fourier_loss: 1.6355 - val_loss: 1.9530 - val_out_loss: 2.2725 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9517 - out_loss: 2.2680 - rbf_fourier_loss: 1.6353 - val_loss: 1.9542 - val_out_loss: 2.2749 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9540 - out_loss: 2.2726 - rbf_fourier_loss: 1.6354 - val_loss: 1.9562 - val_out_loss: 2.2790 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9483 - out_loss: 2.2613 - rbf_fourier_loss: 1.6352 - val_loss: 1.9553 - val_out_loss: 2.2771 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9472 - out_loss: 2.2591 - rbf_fourier_loss: 1.6354 - val_loss: 1.9531 - val_out_loss: 2.2728 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9464 - out_loss: 2.2576 - rbf_fourier_loss: 1.6353 - val_loss: 1.9488 - val_out_loss: 2.2640 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9489 - out_loss: 2.2624 - rbf_fourier_loss: 1.6354 - val_loss: 1.9508 - val_out_loss: 2.2681 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9474 - out_loss: 2.2594 - rbf_fourier_loss: 1.6354 - val_loss: 1.9531 - val_out_loss: 2.2728 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9429 - out_loss: 2.2504 - rbf_fourier_loss: 1.6355 - val_loss: 1.9530 - val_out_loss: 2.2725 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9503 - out_loss: 2.2652 - rbf_fourier_loss: 1.6354 - val_loss: 1.9552 - val_out_loss: 2.2769 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9451 - out_loss: 2.2549 - rbf_fourier_loss: 1.6353 - val_loss: 1.9555 - val_out_loss: 2.2776 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9493 - out_loss: 2.2633 - rbf_fourier_loss: 1.6353 - val_loss: 1.9545 - val_out_loss: 2.2755 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9442 - out_loss: 2.2531 - rbf_fourier_loss: 1.6353 - val_loss: 1.9515 - val_out_loss: 2.2694 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9436 - out_loss: 2.2522 - rbf_fourier_loss: 1.6351 - val_loss: 1.9509 - val_out_loss: 2.2684 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9399 - out_loss: 2.2445 - rbf_fourier_loss: 1.6354 - val_loss: 1.9529 - val_out_loss: 2.2723 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9489 - out_loss: 2.2623 - rbf_fourier_loss: 1.6355 - val_loss: 1.9549 - val_out_loss: 2.2763 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9444 - out_loss: 2.2531 - rbf_fourier_loss: 1.6356 - val_loss: 1.9537 - val_out_loss: 2.2739 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9369 - out_loss: 2.2384 - rbf_fourier_loss: 1.6353 - val_loss: 1.9525 - val_out_loss: 2.2716 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9462 - out_loss: 2.2570 - rbf_fourier_loss: 1.6355 - val_loss: 1.9569 - val_out_loss: 2.2803 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9499 - out_loss: 2.2643 - rbf_fourier_loss: 1.6354 - val_loss: 1.9542 - val_out_loss: 2.2749 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9416 - out_loss: 2.2480 - rbf_fourier_loss: 1.6352 - val_loss: 1.9537 - val_out_loss: 2.2738 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9451 - out_loss: 2.2550 - rbf_fourier_loss: 1.6352 - val_loss: 1.9547 - val_out_loss: 2.2759 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9395 - out_loss: 2.2436 - rbf_fourier_loss: 1.6355 - val_loss: 1.9544 - val_out_loss: 2.2754 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9373 - out_loss: 2.2393 - rbf_fourier_loss: 1.6353 - val_loss: 1.9542 - val_out_loss: 2.2750 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9418 - out_loss: 2.2483 - rbf_fourier_loss: 1.6353 - val_loss: 1.9548 - val_out_loss: 2.2762 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9439 - out_loss: 2.2523 - rbf_fourier_loss: 1.6354 - val_loss: 1.9552 - val_out_loss: 2.2770 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9448 - out_loss: 2.2541 - rbf_fourier_loss: 1.6354 - val_loss: 1.9539 - val_out_loss: 2.2743 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9318 - out_loss: 2.2281 - rbf_fourier_loss: 1.6355 - val_loss: 1.9537 - val_out_loss: 2.2740 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9402 - out_loss: 2.2452 - rbf_fourier_loss: 1.6352 - val_loss: 1.9533 - val_out_loss: 2.2730 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9389 - out_loss: 2.2422 - rbf_fourier_loss: 1.6355 - val_loss: 1.9508 - val_out_loss: 2.2682 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9470 - out_loss: 2.2586 - rbf_fourier_loss: 1.6353 - val_loss: 1.9515 - val_out_loss: 2.2694 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9414 - out_loss: 2.2476 - rbf_fourier_loss: 1.6352 - val_loss: 1.9509 - val_out_loss: 2.2684 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9357 - out_loss: 2.2361 - rbf_fourier_loss: 1.6354 - val_loss: 1.9502 - val_out_loss: 2.2670 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9367 - out_loss: 2.2377 - rbf_fourier_loss: 1.6356 - val_loss: 1.9508 - val_out_loss: 2.2681 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9368 - out_loss: 2.2386 - rbf_fourier_loss: 1.6351 - val_loss: 1.9546 - val_out_loss: 2.2758 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9385 - out_loss: 2.2417 - rbf_fourier_loss: 1.6354 - val_loss: 1.9547 - val_out_loss: 2.2759 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9381 - out_loss: 2.2410 - rbf_fourier_loss: 1.6352 - val_loss: 1.9535 - val_out_loss: 2.2735 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9336 - out_loss: 2.2319 - rbf_fourier_loss: 1.6354 - val_loss: 1.9525 - val_out_loss: 2.2714 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9446 - out_loss: 2.2539 - rbf_fourier_loss: 1.6353 - val_loss: 1.9550 - val_out_loss: 2.2766 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9409 - out_loss: 2.2466 - rbf_fourier_loss: 1.6351 - val_loss: 1.9541 - val_out_loss: 2.2746 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9364 - out_loss: 2.2376 - rbf_fourier_loss: 1.6353 - val_loss: 1.9542 - val_out_loss: 2.2750 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9325 - out_loss: 2.2296 - rbf_fourier_loss: 1.6354 - val_loss: 1.9519 - val_out_loss: 2.2702 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9400 - out_loss: 2.2447 - rbf_fourier_loss: 1.6353 - val_loss: 1.9519 - val_out_loss: 2.2702 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9458 - out_loss: 2.2562 - rbf_fourier_loss: 1.6354 - val_loss: 1.9550 - val_out_loss: 2.2765 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9373 - out_loss: 2.2393 - rbf_fourier_loss: 1.6354 - val_loss: 1.9536 - val_out_loss: 2.2737 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9354 - out_loss: 2.2353 - rbf_fourier_loss: 1.6354 - val_loss: 1.9529 - val_out_loss: 2.2722 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9371 - out_loss: 2.2388 - rbf_fourier_loss: 1.6353 - val_loss: 1.9515 - val_out_loss: 2.2695 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9339 - out_loss: 2.2322 - rbf_fourier_loss: 1.6356 - val_loss: 1.9506 - val_out_loss: 2.2677 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9412 - out_loss: 2.2470 - rbf_fourier_loss: 1.6355 - val_loss: 1.9525 - val_out_loss: 2.2714 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9329 - out_loss: 2.2303 - rbf_fourier_loss: 1.6354 - val_loss: 1.9558 - val_out_loss: 2.2781 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9379 - out_loss: 2.2404 - rbf_fourier_loss: 1.6354 - val_loss: 1.9561 - val_out_loss: 2.2787 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9388 - out_loss: 2.2422 - rbf_fourier_loss: 1.6353 - val_loss: 1.9584 - val_out_loss: 2.2833 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9367 - out_loss: 2.2380 - rbf_fourier_loss: 1.6353 - val_loss: 1.9589 - val_out_loss: 2.2843 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9411 - out_loss: 2.2468 - rbf_fourier_loss: 1.6354 - val_loss: 1.9579 - val_out_loss: 2.2822 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9360 - out_loss: 2.2369 - rbf_fourier_loss: 1.6352 - val_loss: 1.9590 - val_out_loss: 2.2845 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9350 - out_loss: 2.2347 - rbf_fourier_loss: 1.6353 - val_loss: 1.9595 - val_out_loss: 2.2854 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9289 - out_loss: 2.2225 - rbf_fourier_loss: 1.6353 - val_loss: 1.9618 - val_out_loss: 2.2902 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9404 - out_loss: 2.2454 - rbf_fourier_loss: 1.6353 - val_loss: 1.9639 - val_out_loss: 2.2942 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9342 - out_loss: 2.2330 - rbf_fourier_loss: 1.6353 - val_loss: 1.9622 - val_out_loss: 2.2909 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9329 - out_loss: 2.2306 - rbf_fourier_loss: 1.6353 - val_loss: 1.9642 - val_out_loss: 2.2949 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9323 - out_loss: 2.2296 - rbf_fourier_loss: 1.6350 - val_loss: 1.9618 - val_out_loss: 2.2901 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9314 - out_loss: 2.2274 - rbf_fourier_loss: 1.6355 - val_loss: 1.9619 - val_out_loss: 2.2903 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9366 - out_loss: 2.2380 - rbf_fourier_loss: 1.6353 - val_loss: 1.9609 - val_out_loss: 2.2884 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9317 - out_loss: 2.2280 - rbf_fourier_loss: 1.6354 - val_loss: 1.9624 - val_out_loss: 2.2914 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9366 - out_loss: 2.2379 - rbf_fourier_loss: 1.6354 - val_loss: 1.9617 - val_out_loss: 2.2899 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9280 - out_loss: 2.2206 - rbf_fourier_loss: 1.6353 - val_loss: 1.9615 - val_out_loss: 2.2895 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9291 - out_loss: 2.2226 - rbf_fourier_loss: 1.6355 - val_loss: 1.9609 - val_out_loss: 2.2883 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9314 - out_loss: 2.2273 - rbf_fourier_loss: 1.6355 - val_loss: 1.9584 - val_out_loss: 2.2833 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9334 - out_loss: 2.2315 - rbf_fourier_loss: 1.6352 - val_loss: 1.9583 - val_out_loss: 2.2831 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9307 - out_loss: 2.2260 - rbf_fourier_loss: 1.6354 - val_loss: 1.9573 - val_out_loss: 2.2810 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9305 - out_loss: 2.2259 - rbf_fourier_loss: 1.6352 - val_loss: 1.9597 - val_out_loss: 2.2858 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9353 - out_loss: 2.2350 - rbf_fourier_loss: 1.6355 - val_loss: 1.9558 - val_out_loss: 2.2780 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9361 - out_loss: 2.2367 - rbf_fourier_loss: 1.6354 - val_loss: 1.9581 - val_out_loss: 2.2828 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9371 - out_loss: 2.2388 - rbf_fourier_loss: 1.6353 - val_loss: 1.9570 - val_out_loss: 2.2805 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9302 - out_loss: 2.2251 - rbf_fourier_loss: 1.6353 - val_loss: 1.9582 - val_out_loss: 2.2829 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9286 - out_loss: 2.2218 - rbf_fourier_loss: 1.6354 - val_loss: 1.9594 - val_out_loss: 2.2853 - val_rbf_fourier_loss: 1.6335\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9320 - out_loss: 2.2286 - rbf_fourier_loss: 1.6355 - val_loss: 1.9599 - val_out_loss: 2.2862 - val_rbf_fourier_loss: 1.6335\n",
            "it 1/10\n",
            "acc: 11.236666666666666\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 21ms/step - loss: 1.9603 - out_loss: 2.2853 - rbf_fourier_loss: 1.6354 - val_loss: 1.9546 - val_out_loss: 2.2757 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9537 - out_loss: 2.2721 - rbf_fourier_loss: 1.6353 - val_loss: 1.9512 - val_out_loss: 2.2688 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9470 - out_loss: 2.2587 - rbf_fourier_loss: 1.6352 - val_loss: 1.9524 - val_out_loss: 2.2712 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9517 - out_loss: 2.2681 - rbf_fourier_loss: 1.6353 - val_loss: 1.9523 - val_out_loss: 2.2709 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9547 - out_loss: 2.2742 - rbf_fourier_loss: 1.6352 - val_loss: 1.9533 - val_out_loss: 2.2730 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9558 - out_loss: 2.2761 - rbf_fourier_loss: 1.6355 - val_loss: 1.9515 - val_out_loss: 2.2694 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9502 - out_loss: 2.2651 - rbf_fourier_loss: 1.6353 - val_loss: 1.9514 - val_out_loss: 2.2693 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9512 - out_loss: 2.2674 - rbf_fourier_loss: 1.6351 - val_loss: 1.9512 - val_out_loss: 2.2688 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9488 - out_loss: 2.2625 - rbf_fourier_loss: 1.6351 - val_loss: 1.9500 - val_out_loss: 2.2664 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9457 - out_loss: 2.2563 - rbf_fourier_loss: 1.6351 - val_loss: 1.9497 - val_out_loss: 2.2659 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9526 - out_loss: 2.2700 - rbf_fourier_loss: 1.6352 - val_loss: 1.9510 - val_out_loss: 2.2684 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9580 - out_loss: 2.2807 - rbf_fourier_loss: 1.6354 - val_loss: 1.9474 - val_out_loss: 2.2612 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9495 - out_loss: 2.2638 - rbf_fourier_loss: 1.6352 - val_loss: 1.9487 - val_out_loss: 2.2637 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9497 - out_loss: 2.2643 - rbf_fourier_loss: 1.6352 - val_loss: 1.9506 - val_out_loss: 2.2677 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9472 - out_loss: 2.2591 - rbf_fourier_loss: 1.6353 - val_loss: 1.9492 - val_out_loss: 2.2648 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9573 - out_loss: 2.2794 - rbf_fourier_loss: 1.6351 - val_loss: 1.9517 - val_out_loss: 2.2699 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9522 - out_loss: 2.2693 - rbf_fourier_loss: 1.6352 - val_loss: 1.9505 - val_out_loss: 2.2675 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9517 - out_loss: 2.2678 - rbf_fourier_loss: 1.6355 - val_loss: 1.9529 - val_out_loss: 2.2722 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2599 - rbf_fourier_loss: 1.6352 - val_loss: 1.9523 - val_out_loss: 2.2710 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9527 - out_loss: 2.2701 - rbf_fourier_loss: 1.6353 - val_loss: 1.9528 - val_out_loss: 2.2721 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9523 - out_loss: 2.2692 - rbf_fourier_loss: 1.6353 - val_loss: 1.9557 - val_out_loss: 2.2778 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9440 - out_loss: 2.2524 - rbf_fourier_loss: 1.6355 - val_loss: 1.9551 - val_out_loss: 2.2766 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9482 - out_loss: 2.2611 - rbf_fourier_loss: 1.6354 - val_loss: 1.9541 - val_out_loss: 2.2745 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9507 - out_loss: 2.2662 - rbf_fourier_loss: 1.6353 - val_loss: 1.9525 - val_out_loss: 2.2714 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9543 - out_loss: 2.2732 - rbf_fourier_loss: 1.6353 - val_loss: 1.9526 - val_out_loss: 2.2716 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9479 - out_loss: 2.2606 - rbf_fourier_loss: 1.6353 - val_loss: 1.9525 - val_out_loss: 2.2715 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9383 - out_loss: 2.2415 - rbf_fourier_loss: 1.6350 - val_loss: 1.9551 - val_out_loss: 2.2766 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2598 - rbf_fourier_loss: 1.6355 - val_loss: 1.9564 - val_out_loss: 2.2793 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9485 - out_loss: 2.2618 - rbf_fourier_loss: 1.6353 - val_loss: 1.9515 - val_out_loss: 2.2695 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9466 - out_loss: 2.2580 - rbf_fourier_loss: 1.6352 - val_loss: 1.9527 - val_out_loss: 2.2718 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9443 - out_loss: 2.2534 - rbf_fourier_loss: 1.6352 - val_loss: 1.9532 - val_out_loss: 2.2729 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9468 - out_loss: 2.2585 - rbf_fourier_loss: 1.6352 - val_loss: 1.9540 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9367 - out_loss: 2.2380 - rbf_fourier_loss: 1.6354 - val_loss: 1.9535 - val_out_loss: 2.2734 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9486 - out_loss: 2.2620 - rbf_fourier_loss: 1.6352 - val_loss: 1.9555 - val_out_loss: 2.2773 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9485 - out_loss: 2.2617 - rbf_fourier_loss: 1.6352 - val_loss: 1.9534 - val_out_loss: 2.2733 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9448 - out_loss: 2.2540 - rbf_fourier_loss: 1.6356 - val_loss: 1.9570 - val_out_loss: 2.2805 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9476 - out_loss: 2.2600 - rbf_fourier_loss: 1.6352 - val_loss: 1.9566 - val_out_loss: 2.2797 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9495 - out_loss: 2.2637 - rbf_fourier_loss: 1.6353 - val_loss: 1.9552 - val_out_loss: 2.2768 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9428 - out_loss: 2.2501 - rbf_fourier_loss: 1.6355 - val_loss: 1.9542 - val_out_loss: 2.2748 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9453 - out_loss: 2.2551 - rbf_fourier_loss: 1.6355 - val_loss: 1.9562 - val_out_loss: 2.2787 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9425 - out_loss: 2.2497 - rbf_fourier_loss: 1.6353 - val_loss: 1.9532 - val_out_loss: 2.2728 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2599 - rbf_fourier_loss: 1.6353 - val_loss: 1.9544 - val_out_loss: 2.2752 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9529 - out_loss: 2.2704 - rbf_fourier_loss: 1.6354 - val_loss: 1.9564 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9404 - out_loss: 2.2453 - rbf_fourier_loss: 1.6356 - val_loss: 1.9572 - val_out_loss: 2.2809 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9411 - out_loss: 2.2473 - rbf_fourier_loss: 1.6349 - val_loss: 1.9568 - val_out_loss: 2.2801 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9381 - out_loss: 2.2408 - rbf_fourier_loss: 1.6355 - val_loss: 1.9562 - val_out_loss: 2.2789 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9390 - out_loss: 2.2427 - rbf_fourier_loss: 1.6354 - val_loss: 1.9533 - val_out_loss: 2.2731 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9371 - out_loss: 2.2390 - rbf_fourier_loss: 1.6353 - val_loss: 1.9527 - val_out_loss: 2.2718 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9449 - out_loss: 2.2546 - rbf_fourier_loss: 1.6352 - val_loss: 1.9538 - val_out_loss: 2.2740 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9418 - out_loss: 2.2483 - rbf_fourier_loss: 1.6354 - val_loss: 1.9524 - val_out_loss: 2.2712 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9362 - out_loss: 2.2370 - rbf_fourier_loss: 1.6354 - val_loss: 1.9544 - val_out_loss: 2.2751 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9414 - out_loss: 2.2477 - rbf_fourier_loss: 1.6352 - val_loss: 1.9544 - val_out_loss: 2.2752 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9455 - out_loss: 2.2558 - rbf_fourier_loss: 1.6353 - val_loss: 1.9537 - val_out_loss: 2.2739 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9411 - out_loss: 2.2467 - rbf_fourier_loss: 1.6355 - val_loss: 1.9539 - val_out_loss: 2.2742 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9368 - out_loss: 2.2383 - rbf_fourier_loss: 1.6353 - val_loss: 1.9552 - val_out_loss: 2.2768 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9375 - out_loss: 2.2396 - rbf_fourier_loss: 1.6354 - val_loss: 1.9565 - val_out_loss: 2.2793 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9335 - out_loss: 2.2315 - rbf_fourier_loss: 1.6354 - val_loss: 1.9551 - val_out_loss: 2.2766 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9417 - out_loss: 2.2482 - rbf_fourier_loss: 1.6351 - val_loss: 1.9558 - val_out_loss: 2.2780 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9391 - out_loss: 2.2428 - rbf_fourier_loss: 1.6354 - val_loss: 1.9534 - val_out_loss: 2.2733 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9459 - out_loss: 2.2566 - rbf_fourier_loss: 1.6352 - val_loss: 1.9556 - val_out_loss: 2.2777 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9430 - out_loss: 2.2505 - rbf_fourier_loss: 1.6355 - val_loss: 1.9546 - val_out_loss: 2.2756 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9411 - out_loss: 2.2470 - rbf_fourier_loss: 1.6352 - val_loss: 1.9571 - val_out_loss: 2.2806 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9353 - out_loss: 2.2352 - rbf_fourier_loss: 1.6353 - val_loss: 1.9574 - val_out_loss: 2.2812 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9355 - out_loss: 2.2358 - rbf_fourier_loss: 1.6352 - val_loss: 1.9584 - val_out_loss: 2.2832 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9406 - out_loss: 2.2458 - rbf_fourier_loss: 1.6353 - val_loss: 1.9592 - val_out_loss: 2.2848 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9403 - out_loss: 2.2454 - rbf_fourier_loss: 1.6352 - val_loss: 1.9580 - val_out_loss: 2.2825 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9350 - out_loss: 2.2349 - rbf_fourier_loss: 1.6352 - val_loss: 1.9605 - val_out_loss: 2.2874 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9405 - out_loss: 2.2457 - rbf_fourier_loss: 1.6353 - val_loss: 1.9613 - val_out_loss: 2.2890 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9406 - out_loss: 2.2460 - rbf_fourier_loss: 1.6352 - val_loss: 1.9595 - val_out_loss: 2.2854 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9405 - out_loss: 2.2453 - rbf_fourier_loss: 1.6357 - val_loss: 1.9555 - val_out_loss: 2.2775 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9316 - out_loss: 2.2279 - rbf_fourier_loss: 1.6352 - val_loss: 1.9552 - val_out_loss: 2.2768 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9381 - out_loss: 2.2408 - rbf_fourier_loss: 1.6354 - val_loss: 1.9571 - val_out_loss: 2.2807 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9370 - out_loss: 2.2386 - rbf_fourier_loss: 1.6353 - val_loss: 1.9584 - val_out_loss: 2.2833 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9373 - out_loss: 2.2391 - rbf_fourier_loss: 1.6354 - val_loss: 1.9586 - val_out_loss: 2.2837 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9342 - out_loss: 2.2331 - rbf_fourier_loss: 1.6354 - val_loss: 1.9613 - val_out_loss: 2.2889 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9391 - out_loss: 2.2428 - rbf_fourier_loss: 1.6355 - val_loss: 1.9619 - val_out_loss: 2.2903 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9326 - out_loss: 2.2301 - rbf_fourier_loss: 1.6351 - val_loss: 1.9598 - val_out_loss: 2.2861 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9366 - out_loss: 2.2376 - rbf_fourier_loss: 1.6355 - val_loss: 1.9606 - val_out_loss: 2.2876 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9332 - out_loss: 2.2309 - rbf_fourier_loss: 1.6354 - val_loss: 1.9606 - val_out_loss: 2.2877 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9369 - out_loss: 2.2385 - rbf_fourier_loss: 1.6353 - val_loss: 1.9590 - val_out_loss: 2.2844 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9385 - out_loss: 2.2417 - rbf_fourier_loss: 1.6353 - val_loss: 1.9575 - val_out_loss: 2.2815 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9397 - out_loss: 2.2439 - rbf_fourier_loss: 1.6355 - val_loss: 1.9564 - val_out_loss: 2.2791 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9374 - out_loss: 2.2395 - rbf_fourier_loss: 1.6353 - val_loss: 1.9564 - val_out_loss: 2.2793 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9358 - out_loss: 2.2363 - rbf_fourier_loss: 1.6352 - val_loss: 1.9572 - val_out_loss: 2.2809 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9374 - out_loss: 2.2396 - rbf_fourier_loss: 1.6353 - val_loss: 1.9589 - val_out_loss: 2.2842 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9365 - out_loss: 2.2377 - rbf_fourier_loss: 1.6353 - val_loss: 1.9584 - val_out_loss: 2.2832 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9307 - out_loss: 2.2259 - rbf_fourier_loss: 1.6354 - val_loss: 1.9596 - val_out_loss: 2.2857 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9292 - out_loss: 2.2232 - rbf_fourier_loss: 1.6352 - val_loss: 1.9596 - val_out_loss: 2.2856 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9324 - out_loss: 2.2293 - rbf_fourier_loss: 1.6354 - val_loss: 1.9590 - val_out_loss: 2.2844 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9369 - out_loss: 2.2386 - rbf_fourier_loss: 1.6352 - val_loss: 1.9607 - val_out_loss: 2.2879 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9403 - out_loss: 2.2454 - rbf_fourier_loss: 1.6352 - val_loss: 1.9620 - val_out_loss: 2.2904 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9309 - out_loss: 2.2265 - rbf_fourier_loss: 1.6354 - val_loss: 1.9613 - val_out_loss: 2.2891 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9307 - out_loss: 2.2261 - rbf_fourier_loss: 1.6353 - val_loss: 1.9609 - val_out_loss: 2.2882 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9382 - out_loss: 2.2411 - rbf_fourier_loss: 1.6352 - val_loss: 1.9610 - val_out_loss: 2.2884 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9291 - out_loss: 2.2229 - rbf_fourier_loss: 1.6353 - val_loss: 1.9609 - val_out_loss: 2.2882 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9394 - out_loss: 2.2435 - rbf_fourier_loss: 1.6353 - val_loss: 1.9616 - val_out_loss: 2.2896 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9268 - out_loss: 2.2183 - rbf_fourier_loss: 1.6354 - val_loss: 1.9613 - val_out_loss: 2.2890 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9287 - out_loss: 2.2219 - rbf_fourier_loss: 1.6355 - val_loss: 1.9637 - val_out_loss: 2.2937 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9315 - out_loss: 2.2277 - rbf_fourier_loss: 1.6352 - val_loss: 1.9606 - val_out_loss: 2.2875 - val_rbf_fourier_loss: 1.6336\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9329 - out_loss: 2.2303 - rbf_fourier_loss: 1.6354 - val_loss: 1.9602 - val_out_loss: 2.2867 - val_rbf_fourier_loss: 1.6336\n",
            "it 1/10\n",
            "acc: 11.236666666666666\n",
            "ari: 0.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 2.2539 - out_loss: 2.8818 - rbf_fourier_loss: 1.6261 - val_loss: 2.2610 - val_out_loss: 2.8907 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2611 - out_loss: 2.8962 - rbf_fourier_loss: 1.6260 - val_loss: 2.2598 - val_out_loss: 2.8884 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2479 - out_loss: 2.8696 - rbf_fourier_loss: 1.6261 - val_loss: 2.2555 - val_out_loss: 2.8796 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2517 - out_loss: 2.8766 - rbf_fourier_loss: 1.6269 - val_loss: 2.2557 - val_out_loss: 2.8800 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2579 - out_loss: 2.8899 - rbf_fourier_loss: 1.6258 - val_loss: 2.2584 - val_out_loss: 2.8855 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2431 - out_loss: 2.8598 - rbf_fourier_loss: 1.6264 - val_loss: 2.2588 - val_out_loss: 2.8862 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2518 - out_loss: 2.8770 - rbf_fourier_loss: 1.6266 - val_loss: 2.2597 - val_out_loss: 2.8881 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2571 - out_loss: 2.8882 - rbf_fourier_loss: 1.6260 - val_loss: 2.2604 - val_out_loss: 2.8895 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2528 - out_loss: 2.8795 - rbf_fourier_loss: 1.6261 - val_loss: 2.2622 - val_out_loss: 2.8931 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2508 - out_loss: 2.8755 - rbf_fourier_loss: 1.6261 - val_loss: 2.2620 - val_out_loss: 2.8926 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2546 - out_loss: 2.8830 - rbf_fourier_loss: 1.6263 - val_loss: 2.2563 - val_out_loss: 2.8814 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2465 - out_loss: 2.8663 - rbf_fourier_loss: 1.6267 - val_loss: 2.2576 - val_out_loss: 2.8838 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2560 - out_loss: 2.8853 - rbf_fourier_loss: 1.6267 - val_loss: 2.2563 - val_out_loss: 2.8813 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2527 - out_loss: 2.8788 - rbf_fourier_loss: 1.6266 - val_loss: 2.2589 - val_out_loss: 2.8864 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2608 - out_loss: 2.8956 - rbf_fourier_loss: 1.6259 - val_loss: 2.2617 - val_out_loss: 2.8921 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2519 - out_loss: 2.8778 - rbf_fourier_loss: 1.6260 - val_loss: 2.2593 - val_out_loss: 2.8873 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2460 - out_loss: 2.8655 - rbf_fourier_loss: 1.6264 - val_loss: 2.2582 - val_out_loss: 2.8851 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2535 - out_loss: 2.8814 - rbf_fourier_loss: 1.6256 - val_loss: 2.2564 - val_out_loss: 2.8815 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2512 - out_loss: 2.8758 - rbf_fourier_loss: 1.6266 - val_loss: 2.2555 - val_out_loss: 2.8796 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2534 - out_loss: 2.8803 - rbf_fourier_loss: 1.6264 - val_loss: 2.2552 - val_out_loss: 2.8792 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2561 - out_loss: 2.8858 - rbf_fourier_loss: 1.6264 - val_loss: 2.2538 - val_out_loss: 2.8762 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2520 - out_loss: 2.8774 - rbf_fourier_loss: 1.6267 - val_loss: 2.2539 - val_out_loss: 2.8765 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2486 - out_loss: 2.8712 - rbf_fourier_loss: 1.6259 - val_loss: 2.2548 - val_out_loss: 2.8782 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2512 - out_loss: 2.8759 - rbf_fourier_loss: 1.6264 - val_loss: 2.2568 - val_out_loss: 2.8823 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2531 - out_loss: 2.8801 - rbf_fourier_loss: 1.6261 - val_loss: 2.2563 - val_out_loss: 2.8812 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2522 - out_loss: 2.8783 - rbf_fourier_loss: 1.6262 - val_loss: 2.2578 - val_out_loss: 2.8843 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 2.2461 - out_loss: 2.8658 - rbf_fourier_loss: 1.6264 - val_loss: 2.2564 - val_out_loss: 2.8815 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2497 - out_loss: 2.8720 - rbf_fourier_loss: 1.6273 - val_loss: 2.2536 - val_out_loss: 2.8759 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2545 - out_loss: 2.8829 - rbf_fourier_loss: 1.6262 - val_loss: 2.2531 - val_out_loss: 2.8748 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2537 - out_loss: 2.8815 - rbf_fourier_loss: 1.6260 - val_loss: 2.2509 - val_out_loss: 2.8705 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2489 - out_loss: 2.8716 - rbf_fourier_loss: 1.6263 - val_loss: 2.2526 - val_out_loss: 2.8738 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2518 - out_loss: 2.8769 - rbf_fourier_loss: 1.6268 - val_loss: 2.2553 - val_out_loss: 2.8793 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2517 - out_loss: 2.8770 - rbf_fourier_loss: 1.6264 - val_loss: 2.2556 - val_out_loss: 2.8798 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2542 - out_loss: 2.8819 - rbf_fourier_loss: 1.6265 - val_loss: 2.2531 - val_out_loss: 2.8749 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2518 - out_loss: 2.8768 - rbf_fourier_loss: 1.6269 - val_loss: 2.2557 - val_out_loss: 2.8800 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2467 - out_loss: 2.8671 - rbf_fourier_loss: 1.6263 - val_loss: 2.2561 - val_out_loss: 2.8810 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2496 - out_loss: 2.8721 - rbf_fourier_loss: 1.6271 - val_loss: 2.2569 - val_out_loss: 2.8825 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2458 - out_loss: 2.8658 - rbf_fourier_loss: 1.6257 - val_loss: 2.2569 - val_out_loss: 2.8825 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2527 - out_loss: 2.8794 - rbf_fourier_loss: 1.6260 - val_loss: 2.2559 - val_out_loss: 2.8805 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2522 - out_loss: 2.8776 - rbf_fourier_loss: 1.6267 - val_loss: 2.2577 - val_out_loss: 2.8840 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 2.2500 - out_loss: 2.8738 - rbf_fourier_loss: 1.6262 - val_loss: 2.2581 - val_out_loss: 2.8849 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2522 - out_loss: 2.8785 - rbf_fourier_loss: 1.6259 - val_loss: 2.2573 - val_out_loss: 2.8834 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2491 - out_loss: 2.8717 - rbf_fourier_loss: 1.6265 - val_loss: 2.2567 - val_out_loss: 2.8820 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2460 - out_loss: 2.8658 - rbf_fourier_loss: 1.6263 - val_loss: 2.2563 - val_out_loss: 2.8813 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2461 - out_loss: 2.8659 - rbf_fourier_loss: 1.6263 - val_loss: 2.2570 - val_out_loss: 2.8826 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2502 - out_loss: 2.8735 - rbf_fourier_loss: 1.6268 - val_loss: 2.2597 - val_out_loss: 2.8881 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2461 - out_loss: 2.8660 - rbf_fourier_loss: 1.6263 - val_loss: 2.2590 - val_out_loss: 2.8866 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2438 - out_loss: 2.8614 - rbf_fourier_loss: 1.6262 - val_loss: 2.2579 - val_out_loss: 2.8844 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2476 - out_loss: 2.8692 - rbf_fourier_loss: 1.6261 - val_loss: 2.2601 - val_out_loss: 2.8888 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2489 - out_loss: 2.8717 - rbf_fourier_loss: 1.6261 - val_loss: 2.2608 - val_out_loss: 2.8902 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2459 - out_loss: 2.8658 - rbf_fourier_loss: 1.6259 - val_loss: 2.2624 - val_out_loss: 2.8935 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2511 - out_loss: 2.8764 - rbf_fourier_loss: 1.6259 - val_loss: 2.2603 - val_out_loss: 2.8893 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2452 - out_loss: 2.8644 - rbf_fourier_loss: 1.6260 - val_loss: 2.2596 - val_out_loss: 2.8879 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2450 - out_loss: 2.8635 - rbf_fourier_loss: 1.6265 - val_loss: 2.2579 - val_out_loss: 2.8845 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2504 - out_loss: 2.8744 - rbf_fourier_loss: 1.6263 - val_loss: 2.2574 - val_out_loss: 2.8836 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2553 - out_loss: 2.8849 - rbf_fourier_loss: 1.6258 - val_loss: 2.2557 - val_out_loss: 2.8801 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2499 - out_loss: 2.8742 - rbf_fourier_loss: 1.6256 - val_loss: 2.2569 - val_out_loss: 2.8824 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2417 - out_loss: 2.8568 - rbf_fourier_loss: 1.6267 - val_loss: 2.2544 - val_out_loss: 2.8775 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 2.2434 - out_loss: 2.8606 - rbf_fourier_loss: 1.6262 - val_loss: 2.2563 - val_out_loss: 2.8813 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2476 - out_loss: 2.8691 - rbf_fourier_loss: 1.6261 - val_loss: 2.2551 - val_out_loss: 2.8789 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2470 - out_loss: 2.8673 - rbf_fourier_loss: 1.6267 - val_loss: 2.2562 - val_out_loss: 2.8811 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2513 - out_loss: 2.8760 - rbf_fourier_loss: 1.6267 - val_loss: 2.2541 - val_out_loss: 2.8768 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2513 - out_loss: 2.8758 - rbf_fourier_loss: 1.6268 - val_loss: 2.2536 - val_out_loss: 2.8760 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2429 - out_loss: 2.8591 - rbf_fourier_loss: 1.6267 - val_loss: 2.2556 - val_out_loss: 2.8799 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2418 - out_loss: 2.8570 - rbf_fourier_loss: 1.6265 - val_loss: 2.2557 - val_out_loss: 2.8801 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2517 - out_loss: 2.8773 - rbf_fourier_loss: 1.6260 - val_loss: 2.2571 - val_out_loss: 2.8830 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2444 - out_loss: 2.8628 - rbf_fourier_loss: 1.6261 - val_loss: 2.2570 - val_out_loss: 2.8827 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2491 - out_loss: 2.8721 - rbf_fourier_loss: 1.6262 - val_loss: 2.2567 - val_out_loss: 2.8821 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2511 - out_loss: 2.8756 - rbf_fourier_loss: 1.6266 - val_loss: 2.2565 - val_out_loss: 2.8817 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2473 - out_loss: 2.8683 - rbf_fourier_loss: 1.6264 - val_loss: 2.2592 - val_out_loss: 2.8872 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2464 - out_loss: 2.8661 - rbf_fourier_loss: 1.6266 - val_loss: 2.2586 - val_out_loss: 2.8859 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2433 - out_loss: 2.8605 - rbf_fourier_loss: 1.6262 - val_loss: 2.2583 - val_out_loss: 2.8852 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2495 - out_loss: 2.8724 - rbf_fourier_loss: 1.6266 - val_loss: 2.2556 - val_out_loss: 2.8800 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2419 - out_loss: 2.8571 - rbf_fourier_loss: 1.6268 - val_loss: 2.2571 - val_out_loss: 2.8829 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2480 - out_loss: 2.8698 - rbf_fourier_loss: 1.6262 - val_loss: 2.2583 - val_out_loss: 2.8853 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2428 - out_loss: 2.8587 - rbf_fourier_loss: 1.6269 - val_loss: 2.2614 - val_out_loss: 2.8915 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2344 - out_loss: 2.8427 - rbf_fourier_loss: 1.6260 - val_loss: 2.2589 - val_out_loss: 2.8865 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2445 - out_loss: 2.8621 - rbf_fourier_loss: 1.6269 - val_loss: 2.2577 - val_out_loss: 2.8841 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2462 - out_loss: 2.8658 - rbf_fourier_loss: 1.6265 - val_loss: 2.2558 - val_out_loss: 2.8803 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2445 - out_loss: 2.8623 - rbf_fourier_loss: 1.6267 - val_loss: 2.2558 - val_out_loss: 2.8803 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2453 - out_loss: 2.8641 - rbf_fourier_loss: 1.6266 - val_loss: 2.2539 - val_out_loss: 2.8765 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2416 - out_loss: 2.8569 - rbf_fourier_loss: 1.6262 - val_loss: 2.2531 - val_out_loss: 2.8748 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2408 - out_loss: 2.8552 - rbf_fourier_loss: 1.6264 - val_loss: 2.2544 - val_out_loss: 2.8776 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2455 - out_loss: 2.8648 - rbf_fourier_loss: 1.6261 - val_loss: 2.2559 - val_out_loss: 2.8805 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2390 - out_loss: 2.8516 - rbf_fourier_loss: 1.6263 - val_loss: 2.2544 - val_out_loss: 2.8775 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2362 - out_loss: 2.8456 - rbf_fourier_loss: 1.6267 - val_loss: 2.2554 - val_out_loss: 2.8795 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2394 - out_loss: 2.8519 - rbf_fourier_loss: 1.6269 - val_loss: 2.2571 - val_out_loss: 2.8829 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2360 - out_loss: 2.8457 - rbf_fourier_loss: 1.6263 - val_loss: 2.2549 - val_out_loss: 2.8784 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2390 - out_loss: 2.8521 - rbf_fourier_loss: 1.6260 - val_loss: 2.2527 - val_out_loss: 2.8741 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2418 - out_loss: 2.8576 - rbf_fourier_loss: 1.6260 - val_loss: 2.2536 - val_out_loss: 2.8760 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2423 - out_loss: 2.8583 - rbf_fourier_loss: 1.6263 - val_loss: 2.2513 - val_out_loss: 2.8713 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2392 - out_loss: 2.8519 - rbf_fourier_loss: 1.6265 - val_loss: 2.2522 - val_out_loss: 2.8731 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2392 - out_loss: 2.8513 - rbf_fourier_loss: 1.6271 - val_loss: 2.2535 - val_out_loss: 2.8757 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2390 - out_loss: 2.8514 - rbf_fourier_loss: 1.6266 - val_loss: 2.2535 - val_out_loss: 2.8756 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2426 - out_loss: 2.8593 - rbf_fourier_loss: 1.6259 - val_loss: 2.2527 - val_out_loss: 2.8741 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2426 - out_loss: 2.8598 - rbf_fourier_loss: 1.6255 - val_loss: 2.2578 - val_out_loss: 2.8842 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2437 - out_loss: 2.8614 - rbf_fourier_loss: 1.6261 - val_loss: 2.2591 - val_out_loss: 2.8869 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2377 - out_loss: 2.8488 - rbf_fourier_loss: 1.6266 - val_loss: 2.2557 - val_out_loss: 2.8801 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2319 - out_loss: 2.8379 - rbf_fourier_loss: 1.6260 - val_loss: 2.2549 - val_out_loss: 2.8784 - val_rbf_fourier_loss: 1.6313\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2414 - out_loss: 2.8561 - rbf_fourier_loss: 1.6266 - val_loss: 2.2554 - val_out_loss: 2.8795 - val_rbf_fourier_loss: 1.6313\n",
            "it 1/10\n",
            "acc: 11.858333333333333\n",
            "ari: 0.0755606150260448\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 0.2690 - out_loss: 0.6302 - rbf_fourier_loss: -0.0921 - val_loss: 0.2622 - val_out_loss: 0.6180 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2677 - out_loss: 0.6266 - rbf_fourier_loss: -0.0911 - val_loss: 0.2626 - val_out_loss: 0.6187 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2679 - out_loss: 0.6281 - rbf_fourier_loss: -0.0923 - val_loss: 0.2604 - val_out_loss: 0.6142 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2597 - out_loss: 0.6116 - rbf_fourier_loss: -0.0923 - val_loss: 0.2595 - val_out_loss: 0.6125 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2562 - out_loss: 0.6039 - rbf_fourier_loss: -0.0915 - val_loss: 0.2599 - val_out_loss: 0.6132 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2612 - out_loss: 0.6151 - rbf_fourier_loss: -0.0926 - val_loss: 0.2579 - val_out_loss: 0.6093 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 0.2581 - out_loss: 0.6074 - rbf_fourier_loss: -0.0912 - val_loss: 0.2567 - val_out_loss: 0.6069 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2591 - out_loss: 0.6098 - rbf_fourier_loss: -0.0916 - val_loss: 0.2553 - val_out_loss: 0.6042 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2579 - out_loss: 0.6066 - rbf_fourier_loss: -0.0907 - val_loss: 0.2569 - val_out_loss: 0.6074 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2582 - out_loss: 0.6080 - rbf_fourier_loss: -0.0917 - val_loss: 0.2529 - val_out_loss: 0.5993 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2531 - out_loss: 0.5981 - rbf_fourier_loss: -0.0919 - val_loss: 0.2539 - val_out_loss: 0.6013 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2526 - out_loss: 0.5975 - rbf_fourier_loss: -0.0923 - val_loss: 0.2512 - val_out_loss: 0.5959 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2459 - out_loss: 0.5817 - rbf_fourier_loss: -0.0899 - val_loss: 0.2488 - val_out_loss: 0.5910 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2465 - out_loss: 0.5847 - rbf_fourier_loss: -0.0917 - val_loss: 0.2474 - val_out_loss: 0.5883 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2463 - out_loss: 0.5837 - rbf_fourier_loss: -0.0911 - val_loss: 0.2444 - val_out_loss: 0.5823 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2448 - out_loss: 0.5818 - rbf_fourier_loss: -0.0921 - val_loss: 0.2411 - val_out_loss: 0.5757 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2424 - out_loss: 0.5770 - rbf_fourier_loss: -0.0922 - val_loss: 0.2384 - val_out_loss: 0.5703 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2369 - out_loss: 0.5648 - rbf_fourier_loss: -0.0911 - val_loss: 0.2345 - val_out_loss: 0.5625 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2328 - out_loss: 0.5574 - rbf_fourier_loss: -0.0919 - val_loss: 0.2282 - val_out_loss: 0.5499 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2256 - out_loss: 0.5429 - rbf_fourier_loss: -0.0918 - val_loss: 0.2229 - val_out_loss: 0.5393 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2294 - out_loss: 0.5499 - rbf_fourier_loss: -0.0910 - val_loss: 0.2161 - val_out_loss: 0.5257 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2121 - out_loss: 0.5172 - rbf_fourier_loss: -0.0929 - val_loss: 0.2021 - val_out_loss: 0.4977 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 0.1976 - out_loss: 0.4865 - rbf_fourier_loss: -0.0913 - val_loss: 0.1823 - val_out_loss: 0.4580 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1679 - out_loss: 0.4282 - rbf_fourier_loss: -0.0924 - val_loss: 0.1183 - val_out_loss: 0.3302 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.0339 - out_loss: 0.1591 - rbf_fourier_loss: -0.0913 - val_loss: -0.4509 - val_out_loss: -0.8083 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7544 - out_loss: -1.4182 - rbf_fourier_loss: -0.0905 - val_loss: -1.2246 - val_out_loss: -2.3557 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3919 - out_loss: -2.6939 - rbf_fourier_loss: -0.0899 - val_loss: -1.4077 - val_out_loss: -2.7218 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4247 - out_loss: -2.7580 - rbf_fourier_loss: -0.0914 - val_loss: -1.3974 - val_out_loss: -2.7013 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4174 - out_loss: -2.7425 - rbf_fourier_loss: -0.0924 - val_loss: -1.4041 - val_out_loss: -2.7146 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3908 - out_loss: -2.6887 - rbf_fourier_loss: -0.0928 - val_loss: -1.4087 - val_out_loss: -2.7240 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3862 - out_loss: -2.6802 - rbf_fourier_loss: -0.0922 - val_loss: -1.3887 - val_out_loss: -2.6838 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3710 - out_loss: -2.6501 - rbf_fourier_loss: -0.0919 - val_loss: -1.3656 - val_out_loss: -2.6378 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3584 - out_loss: -2.6245 - rbf_fourier_loss: -0.0922 - val_loss: -1.3807 - val_out_loss: -2.6678 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3449 - out_loss: -2.5974 - rbf_fourier_loss: -0.0924 - val_loss: -1.3312 - val_out_loss: -2.5689 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3530 - out_loss: -2.6147 - rbf_fourier_loss: -0.0912 - val_loss: -1.3575 - val_out_loss: -2.6216 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3094 - out_loss: -2.5256 - rbf_fourier_loss: -0.0933 - val_loss: -1.3097 - val_out_loss: -2.5258 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3103 - out_loss: -2.5276 - rbf_fourier_loss: -0.0930 - val_loss: -1.3390 - val_out_loss: -2.5845 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3159 - out_loss: -2.5400 - rbf_fourier_loss: -0.0918 - val_loss: -1.3355 - val_out_loss: -2.5775 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3088 - out_loss: -2.5264 - rbf_fourier_loss: -0.0912 - val_loss: -1.2689 - val_out_loss: -2.4443 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2402 - out_loss: -2.3885 - rbf_fourier_loss: -0.0920 - val_loss: -1.2729 - val_out_loss: -2.4523 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2640 - out_loss: -2.4344 - rbf_fourier_loss: -0.0935 - val_loss: -1.2681 - val_out_loss: -2.4427 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2621 - out_loss: -2.4320 - rbf_fourier_loss: -0.0921 - val_loss: -1.2456 - val_out_loss: -2.3978 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2732 - out_loss: -2.4548 - rbf_fourier_loss: -0.0915 - val_loss: -1.2325 - val_out_loss: -2.3715 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2622 - out_loss: -2.4332 - rbf_fourier_loss: -0.0912 - val_loss: -1.2787 - val_out_loss: -2.4639 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2284 - out_loss: -2.3636 - rbf_fourier_loss: -0.0931 - val_loss: -1.2340 - val_out_loss: -2.3745 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2277 - out_loss: -2.3640 - rbf_fourier_loss: -0.0914 - val_loss: -1.2222 - val_out_loss: -2.3508 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2338 - out_loss: -2.3744 - rbf_fourier_loss: -0.0932 - val_loss: -1.2254 - val_out_loss: -2.3572 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2247 - out_loss: -2.3578 - rbf_fourier_loss: -0.0916 - val_loss: -1.2385 - val_out_loss: -2.3834 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2420 - out_loss: -2.3919 - rbf_fourier_loss: -0.0921 - val_loss: -1.2375 - val_out_loss: -2.3815 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2402 - out_loss: -2.3883 - rbf_fourier_loss: -0.0921 - val_loss: -1.1885 - val_out_loss: -2.2834 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1998 - out_loss: -2.3102 - rbf_fourier_loss: -0.0895 - val_loss: -1.2215 - val_out_loss: -2.3495 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1920 - out_loss: -2.2933 - rbf_fourier_loss: -0.0906 - val_loss: -1.1769 - val_out_loss: -2.2602 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1487 - out_loss: -2.2048 - rbf_fourier_loss: -0.0927 - val_loss: -1.1968 - val_out_loss: -2.3000 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2205 - out_loss: -2.3484 - rbf_fourier_loss: -0.0927 - val_loss: -1.1293 - val_out_loss: -2.1650 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1878 - out_loss: -2.2836 - rbf_fourier_loss: -0.0920 - val_loss: -1.1601 - val_out_loss: -2.2267 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1408 - out_loss: -2.1902 - rbf_fourier_loss: -0.0914 - val_loss: -1.1462 - val_out_loss: -2.1988 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1864 - out_loss: -2.2823 - rbf_fourier_loss: -0.0905 - val_loss: -1.1492 - val_out_loss: -2.2049 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2128 - out_loss: -2.3321 - rbf_fourier_loss: -0.0935 - val_loss: -1.1639 - val_out_loss: -2.2342 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1669 - out_loss: -2.2436 - rbf_fourier_loss: -0.0903 - val_loss: -1.1143 - val_out_loss: -2.1351 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1466 - out_loss: -2.2011 - rbf_fourier_loss: -0.0921 - val_loss: -1.0859 - val_out_loss: -2.0784 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2025 - out_loss: -2.3130 - rbf_fourier_loss: -0.0920 - val_loss: -1.1406 - val_out_loss: -2.1877 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1388 - out_loss: -2.1867 - rbf_fourier_loss: -0.0909 - val_loss: -1.0765 - val_out_loss: -2.0595 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1238 - out_loss: -2.1563 - rbf_fourier_loss: -0.0913 - val_loss: -1.0699 - val_out_loss: -2.0462 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1427 - out_loss: -2.1937 - rbf_fourier_loss: -0.0917 - val_loss: -1.0799 - val_out_loss: -2.0663 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1358 - out_loss: -2.1797 - rbf_fourier_loss: -0.0918 - val_loss: -1.0811 - val_out_loss: -2.0686 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1383 - out_loss: -2.1845 - rbf_fourier_loss: -0.0921 - val_loss: -1.0544 - val_out_loss: -2.0152 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0975 - out_loss: -2.1039 - rbf_fourier_loss: -0.0910 - val_loss: -1.0808 - val_out_loss: -2.0681 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1101 - out_loss: -2.1284 - rbf_fourier_loss: -0.0917 - val_loss: -1.0741 - val_out_loss: -2.0548 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1373 - out_loss: -2.1833 - rbf_fourier_loss: -0.0913 - val_loss: -1.1077 - val_out_loss: -2.1219 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1368 - out_loss: -2.1812 - rbf_fourier_loss: -0.0924 - val_loss: -1.0496 - val_out_loss: -2.0057 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1698 - out_loss: -2.2472 - rbf_fourier_loss: -0.0923 - val_loss: -1.0428 - val_out_loss: -1.9920 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -1.1842 - out_loss: -2.2762 - rbf_fourier_loss: -0.0922 - val_loss: -1.0337 - val_out_loss: -1.9739 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0979 - out_loss: -2.1054 - rbf_fourier_loss: -0.0904 - val_loss: -1.0651 - val_out_loss: -2.0366 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0931 - out_loss: -2.0944 - rbf_fourier_loss: -0.0918 - val_loss: -1.0496 - val_out_loss: -2.0057 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1334 - out_loss: -2.1772 - rbf_fourier_loss: -0.0895 - val_loss: -1.0324 - val_out_loss: -1.9712 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1610 - out_loss: -2.2294 - rbf_fourier_loss: -0.0926 - val_loss: -1.0081 - val_out_loss: -1.9227 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1391 - out_loss: -2.1872 - rbf_fourier_loss: -0.0911 - val_loss: -1.0183 - val_out_loss: -1.9431 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1057 - out_loss: -2.1182 - rbf_fourier_loss: -0.0932 - val_loss: -1.0175 - val_out_loss: -1.9416 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1615 - out_loss: -2.2321 - rbf_fourier_loss: -0.0909 - val_loss: -1.0329 - val_out_loss: -1.9723 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1748 - out_loss: -2.2579 - rbf_fourier_loss: -0.0918 - val_loss: -1.0564 - val_out_loss: -2.0192 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0915 - out_loss: -2.0912 - rbf_fourier_loss: -0.0919 - val_loss: -1.0668 - val_out_loss: -2.0401 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1076 - out_loss: -2.1245 - rbf_fourier_loss: -0.0906 - val_loss: -1.0386 - val_out_loss: -1.9837 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -1.1580 - out_loss: -2.2257 - rbf_fourier_loss: -0.0903 - val_loss: -1.0922 - val_out_loss: -2.0910 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0874 - out_loss: -2.0835 - rbf_fourier_loss: -0.0914 - val_loss: -1.1293 - val_out_loss: -2.1651 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1912 - out_loss: -2.2913 - rbf_fourier_loss: -0.0910 - val_loss: -1.0591 - val_out_loss: -2.0248 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0775 - out_loss: -2.0632 - rbf_fourier_loss: -0.0918 - val_loss: -1.0790 - val_out_loss: -2.0646 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1643 - out_loss: -2.2365 - rbf_fourier_loss: -0.0921 - val_loss: -1.0757 - val_out_loss: -2.0580 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0806 - out_loss: -2.0689 - rbf_fourier_loss: -0.0924 - val_loss: -1.0207 - val_out_loss: -1.9478 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1046 - out_loss: -2.1181 - rbf_fourier_loss: -0.0911 - val_loss: -1.0424 - val_out_loss: -1.9912 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: nan - out_loss: nan - rbf_fourier_loss: -0.0914 - val_loss: -1.0105 - val_out_loss: -1.9275 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0958 - out_loss: -2.0991 - rbf_fourier_loss: -0.0925 - val_loss: -0.9874 - val_out_loss: -1.8813 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1151 - out_loss: -2.1402 - rbf_fourier_loss: -0.0900 - val_loss: -0.9920 - val_out_loss: -1.8904 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0896 - out_loss: -2.0884 - rbf_fourier_loss: -0.0909 - val_loss: -1.0097 - val_out_loss: -1.9258 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0942 - out_loss: -2.0967 - rbf_fourier_loss: -0.0918 - val_loss: -0.9577 - val_out_loss: -1.8220 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1123 - out_loss: -2.1346 - rbf_fourier_loss: -0.0901 - val_loss: -1.0235 - val_out_loss: -1.9534 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1192 - out_loss: -2.1466 - rbf_fourier_loss: -0.0919 - val_loss: -0.9672 - val_out_loss: -1.8409 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: nan - out_loss: nan - rbf_fourier_loss: -0.0904 - val_loss: -0.9787 - val_out_loss: -1.8639 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0966 - out_loss: -2.1020 - rbf_fourier_loss: -0.0912 - val_loss: -1.0617 - val_out_loss: -2.0298 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0877 - out_loss: -2.0833 - rbf_fourier_loss: -0.0920 - val_loss: -1.0560 - val_out_loss: -2.0185 - val_rbf_fourier_loss: -0.0935\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0896 - out_loss: -2.0880 - rbf_fourier_loss: -0.0912 - val_loss: -1.0596 - val_out_loss: -2.0256 - val_rbf_fourier_loss: -0.0935\n",
            "it 1/10\n",
            "acc: 11.246666666666668\n",
            "ari: 6.341930039383056e-05\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 20ms/step - loss: 0.2706 - out_loss: 0.6323 - rbf_fourier_loss: -0.0911 - val_loss: 0.2647 - val_out_loss: 0.6217 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2669 - out_loss: 0.6240 - rbf_fourier_loss: -0.0903 - val_loss: 0.2626 - val_out_loss: 0.6175 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2659 - out_loss: 0.6236 - rbf_fourier_loss: -0.0919 - val_loss: 0.2622 - val_out_loss: 0.6166 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2632 - out_loss: 0.6183 - rbf_fourier_loss: -0.0919 - val_loss: 0.2623 - val_out_loss: 0.6167 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2634 - out_loss: 0.6189 - rbf_fourier_loss: -0.0920 - val_loss: 0.2603 - val_out_loss: 0.6128 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2622 - out_loss: 0.6164 - rbf_fourier_loss: -0.0920 - val_loss: 0.2575 - val_out_loss: 0.6071 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2550 - out_loss: 0.6020 - rbf_fourier_loss: -0.0920 - val_loss: 0.2579 - val_out_loss: 0.6081 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2590 - out_loss: 0.6081 - rbf_fourier_loss: -0.0900 - val_loss: 0.2566 - val_out_loss: 0.6054 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2526 - out_loss: 0.5986 - rbf_fourier_loss: -0.0935 - val_loss: 0.2554 - val_out_loss: 0.6030 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2546 - out_loss: 0.6009 - rbf_fourier_loss: -0.0916 - val_loss: 0.2517 - val_out_loss: 0.5957 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2570 - out_loss: 0.6060 - rbf_fourier_loss: -0.0921 - val_loss: 0.2518 - val_out_loss: 0.5957 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2515 - out_loss: 0.5951 - rbf_fourier_loss: -0.0921 - val_loss: 0.2509 - val_out_loss: 0.5940 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2523 - out_loss: 0.5965 - rbf_fourier_loss: -0.0919 - val_loss: 0.2486 - val_out_loss: 0.5894 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2483 - out_loss: 0.5893 - rbf_fourier_loss: -0.0927 - val_loss: 0.2460 - val_out_loss: 0.5843 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2474 - out_loss: 0.5875 - rbf_fourier_loss: -0.0927 - val_loss: 0.2458 - val_out_loss: 0.5838 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2458 - out_loss: 0.5826 - rbf_fourier_loss: -0.0910 - val_loss: 0.2446 - val_out_loss: 0.5815 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2415 - out_loss: 0.5741 - rbf_fourier_loss: -0.0911 - val_loss: 0.2417 - val_out_loss: 0.5756 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2333 - out_loss: 0.5584 - rbf_fourier_loss: -0.0919 - val_loss: 0.2375 - val_out_loss: 0.5672 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2335 - out_loss: 0.5584 - rbf_fourier_loss: -0.0914 - val_loss: 0.2318 - val_out_loss: 0.5559 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2320 - out_loss: 0.5554 - rbf_fourier_loss: -0.0915 - val_loss: 0.2244 - val_out_loss: 0.5410 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2232 - out_loss: 0.5388 - rbf_fourier_loss: -0.0924 - val_loss: 0.2151 - val_out_loss: 0.5225 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2043 - out_loss: 0.5011 - rbf_fourier_loss: -0.0926 - val_loss: 0.2030 - val_out_loss: 0.4982 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2011 - out_loss: 0.4945 - rbf_fourier_loss: -0.0923 - val_loss: 0.1824 - val_out_loss: 0.4570 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.1705 - out_loss: 0.4337 - rbf_fourier_loss: -0.0927 - val_loss: 0.1288 - val_out_loss: 0.3498 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.0608 - out_loss: 0.2130 - rbf_fourier_loss: -0.0914 - val_loss: -0.5016 - val_out_loss: -0.9110 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.5906 - out_loss: -1.0881 - rbf_fourier_loss: -0.0931 - val_loss: -0.4528 - val_out_loss: -0.8135 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.6618 - out_loss: -1.2316 - rbf_fourier_loss: -0.0920 - val_loss: -0.6303 - val_out_loss: -1.1684 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7113 - out_loss: -1.3312 - rbf_fourier_loss: -0.0913 - val_loss: -0.6724 - val_out_loss: -1.2526 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7299 - out_loss: -1.3678 - rbf_fourier_loss: -0.0920 - val_loss: -0.6277 - val_out_loss: -1.1632 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7249 - out_loss: -1.3579 - rbf_fourier_loss: -0.0918 - val_loss: -0.6357 - val_out_loss: -1.1792 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7401 - out_loss: -1.3887 - rbf_fourier_loss: -0.0915 - val_loss: -0.6674 - val_out_loss: -1.2425 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7394 - out_loss: -1.3873 - rbf_fourier_loss: -0.0916 - val_loss: -0.6767 - val_out_loss: -1.2611 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7473 - out_loss: -1.4033 - rbf_fourier_loss: -0.0913 - val_loss: -0.6242 - val_out_loss: -1.1561 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7442 - out_loss: -1.3963 - rbf_fourier_loss: -0.0921 - val_loss: -0.6902 - val_out_loss: -1.2883 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7519 - out_loss: -1.4105 - rbf_fourier_loss: -0.0933 - val_loss: -0.6666 - val_out_loss: -1.2409 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7531 - out_loss: -1.4142 - rbf_fourier_loss: -0.0919 - val_loss: -0.7115 - val_out_loss: -1.3307 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7559 - out_loss: -1.4205 - rbf_fourier_loss: -0.0913 - val_loss: -0.6998 - val_out_loss: -1.3073 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7509 - out_loss: -1.4107 - rbf_fourier_loss: -0.0911 - val_loss: -0.6866 - val_out_loss: -1.2810 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7390 - out_loss: -1.3843 - rbf_fourier_loss: -0.0937 - val_loss: -0.6895 - val_out_loss: -1.2868 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7525 - out_loss: -1.4139 - rbf_fourier_loss: -0.0912 - val_loss: -0.6956 - val_out_loss: -1.2989 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7460 - out_loss: -1.4008 - rbf_fourier_loss: -0.0911 - val_loss: -0.7001 - val_out_loss: -1.3079 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7381 - out_loss: -1.3845 - rbf_fourier_loss: -0.0917 - val_loss: -0.7048 - val_out_loss: -1.3173 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7487 - out_loss: -1.4063 - rbf_fourier_loss: -0.0910 - val_loss: -0.7301 - val_out_loss: -1.3680 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7533 - out_loss: -1.4148 - rbf_fourier_loss: -0.0917 - val_loss: -0.6758 - val_out_loss: -1.2594 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7502 - out_loss: -1.4078 - rbf_fourier_loss: -0.0927 - val_loss: -0.6510 - val_out_loss: -1.2097 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -0.7442 - out_loss: -1.3970 - rbf_fourier_loss: -0.0914 - val_loss: -0.6304 - val_out_loss: -1.1686 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -0.7318 - out_loss: -1.3718 - rbf_fourier_loss: -0.0919 - val_loss: -0.7103 - val_out_loss: -1.3284 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7472 - out_loss: -1.4029 - rbf_fourier_loss: -0.0914 - val_loss: -0.6730 - val_out_loss: -1.2537 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7477 - out_loss: -1.4026 - rbf_fourier_loss: -0.0929 - val_loss: -0.7141 - val_out_loss: -1.3361 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7480 - out_loss: -1.4057 - rbf_fourier_loss: -0.0903 - val_loss: -0.6648 - val_out_loss: -1.2373 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7509 - out_loss: -1.4107 - rbf_fourier_loss: -0.0910 - val_loss: -0.7212 - val_out_loss: -1.3502 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -0.7416 - out_loss: -1.3895 - rbf_fourier_loss: -0.0938 - val_loss: -0.7034 - val_out_loss: -1.3146 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7505 - out_loss: -1.4102 - rbf_fourier_loss: -0.0909 - val_loss: -0.6877 - val_out_loss: -1.2832 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7368 - out_loss: -1.3812 - rbf_fourier_loss: -0.0924 - val_loss: -0.6778 - val_out_loss: -1.2633 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7458 - out_loss: -1.3992 - rbf_fourier_loss: -0.0925 - val_loss: -0.6618 - val_out_loss: -1.2314 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7422 - out_loss: -1.3924 - rbf_fourier_loss: -0.0919 - val_loss: -0.6988 - val_out_loss: -1.3053 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7421 - out_loss: -1.3916 - rbf_fourier_loss: -0.0926 - val_loss: -0.6865 - val_out_loss: -1.2808 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7392 - out_loss: -1.3862 - rbf_fourier_loss: -0.0922 - val_loss: -0.7184 - val_out_loss: -1.3446 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7471 - out_loss: -1.4030 - rbf_fourier_loss: -0.0912 - val_loss: -0.6967 - val_out_loss: -1.3012 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7535 - out_loss: -1.4169 - rbf_fourier_loss: -0.0901 - val_loss: -0.6781 - val_out_loss: -1.2640 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7503 - out_loss: -1.4091 - rbf_fourier_loss: -0.0915 - val_loss: -0.6934 - val_out_loss: -1.2946 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7527 - out_loss: -1.4138 - rbf_fourier_loss: -0.0916 - val_loss: -0.6830 - val_out_loss: -1.2738 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7429 - out_loss: -1.3937 - rbf_fourier_loss: -0.0921 - val_loss: -0.6718 - val_out_loss: -1.2513 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7472 - out_loss: -1.4029 - rbf_fourier_loss: -0.0915 - val_loss: -0.6926 - val_out_loss: -1.2930 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7470 - out_loss: -1.4039 - rbf_fourier_loss: -0.0902 - val_loss: -0.6650 - val_out_loss: -1.2377 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7505 - out_loss: -1.4112 - rbf_fourier_loss: -0.0899 - val_loss: -0.7321 - val_out_loss: -1.3720 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7467 - out_loss: -1.4023 - rbf_fourier_loss: -0.0912 - val_loss: -0.7184 - val_out_loss: -1.3445 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7435 - out_loss: -1.3966 - rbf_fourier_loss: -0.0904 - val_loss: -0.6192 - val_out_loss: -1.1461 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7408 - out_loss: -1.3892 - rbf_fourier_loss: -0.0925 - val_loss: -0.6785 - val_out_loss: -1.2647 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7443 - out_loss: -1.3966 - rbf_fourier_loss: -0.0919 - val_loss: -0.6402 - val_out_loss: -1.1882 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7449 - out_loss: -1.3969 - rbf_fourier_loss: -0.0929 - val_loss: -0.7109 - val_out_loss: -1.3295 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7474 - out_loss: -1.4023 - rbf_fourier_loss: -0.0926 - val_loss: -0.7103 - val_out_loss: -1.3285 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7467 - out_loss: -1.4019 - rbf_fourier_loss: -0.0914 - val_loss: -0.6848 - val_out_loss: -1.2773 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7429 - out_loss: -1.3932 - rbf_fourier_loss: -0.0926 - val_loss: -0.6735 - val_out_loss: -1.2548 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7461 - out_loss: -1.3998 - rbf_fourier_loss: -0.0925 - val_loss: -0.6686 - val_out_loss: -1.2451 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7430 - out_loss: -1.3936 - rbf_fourier_loss: -0.0923 - val_loss: -0.6936 - val_out_loss: -1.2949 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7538 - out_loss: -1.4169 - rbf_fourier_loss: -0.0906 - val_loss: -0.6886 - val_out_loss: -1.2850 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7381 - out_loss: -1.3852 - rbf_fourier_loss: -0.0909 - val_loss: -0.6919 - val_out_loss: -1.2916 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7472 - out_loss: -1.4037 - rbf_fourier_loss: -0.0907 - val_loss: -0.7033 - val_out_loss: -1.3144 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7575 - out_loss: -1.4230 - rbf_fourier_loss: -0.0920 - val_loss: -0.6926 - val_out_loss: -1.2931 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7548 - out_loss: -1.4177 - rbf_fourier_loss: -0.0919 - val_loss: -0.6863 - val_out_loss: -1.2804 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7393 - out_loss: -1.3860 - rbf_fourier_loss: -0.0925 - val_loss: -0.6959 - val_out_loss: -1.2997 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7506 - out_loss: -1.4090 - rbf_fourier_loss: -0.0921 - val_loss: -0.7077 - val_out_loss: -1.3232 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7512 - out_loss: -1.4108 - rbf_fourier_loss: -0.0916 - val_loss: -0.6859 - val_out_loss: -1.2796 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7445 - out_loss: -1.3973 - rbf_fourier_loss: -0.0917 - val_loss: -0.6777 - val_out_loss: -1.2631 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7610 - out_loss: -1.4292 - rbf_fourier_loss: -0.0928 - val_loss: -0.6981 - val_out_loss: -1.3040 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7510 - out_loss: -1.4100 - rbf_fourier_loss: -0.0919 - val_loss: -0.7005 - val_out_loss: -1.3089 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7537 - out_loss: -1.4153 - rbf_fourier_loss: -0.0920 - val_loss: -0.6543 - val_out_loss: -1.2164 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7471 - out_loss: -1.4014 - rbf_fourier_loss: -0.0929 - val_loss: -0.6986 - val_out_loss: -1.3049 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7526 - out_loss: -1.4131 - rbf_fourier_loss: -0.0921 - val_loss: -0.6534 - val_out_loss: -1.2145 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7389 - out_loss: -1.3867 - rbf_fourier_loss: -0.0911 - val_loss: -0.6914 - val_out_loss: -1.2906 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7476 - out_loss: -1.4045 - rbf_fourier_loss: -0.0906 - val_loss: -0.6775 - val_out_loss: -1.2628 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7528 - out_loss: -1.4136 - rbf_fourier_loss: -0.0920 - val_loss: -0.6865 - val_out_loss: -1.2809 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7469 - out_loss: -1.4026 - rbf_fourier_loss: -0.0912 - val_loss: -0.7336 - val_out_loss: -1.3750 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7530 - out_loss: -1.4145 - rbf_fourier_loss: -0.0916 - val_loss: -0.6797 - val_out_loss: -1.2671 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7398 - out_loss: -1.3889 - rbf_fourier_loss: -0.0907 - val_loss: -0.7305 - val_out_loss: -1.3689 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7553 - out_loss: -1.4191 - rbf_fourier_loss: -0.0916 - val_loss: -0.7062 - val_out_loss: -1.3201 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7429 - out_loss: -1.3954 - rbf_fourier_loss: -0.0905 - val_loss: -0.7079 - val_out_loss: -1.3236 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7452 - out_loss: -1.3979 - rbf_fourier_loss: -0.0925 - val_loss: -0.6898 - val_out_loss: -1.2874 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7542 - out_loss: -1.4144 - rbf_fourier_loss: -0.0939 - val_loss: -0.6972 - val_out_loss: -1.3023 - val_rbf_fourier_loss: -0.0922\n",
            "it 1/10\n",
            "acc: 11.258333333333333\n",
            "ari: 0.004356702528525517\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 0.2660 - out_loss: 0.6227 - rbf_fourier_loss: -0.0906 - val_loss: 0.2662 - val_out_loss: 0.6251 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2643 - out_loss: 0.6212 - rbf_fourier_loss: -0.0927 - val_loss: 0.2669 - val_out_loss: 0.6265 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2645 - out_loss: 0.6205 - rbf_fourier_loss: -0.0915 - val_loss: 0.2660 - val_out_loss: 0.6247 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2644 - out_loss: 0.6191 - rbf_fourier_loss: -0.0904 - val_loss: 0.2651 - val_out_loss: 0.6229 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2604 - out_loss: 0.6117 - rbf_fourier_loss: -0.0909 - val_loss: 0.2625 - val_out_loss: 0.6177 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2565 - out_loss: 0.6036 - rbf_fourier_loss: -0.0907 - val_loss: 0.2646 - val_out_loss: 0.6219 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2577 - out_loss: 0.6065 - rbf_fourier_loss: -0.0910 - val_loss: 0.2620 - val_out_loss: 0.6167 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2587 - out_loss: 0.6088 - rbf_fourier_loss: -0.0913 - val_loss: 0.2614 - val_out_loss: 0.6156 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2571 - out_loss: 0.6053 - rbf_fourier_loss: -0.0910 - val_loss: 0.2600 - val_out_loss: 0.6128 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2566 - out_loss: 0.6049 - rbf_fourier_loss: -0.0918 - val_loss: 0.2575 - val_out_loss: 0.6078 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2519 - out_loss: 0.5958 - rbf_fourier_loss: -0.0920 - val_loss: 0.2577 - val_out_loss: 0.6082 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2507 - out_loss: 0.5938 - rbf_fourier_loss: -0.0924 - val_loss: 0.2525 - val_out_loss: 0.5977 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2535 - out_loss: 0.5997 - rbf_fourier_loss: -0.0926 - val_loss: 0.2520 - val_out_loss: 0.5967 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2520 - out_loss: 0.5957 - rbf_fourier_loss: -0.0917 - val_loss: 0.2514 - val_out_loss: 0.5956 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2441 - out_loss: 0.5804 - rbf_fourier_loss: -0.0921 - val_loss: 0.2485 - val_out_loss: 0.5897 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2456 - out_loss: 0.5829 - rbf_fourier_loss: -0.0916 - val_loss: 0.2452 - val_out_loss: 0.5832 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2424 - out_loss: 0.5771 - rbf_fourier_loss: -0.0922 - val_loss: 0.2402 - val_out_loss: 0.5732 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2369 - out_loss: 0.5651 - rbf_fourier_loss: -0.0912 - val_loss: 0.2368 - val_out_loss: 0.5664 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2340 - out_loss: 0.5579 - rbf_fourier_loss: -0.0899 - val_loss: 0.2329 - val_out_loss: 0.5585 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2294 - out_loss: 0.5499 - rbf_fourier_loss: -0.0910 - val_loss: 0.2307 - val_out_loss: 0.5541 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2223 - out_loss: 0.5350 - rbf_fourier_loss: -0.0904 - val_loss: 0.2242 - val_out_loss: 0.5411 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2110 - out_loss: 0.5134 - rbf_fourier_loss: -0.0914 - val_loss: 0.2131 - val_out_loss: 0.5189 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2076 - out_loss: 0.5076 - rbf_fourier_loss: -0.0924 - val_loss: 0.1939 - val_out_loss: 0.4805 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1794 - out_loss: 0.4495 - rbf_fourier_loss: -0.0908 - val_loss: 0.1493 - val_out_loss: 0.3914 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1111 - out_loss: 0.3140 - rbf_fourier_loss: -0.0918 - val_loss: -0.2881 - val_out_loss: -0.4835 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.5058 - out_loss: -0.9193 - rbf_fourier_loss: -0.0924 - val_loss: -0.7091 - val_out_loss: -1.3254 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0920 - out_loss: -2.0919 - rbf_fourier_loss: -0.0920 - val_loss: -1.4139 - val_out_loss: -2.7350 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.4171 - out_loss: -2.7436 - rbf_fourier_loss: -0.0907 - val_loss: -1.4245 - val_out_loss: -2.7562 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.4217 - out_loss: -2.7520 - rbf_fourier_loss: -0.0915 - val_loss: -1.4042 - val_out_loss: -2.7157 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4223 - out_loss: -2.7516 - rbf_fourier_loss: -0.0930 - val_loss: -1.4103 - val_out_loss: -2.7278 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3883 - out_loss: -2.6840 - rbf_fourier_loss: -0.0925 - val_loss: -1.3735 - val_out_loss: -2.6543 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3594 - out_loss: -2.6288 - rbf_fourier_loss: -0.0901 - val_loss: -1.3945 - val_out_loss: -2.6963 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3548 - out_loss: -2.6177 - rbf_fourier_loss: -0.0919 - val_loss: -1.3752 - val_out_loss: -2.6576 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3714 - out_loss: -2.6514 - rbf_fourier_loss: -0.0915 - val_loss: -1.3536 - val_out_loss: -2.6144 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3455 - out_loss: -2.5990 - rbf_fourier_loss: -0.0920 - val_loss: -1.3238 - val_out_loss: -2.5549 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3488 - out_loss: -2.6067 - rbf_fourier_loss: -0.0910 - val_loss: -1.3494 - val_out_loss: -2.6060 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2991 - out_loss: -2.5067 - rbf_fourier_loss: -0.0915 - val_loss: -1.3291 - val_out_loss: -2.5655 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3452 - out_loss: -2.5983 - rbf_fourier_loss: -0.0921 - val_loss: -1.2642 - val_out_loss: -2.4357 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2860 - out_loss: -2.4818 - rbf_fourier_loss: -0.0902 - val_loss: -1.3268 - val_out_loss: -2.5608 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3074 - out_loss: -2.5234 - rbf_fourier_loss: -0.0913 - val_loss: -1.3161 - val_out_loss: -2.5395 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2796 - out_loss: -2.4683 - rbf_fourier_loss: -0.0909 - val_loss: -1.2603 - val_out_loss: -2.4278 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -1.2402 - out_loss: -2.3891 - rbf_fourier_loss: -0.0913 - val_loss: -1.2436 - val_out_loss: -2.3944 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2578 - out_loss: -2.4243 - rbf_fourier_loss: -0.0914 - val_loss: -1.2856 - val_out_loss: -2.4784 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2570 - out_loss: -2.4240 - rbf_fourier_loss: -0.0899 - val_loss: -1.2684 - val_out_loss: -2.4440 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2361 - out_loss: -2.3814 - rbf_fourier_loss: -0.0909 - val_loss: -1.2619 - val_out_loss: -2.4311 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2584 - out_loss: -2.4262 - rbf_fourier_loss: -0.0906 - val_loss: -1.2382 - val_out_loss: -2.3837 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2259 - out_loss: -2.3596 - rbf_fourier_loss: -0.0921 - val_loss: -1.2658 - val_out_loss: -2.4389 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -1.2435 - out_loss: -2.3959 - rbf_fourier_loss: -0.0912 - val_loss: -1.2668 - val_out_loss: -2.4407 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1919 - out_loss: -2.2923 - rbf_fourier_loss: -0.0915 - val_loss: -1.2376 - val_out_loss: -2.3824 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1858 - out_loss: -2.2795 - rbf_fourier_loss: -0.0921 - val_loss: -1.2402 - val_out_loss: -2.3876 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1972 - out_loss: -2.3047 - rbf_fourier_loss: -0.0897 - val_loss: -1.2541 - val_out_loss: -2.4154 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1984 - out_loss: -2.3037 - rbf_fourier_loss: -0.0931 - val_loss: -1.2339 - val_out_loss: -2.3751 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1899 - out_loss: -2.2886 - rbf_fourier_loss: -0.0913 - val_loss: -1.2094 - val_out_loss: -2.3260 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1490 - out_loss: -2.2066 - rbf_fourier_loss: -0.0914 - val_loss: -1.1864 - val_out_loss: -2.2801 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2270 - out_loss: -2.3610 - rbf_fourier_loss: -0.0930 - val_loss: -1.2030 - val_out_loss: -2.3133 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1652 - out_loss: -2.2387 - rbf_fourier_loss: -0.0917 - val_loss: -1.1759 - val_out_loss: -2.2590 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2193 - out_loss: -2.3465 - rbf_fourier_loss: -0.0921 - val_loss: -1.1581 - val_out_loss: -2.2235 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1414 - out_loss: -2.1906 - rbf_fourier_loss: -0.0921 - val_loss: -1.1730 - val_out_loss: -2.2532 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2034 - out_loss: -2.3146 - rbf_fourier_loss: -0.0923 - val_loss: -1.0822 - val_out_loss: -2.0717 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1474 - out_loss: -2.2030 - rbf_fourier_loss: -0.0918 - val_loss: -1.1522 - val_out_loss: -2.2117 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1515 - out_loss: -2.2118 - rbf_fourier_loss: -0.0913 - val_loss: -1.1144 - val_out_loss: -2.1361 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2083 - out_loss: -2.3248 - rbf_fourier_loss: -0.0918 - val_loss: -1.1313 - val_out_loss: -2.1697 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1759 - out_loss: -2.2608 - rbf_fourier_loss: -0.0911 - val_loss: -1.1633 - val_out_loss: -2.2339 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1658 - out_loss: -2.2379 - rbf_fourier_loss: -0.0936 - val_loss: -1.1023 - val_out_loss: -2.1119 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1979 - out_loss: -2.3058 - rbf_fourier_loss: -0.0899 - val_loss: -1.0920 - val_out_loss: -2.0913 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1547 - out_loss: -2.2175 - rbf_fourier_loss: -0.0919 - val_loss: -1.0668 - val_out_loss: -2.0409 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1296 - out_loss: -2.1679 - rbf_fourier_loss: -0.0913 - val_loss: -1.0838 - val_out_loss: -2.0749 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1124 - out_loss: -2.1331 - rbf_fourier_loss: -0.0918 - val_loss: -1.1203 - val_out_loss: -2.1478 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1350 - out_loss: -2.1795 - rbf_fourier_loss: -0.0906 - val_loss: -1.0607 - val_out_loss: -2.0286 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1184 - out_loss: -2.1471 - rbf_fourier_loss: -0.0898 - val_loss: -1.1436 - val_out_loss: -2.1944 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1198 - out_loss: -2.1479 - rbf_fourier_loss: -0.0917 - val_loss: -1.1140 - val_out_loss: -2.1353 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1062 - out_loss: -2.1211 - rbf_fourier_loss: -0.0912 - val_loss: -1.0954 - val_out_loss: -2.0981 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1250 - out_loss: -2.1575 - rbf_fourier_loss: -0.0924 - val_loss: -1.0962 - val_out_loss: -2.0996 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0826 - out_loss: -2.0735 - rbf_fourier_loss: -0.0918 - val_loss: -1.0914 - val_out_loss: -2.0901 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1304 - out_loss: -2.1694 - rbf_fourier_loss: -0.0913 - val_loss: -1.0747 - val_out_loss: -2.0566 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1306 - out_loss: -2.1689 - rbf_fourier_loss: -0.0924 - val_loss: -1.0751 - val_out_loss: -2.0574 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1597 - out_loss: -2.2292 - rbf_fourier_loss: -0.0902 - val_loss: -1.1131 - val_out_loss: -2.1335 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1176 - out_loss: -2.1422 - rbf_fourier_loss: -0.0930 - val_loss: -1.1225 - val_out_loss: -2.1523 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1447 - out_loss: -2.1987 - rbf_fourier_loss: -0.0907 - val_loss: -1.0519 - val_out_loss: -2.0111 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0437 - out_loss: -1.9951 - rbf_fourier_loss: -0.0922 - val_loss: -0.9930 - val_out_loss: -1.8932 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0839 - out_loss: -2.0760 - rbf_fourier_loss: -0.0918 - val_loss: -1.0322 - val_out_loss: -1.9717 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0976 - out_loss: -2.1032 - rbf_fourier_loss: -0.0920 - val_loss: -1.0003 - val_out_loss: -1.9078 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1425 - out_loss: -2.1936 - rbf_fourier_loss: -0.0915 - val_loss: -1.0382 - val_out_loss: -1.9837 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1374 - out_loss: -2.1832 - rbf_fourier_loss: -0.0916 - val_loss: -1.0055 - val_out_loss: -1.9182 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1128 - out_loss: -2.1340 - rbf_fourier_loss: -0.0915 - val_loss: -0.9757 - val_out_loss: -1.8587 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0917 - out_loss: -2.0912 - rbf_fourier_loss: -0.0921 - val_loss: -0.9966 - val_out_loss: -1.9005 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0972 - out_loss: -2.1034 - rbf_fourier_loss: -0.0911 - val_loss: -0.9501 - val_out_loss: -1.8074 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0684 - out_loss: -2.0465 - rbf_fourier_loss: -0.0903 - val_loss: -0.9823 - val_out_loss: -1.8719 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1014 - out_loss: -2.1117 - rbf_fourier_loss: -0.0911 - val_loss: -1.0090 - val_out_loss: -1.9252 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0979 - out_loss: -2.1049 - rbf_fourier_loss: -0.0908 - val_loss: -1.0295 - val_out_loss: -1.9663 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1204 - out_loss: -2.1505 - rbf_fourier_loss: -0.0904 - val_loss: -1.0089 - val_out_loss: -1.9251 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1168 - out_loss: -2.1424 - rbf_fourier_loss: -0.0912 - val_loss: -0.9804 - val_out_loss: -1.8680 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1014 - out_loss: -2.1107 - rbf_fourier_loss: -0.0920 - val_loss: -1.0246 - val_out_loss: -1.9565 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1547 - out_loss: -2.2181 - rbf_fourier_loss: -0.0914 - val_loss: -0.9906 - val_out_loss: -1.8885 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0246 - out_loss: -1.9589 - rbf_fourier_loss: -0.0903 - val_loss: -1.0096 - val_out_loss: -1.9265 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0805 - out_loss: -2.0695 - rbf_fourier_loss: -0.0916 - val_loss: -0.9235 - val_out_loss: -1.7543 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0937 - out_loss: -2.0962 - rbf_fourier_loss: -0.0913 - val_loss: -1.0402 - val_out_loss: -1.9877 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1473 - out_loss: -2.2033 - rbf_fourier_loss: -0.0912 - val_loss: -0.9587 - val_out_loss: -1.8246 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1036 - out_loss: -2.1150 - rbf_fourier_loss: -0.0922 - val_loss: -0.9742 - val_out_loss: -1.8556 - val_rbf_fourier_loss: -0.0928\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1051 - out_loss: -2.1172 - rbf_fourier_loss: -0.0930 - val_loss: -1.0586 - val_out_loss: -2.0244 - val_rbf_fourier_loss: -0.0928\n",
            "it 1/10\n",
            "acc: 11.248333333333333\n",
            "ari: 2.827056380395375e-05\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 0.4516 - out_loss: 1.0001 - rbf_fourier_loss: -0.0969 - val_loss: 0.4505 - val_out_loss: 0.9956 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4456 - out_loss: 0.9888 - rbf_fourier_loss: -0.0977 - val_loss: 0.4499 - val_out_loss: 0.9944 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4471 - out_loss: 0.9894 - rbf_fourier_loss: -0.0953 - val_loss: 0.4495 - val_out_loss: 0.9936 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4436 - out_loss: 0.9833 - rbf_fourier_loss: -0.0961 - val_loss: 0.4485 - val_out_loss: 0.9917 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4423 - out_loss: 0.9800 - rbf_fourier_loss: -0.0955 - val_loss: 0.4478 - val_out_loss: 0.9903 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4432 - out_loss: 0.9826 - rbf_fourier_loss: -0.0962 - val_loss: 0.4467 - val_out_loss: 0.9880 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4412 - out_loss: 0.9785 - rbf_fourier_loss: -0.0961 - val_loss: 0.4450 - val_out_loss: 0.9846 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4396 - out_loss: 0.9737 - rbf_fourier_loss: -0.0944 - val_loss: 0.4445 - val_out_loss: 0.9837 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4361 - out_loss: 0.9697 - rbf_fourier_loss: -0.0974 - val_loss: 0.4432 - val_out_loss: 0.9812 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4339 - out_loss: 0.9632 - rbf_fourier_loss: -0.0954 - val_loss: 0.4417 - val_out_loss: 0.9780 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4323 - out_loss: 0.9602 - rbf_fourier_loss: -0.0955 - val_loss: 0.4396 - val_out_loss: 0.9739 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4333 - out_loss: 0.9619 - rbf_fourier_loss: -0.0953 - val_loss: 0.4377 - val_out_loss: 0.9701 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4290 - out_loss: 0.9540 - rbf_fourier_loss: -0.0960 - val_loss: 0.4368 - val_out_loss: 0.9683 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4252 - out_loss: 0.9470 - rbf_fourier_loss: -0.0965 - val_loss: 0.4322 - val_out_loss: 0.9591 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4266 - out_loss: 0.9486 - rbf_fourier_loss: -0.0954 - val_loss: 0.4311 - val_out_loss: 0.9569 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4232 - out_loss: 0.9422 - rbf_fourier_loss: -0.0958 - val_loss: 0.4280 - val_out_loss: 0.9507 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4256 - out_loss: 0.9469 - rbf_fourier_loss: -0.0956 - val_loss: 0.4253 - val_out_loss: 0.9453 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4191 - out_loss: 0.9339 - rbf_fourier_loss: -0.0958 - val_loss: 0.4221 - val_out_loss: 0.9389 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4128 - out_loss: 0.9223 - rbf_fourier_loss: -0.0966 - val_loss: 0.4160 - val_out_loss: 0.9267 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4059 - out_loss: 0.9072 - rbf_fourier_loss: -0.0954 - val_loss: 0.4084 - val_out_loss: 0.9115 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4003 - out_loss: 0.8974 - rbf_fourier_loss: -0.0968 - val_loss: 0.4000 - val_out_loss: 0.8948 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.3936 - out_loss: 0.8830 - rbf_fourier_loss: -0.0958 - val_loss: 0.3862 - val_out_loss: 0.8672 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.3702 - out_loss: 0.8348 - rbf_fourier_loss: -0.0944 - val_loss: 0.3588 - val_out_loss: 0.8122 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.3253 - out_loss: 0.7462 - rbf_fourier_loss: -0.0956 - val_loss: 0.2446 - val_out_loss: 0.5839 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.0157 - out_loss: 0.1268 - rbf_fourier_loss: -0.0955 - val_loss: -0.3125 - val_out_loss: -0.5304 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.6770 - out_loss: -1.2596 - rbf_fourier_loss: -0.0943 - val_loss: -1.1774 - val_out_loss: -2.2601 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2211 - out_loss: -2.3477 - rbf_fourier_loss: -0.0946 - val_loss: -1.2361 - val_out_loss: -2.3775 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2337 - out_loss: -2.3731 - rbf_fourier_loss: -0.0942 - val_loss: -1.2420 - val_out_loss: -2.3894 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2274 - out_loss: -2.3574 - rbf_fourier_loss: -0.0974 - val_loss: -1.2280 - val_out_loss: -2.3613 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1780 - out_loss: -2.2594 - rbf_fourier_loss: -0.0966 - val_loss: -1.2261 - val_out_loss: -2.3576 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1937 - out_loss: -2.2921 - rbf_fourier_loss: -0.0953 - val_loss: -1.2129 - val_out_loss: -2.3310 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2169 - out_loss: -2.3378 - rbf_fourier_loss: -0.0959 - val_loss: -1.1983 - val_out_loss: -2.3019 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1602 - out_loss: -2.2258 - rbf_fourier_loss: -0.0947 - val_loss: -1.1583 - val_out_loss: -2.2220 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1524 - out_loss: -2.2097 - rbf_fourier_loss: -0.0950 - val_loss: -1.1526 - val_out_loss: -2.2106 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1697 - out_loss: -2.2416 - rbf_fourier_loss: -0.0979 - val_loss: -1.1576 - val_out_loss: -2.2205 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1484 - out_loss: -2.2006 - rbf_fourier_loss: -0.0961 - val_loss: -1.1807 - val_out_loss: -2.2666 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1355 - out_loss: -2.1748 - rbf_fourier_loss: -0.0962 - val_loss: -1.1260 - val_out_loss: -2.1572 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1169 - out_loss: -2.1371 - rbf_fourier_loss: -0.0966 - val_loss: -1.1210 - val_out_loss: -2.1473 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1333 - out_loss: -2.1707 - rbf_fourier_loss: -0.0959 - val_loss: -1.0946 - val_out_loss: -2.0944 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1186 - out_loss: -2.1401 - rbf_fourier_loss: -0.0970 - val_loss: -1.1010 - val_out_loss: -2.1073 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1224 - out_loss: -2.1485 - rbf_fourier_loss: -0.0962 - val_loss: -1.1029 - val_out_loss: -2.1110 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0727 - out_loss: -2.0513 - rbf_fourier_loss: -0.0941 - val_loss: -1.0556 - val_out_loss: -2.0165 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0765 - out_loss: -2.0569 - rbf_fourier_loss: -0.0961 - val_loss: -1.0462 - val_out_loss: -1.9977 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0740 - out_loss: -2.0514 - rbf_fourier_loss: -0.0966 - val_loss: -1.0537 - val_out_loss: -2.0126 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0478 - out_loss: -1.9995 - rbf_fourier_loss: -0.0961 - val_loss: -1.0449 - val_out_loss: -1.9951 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0354 - out_loss: -1.9736 - rbf_fourier_loss: -0.0972 - val_loss: -0.9932 - val_out_loss: -1.8918 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0418 - out_loss: -1.9878 - rbf_fourier_loss: -0.0959 - val_loss: -1.0241 - val_out_loss: -1.9535 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0467 - out_loss: -1.9962 - rbf_fourier_loss: -0.0972 - val_loss: -0.9672 - val_out_loss: -1.8398 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0352 - out_loss: -1.9758 - rbf_fourier_loss: -0.0947 - val_loss: -1.0132 - val_out_loss: -1.9316 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0282 - out_loss: -1.9581 - rbf_fourier_loss: -0.0984 - val_loss: -1.0369 - val_out_loss: -1.9791 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0168 - out_loss: -1.9379 - rbf_fourier_loss: -0.0957 - val_loss: -1.0381 - val_out_loss: -1.9815 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0004 - out_loss: -1.9062 - rbf_fourier_loss: -0.0946 - val_loss: -0.9852 - val_out_loss: -1.8757 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0417 - out_loss: -1.9871 - rbf_fourier_loss: -0.0963 - val_loss: -1.0054 - val_out_loss: -1.9162 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0324 - out_loss: -1.9677 - rbf_fourier_loss: -0.0970 - val_loss: -1.0081 - val_out_loss: -1.9215 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0493 - out_loss: -2.0028 - rbf_fourier_loss: -0.0959 - val_loss: -0.9540 - val_out_loss: -1.8134 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9993 - out_loss: -1.9022 - rbf_fourier_loss: -0.0964 - val_loss: -0.9277 - val_out_loss: -1.7607 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9913 - out_loss: -1.8859 - rbf_fourier_loss: -0.0966 - val_loss: -0.9518 - val_out_loss: -1.8090 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9809 - out_loss: -1.8646 - rbf_fourier_loss: -0.0972 - val_loss: -0.9891 - val_out_loss: -1.8836 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9811 - out_loss: -1.8658 - rbf_fourier_loss: -0.0963 - val_loss: -0.9645 - val_out_loss: -1.8343 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0086 - out_loss: -1.9210 - rbf_fourier_loss: -0.0961 - val_loss: -0.9713 - val_out_loss: -1.8479 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9759 - out_loss: -1.8562 - rbf_fourier_loss: -0.0956 - val_loss: -0.9478 - val_out_loss: -1.8008 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9813 - out_loss: -1.8656 - rbf_fourier_loss: -0.0971 - val_loss: -0.9091 - val_out_loss: -1.7236 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9636 - out_loss: -1.8315 - rbf_fourier_loss: -0.0958 - val_loss: -0.9383 - val_out_loss: -1.7819 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9612 - out_loss: -1.8277 - rbf_fourier_loss: -0.0946 - val_loss: -0.9695 - val_out_loss: -1.8444 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9183 - out_loss: -1.7398 - rbf_fourier_loss: -0.0967 - val_loss: -0.9507 - val_out_loss: -1.8066 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9777 - out_loss: -1.8601 - rbf_fourier_loss: -0.0953 - val_loss: -0.9297 - val_out_loss: -1.7647 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9885 - out_loss: -1.8796 - rbf_fourier_loss: -0.0974 - val_loss: -0.9527 - val_out_loss: -1.8107 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0073 - out_loss: -1.9187 - rbf_fourier_loss: -0.0958 - val_loss: -0.9461 - val_out_loss: -1.7976 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9720 - out_loss: -1.8481 - rbf_fourier_loss: -0.0960 - val_loss: -0.8881 - val_out_loss: -1.6814 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9324 - out_loss: -1.7672 - rbf_fourier_loss: -0.0975 - val_loss: -0.9242 - val_out_loss: -1.7537 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9605 - out_loss: -1.8264 - rbf_fourier_loss: -0.0946 - val_loss: -0.9279 - val_out_loss: -1.7612 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9102 - out_loss: -1.7227 - rbf_fourier_loss: -0.0977 - val_loss: -0.8924 - val_out_loss: -1.6900 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9828 - out_loss: -1.8686 - rbf_fourier_loss: -0.0971 - val_loss: -0.9544 - val_out_loss: -1.8141 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9812 - out_loss: -1.8674 - rbf_fourier_loss: -0.0950 - val_loss: -0.8807 - val_out_loss: -1.6667 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9463 - out_loss: -1.7957 - rbf_fourier_loss: -0.0968 - val_loss: -0.9118 - val_out_loss: -1.7289 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9485 - out_loss: -1.8003 - rbf_fourier_loss: -0.0967 - val_loss: -0.9056 - val_out_loss: -1.7164 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9237 - out_loss: -1.7512 - rbf_fourier_loss: -0.0962 - val_loss: -0.9410 - val_out_loss: -1.7873 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9548 - out_loss: -1.8143 - rbf_fourier_loss: -0.0953 - val_loss: -0.9121 - val_out_loss: -1.7295 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0170 - out_loss: -1.9399 - rbf_fourier_loss: -0.0942 - val_loss: -0.9166 - val_out_loss: -1.7385 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9179 - out_loss: -1.7389 - rbf_fourier_loss: -0.0968 - val_loss: -0.8456 - val_out_loss: -1.5965 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9591 - out_loss: -1.8213 - rbf_fourier_loss: -0.0968 - val_loss: -0.8804 - val_out_loss: -1.6661 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.8926 - out_loss: -1.6899 - rbf_fourier_loss: -0.0954 - val_loss: -0.9177 - val_out_loss: -1.7408 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9131 - out_loss: -1.7302 - rbf_fourier_loss: -0.0959 - val_loss: -0.9088 - val_out_loss: -1.7228 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9501 - out_loss: -1.8042 - rbf_fourier_loss: -0.0961 - val_loss: -0.9540 - val_out_loss: -1.8134 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9650 - out_loss: -1.8342 - rbf_fourier_loss: -0.0958 - val_loss: -0.8932 - val_out_loss: -1.6918 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9799 - out_loss: -1.8631 - rbf_fourier_loss: -0.0967 - val_loss: -0.9326 - val_out_loss: -1.7705 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9042 - out_loss: -1.7133 - rbf_fourier_loss: -0.0952 - val_loss: -0.8672 - val_out_loss: -1.6398 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.8951 - out_loss: -1.6938 - rbf_fourier_loss: -0.0963 - val_loss: -0.8178 - val_out_loss: -1.5409 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9218 - out_loss: -1.7484 - rbf_fourier_loss: -0.0952 - val_loss: -0.8585 - val_out_loss: -1.6223 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9796 - out_loss: -1.8644 - rbf_fourier_loss: -0.0949 - val_loss: -0.8082 - val_out_loss: -1.5218 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9486 - out_loss: -1.8007 - rbf_fourier_loss: -0.0965 - val_loss: -0.8409 - val_out_loss: -1.5872 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9318 - out_loss: -1.7681 - rbf_fourier_loss: -0.0955 - val_loss: -0.8370 - val_out_loss: -1.5793 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9165 - out_loss: -1.7363 - rbf_fourier_loss: -0.0967 - val_loss: -0.8352 - val_out_loss: -1.5758 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9407 - out_loss: -1.7863 - rbf_fourier_loss: -0.0950 - val_loss: -0.8432 - val_out_loss: -1.5917 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9194 - out_loss: -1.7433 - rbf_fourier_loss: -0.0955 - val_loss: -0.8894 - val_out_loss: -1.6842 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9365 - out_loss: -1.7767 - rbf_fourier_loss: -0.0962 - val_loss: -0.8514 - val_out_loss: -1.6081 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.8953 - out_loss: -1.6939 - rbf_fourier_loss: -0.0966 - val_loss: -0.8846 - val_out_loss: -1.6746 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9061 - out_loss: -1.7160 - rbf_fourier_loss: -0.0962 - val_loss: -0.8642 - val_out_loss: -1.6337 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.8948 - out_loss: -1.6951 - rbf_fourier_loss: -0.0944 - val_loss: -0.8199 - val_out_loss: -1.5450 - val_rbf_fourier_loss: -0.0947\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9229 - out_loss: -1.7496 - rbf_fourier_loss: -0.0963 - val_loss: -0.8330 - val_out_loss: -1.5714 - val_rbf_fourier_loss: -0.0947\n",
            "it 1/10\n",
            "acc: 11.246666666666668\n",
            "ari: 0.0001735030347279119\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 20ms/step - loss: 4.4811 - out_loss: 4.7339 - rbf_fourier_loss: 4.2283 - val_loss: 4.4858 - val_out_loss: 4.7459 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4770 - out_loss: 4.7263 - rbf_fourier_loss: 4.2277 - val_loss: 4.4869 - val_out_loss: 4.7480 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4741 - out_loss: 4.7195 - rbf_fourier_loss: 4.2287 - val_loss: 4.4849 - val_out_loss: 4.7440 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4727 - out_loss: 4.7166 - rbf_fourier_loss: 4.2289 - val_loss: 4.4880 - val_out_loss: 4.7503 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4668 - out_loss: 4.7087 - rbf_fourier_loss: 4.2249 - val_loss: 4.4880 - val_out_loss: 4.7502 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4652 - out_loss: 4.7009 - rbf_fourier_loss: 4.2295 - val_loss: 4.4881 - val_out_loss: 4.7504 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4610 - out_loss: 4.6933 - rbf_fourier_loss: 4.2288 - val_loss: 4.4871 - val_out_loss: 4.7484 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4794 - out_loss: 4.7295 - rbf_fourier_loss: 4.2293 - val_loss: 4.4854 - val_out_loss: 4.7452 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4731 - out_loss: 4.7180 - rbf_fourier_loss: 4.2283 - val_loss: 4.4868 - val_out_loss: 4.7479 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4587 - out_loss: 4.6881 - rbf_fourier_loss: 4.2293 - val_loss: 4.4865 - val_out_loss: 4.7473 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4759 - out_loss: 4.7239 - rbf_fourier_loss: 4.2279 - val_loss: 4.4889 - val_out_loss: 4.7521 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4709 - out_loss: 4.7133 - rbf_fourier_loss: 4.2285 - val_loss: 4.4839 - val_out_loss: 4.7420 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4588 - out_loss: 4.6905 - rbf_fourier_loss: 4.2270 - val_loss: 4.4820 - val_out_loss: 4.7384 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4565 - out_loss: 4.6853 - rbf_fourier_loss: 4.2276 - val_loss: 4.4833 - val_out_loss: 4.7408 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4675 - out_loss: 4.7056 - rbf_fourier_loss: 4.2294 - val_loss: 4.4827 - val_out_loss: 4.7398 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4613 - out_loss: 4.6925 - rbf_fourier_loss: 4.2302 - val_loss: 4.4846 - val_out_loss: 4.7435 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4619 - out_loss: 4.6947 - rbf_fourier_loss: 4.2291 - val_loss: 4.4822 - val_out_loss: 4.7387 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4685 - out_loss: 4.7085 - rbf_fourier_loss: 4.2284 - val_loss: 4.4814 - val_out_loss: 4.7370 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4736 - out_loss: 4.7175 - rbf_fourier_loss: 4.2298 - val_loss: 4.4841 - val_out_loss: 4.7424 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4734 - out_loss: 4.7188 - rbf_fourier_loss: 4.2280 - val_loss: 4.4889 - val_out_loss: 4.7520 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4583 - out_loss: 4.6878 - rbf_fourier_loss: 4.2289 - val_loss: 4.4880 - val_out_loss: 4.7503 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4692 - out_loss: 4.7085 - rbf_fourier_loss: 4.2300 - val_loss: 4.4894 - val_out_loss: 4.7531 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4690 - out_loss: 4.7082 - rbf_fourier_loss: 4.2298 - val_loss: 4.4861 - val_out_loss: 4.7465 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4628 - out_loss: 4.6979 - rbf_fourier_loss: 4.2276 - val_loss: 4.4852 - val_out_loss: 4.7446 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4642 - out_loss: 4.7002 - rbf_fourier_loss: 4.2282 - val_loss: 4.4898 - val_out_loss: 4.7538 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4654 - out_loss: 4.7038 - rbf_fourier_loss: 4.2270 - val_loss: 4.4905 - val_out_loss: 4.7553 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4633 - out_loss: 4.6994 - rbf_fourier_loss: 4.2272 - val_loss: 4.4859 - val_out_loss: 4.7460 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4586 - out_loss: 4.6888 - rbf_fourier_loss: 4.2284 - val_loss: 4.4856 - val_out_loss: 4.7456 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4567 - out_loss: 4.6860 - rbf_fourier_loss: 4.2274 - val_loss: 4.4833 - val_out_loss: 4.7409 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4541 - out_loss: 4.6784 - rbf_fourier_loss: 4.2297 - val_loss: 4.4826 - val_out_loss: 4.7396 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4433 - out_loss: 4.6577 - rbf_fourier_loss: 4.2290 - val_loss: 4.4809 - val_out_loss: 4.7360 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4539 - out_loss: 4.6809 - rbf_fourier_loss: 4.2269 - val_loss: 4.4802 - val_out_loss: 4.7346 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4561 - out_loss: 4.6840 - rbf_fourier_loss: 4.2283 - val_loss: 4.4814 - val_out_loss: 4.7371 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4591 - out_loss: 4.6882 - rbf_fourier_loss: 4.2299 - val_loss: 4.4801 - val_out_loss: 4.7345 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4788 - out_loss: 4.7267 - rbf_fourier_loss: 4.2310 - val_loss: 4.4840 - val_out_loss: 4.7422 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4606 - out_loss: 4.6933 - rbf_fourier_loss: 4.2279 - val_loss: 4.4825 - val_out_loss: 4.7392 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4547 - out_loss: 4.6820 - rbf_fourier_loss: 4.2273 - val_loss: 4.4825 - val_out_loss: 4.7393 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4554 - out_loss: 4.6795 - rbf_fourier_loss: 4.2312 - val_loss: 4.4820 - val_out_loss: 4.7382 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4436 - out_loss: 4.6595 - rbf_fourier_loss: 4.2278 - val_loss: 4.4810 - val_out_loss: 4.7364 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4544 - out_loss: 4.6797 - rbf_fourier_loss: 4.2291 - val_loss: 4.4750 - val_out_loss: 4.7243 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4523 - out_loss: 4.6748 - rbf_fourier_loss: 4.2298 - val_loss: 4.4791 - val_out_loss: 4.7324 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4403 - out_loss: 4.6535 - rbf_fourier_loss: 4.2270 - val_loss: 4.4778 - val_out_loss: 4.7298 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4551 - out_loss: 4.6813 - rbf_fourier_loss: 4.2289 - val_loss: 4.4788 - val_out_loss: 4.7319 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4507 - out_loss: 4.6737 - rbf_fourier_loss: 4.2277 - val_loss: 4.4762 - val_out_loss: 4.7267 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4417 - out_loss: 4.6555 - rbf_fourier_loss: 4.2278 - val_loss: 4.4756 - val_out_loss: 4.7255 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4458 - out_loss: 4.6606 - rbf_fourier_loss: 4.2310 - val_loss: 4.4779 - val_out_loss: 4.7300 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4431 - out_loss: 4.6577 - rbf_fourier_loss: 4.2285 - val_loss: 4.4782 - val_out_loss: 4.7306 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4556 - out_loss: 4.6822 - rbf_fourier_loss: 4.2290 - val_loss: 4.4742 - val_out_loss: 4.7227 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4587 - out_loss: 4.6884 - rbf_fourier_loss: 4.2289 - val_loss: 4.4782 - val_out_loss: 4.7306 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4516 - out_loss: 4.6768 - rbf_fourier_loss: 4.2265 - val_loss: 4.4826 - val_out_loss: 4.7395 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4522 - out_loss: 4.6780 - rbf_fourier_loss: 4.2263 - val_loss: 4.4805 - val_out_loss: 4.7352 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4443 - out_loss: 4.6615 - rbf_fourier_loss: 4.2271 - val_loss: 4.4775 - val_out_loss: 4.7293 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4363 - out_loss: 4.6430 - rbf_fourier_loss: 4.2296 - val_loss: 4.4824 - val_out_loss: 4.7390 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4493 - out_loss: 4.6694 - rbf_fourier_loss: 4.2291 - val_loss: 4.4810 - val_out_loss: 4.7364 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4404 - out_loss: 4.6522 - rbf_fourier_loss: 4.2285 - val_loss: 4.4799 - val_out_loss: 4.7341 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4476 - out_loss: 4.6677 - rbf_fourier_loss: 4.2275 - val_loss: 4.4768 - val_out_loss: 4.7278 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4548 - out_loss: 4.6819 - rbf_fourier_loss: 4.2276 - val_loss: 4.4748 - val_out_loss: 4.7239 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4411 - out_loss: 4.6547 - rbf_fourier_loss: 4.2274 - val_loss: 4.4799 - val_out_loss: 4.7340 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4458 - out_loss: 4.6642 - rbf_fourier_loss: 4.2273 - val_loss: 4.4791 - val_out_loss: 4.7324 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4363 - out_loss: 4.6451 - rbf_fourier_loss: 4.2275 - val_loss: 4.4759 - val_out_loss: 4.7260 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4347 - out_loss: 4.6407 - rbf_fourier_loss: 4.2286 - val_loss: 4.4752 - val_out_loss: 4.7247 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4394 - out_loss: 4.6502 - rbf_fourier_loss: 4.2286 - val_loss: 4.4783 - val_out_loss: 4.7310 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4319 - out_loss: 4.6354 - rbf_fourier_loss: 4.2285 - val_loss: 4.4757 - val_out_loss: 4.7256 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4425 - out_loss: 4.6584 - rbf_fourier_loss: 4.2265 - val_loss: 4.4760 - val_out_loss: 4.7263 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4363 - out_loss: 4.6447 - rbf_fourier_loss: 4.2280 - val_loss: 4.4765 - val_out_loss: 4.7273 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4360 - out_loss: 4.6445 - rbf_fourier_loss: 4.2276 - val_loss: 4.4752 - val_out_loss: 4.7246 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4471 - out_loss: 4.6641 - rbf_fourier_loss: 4.2301 - val_loss: 4.4756 - val_out_loss: 4.7254 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4408 - out_loss: 4.6526 - rbf_fourier_loss: 4.2290 - val_loss: 4.4748 - val_out_loss: 4.7238 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4457 - out_loss: 4.6633 - rbf_fourier_loss: 4.2282 - val_loss: 4.4740 - val_out_loss: 4.7222 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4419 - out_loss: 4.6545 - rbf_fourier_loss: 4.2292 - val_loss: 4.4739 - val_out_loss: 4.7220 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4437 - out_loss: 4.6566 - rbf_fourier_loss: 4.2309 - val_loss: 4.4737 - val_out_loss: 4.7217 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4301 - out_loss: 4.6314 - rbf_fourier_loss: 4.2287 - val_loss: 4.4748 - val_out_loss: 4.7239 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4379 - out_loss: 4.6469 - rbf_fourier_loss: 4.2289 - val_loss: 4.4786 - val_out_loss: 4.7315 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4392 - out_loss: 4.6484 - rbf_fourier_loss: 4.2300 - val_loss: 4.4741 - val_out_loss: 4.7225 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4363 - out_loss: 4.6449 - rbf_fourier_loss: 4.2276 - val_loss: 4.4710 - val_out_loss: 4.7162 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4283 - out_loss: 4.6285 - rbf_fourier_loss: 4.2281 - val_loss: 4.4719 - val_out_loss: 4.7181 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4369 - out_loss: 4.6469 - rbf_fourier_loss: 4.2269 - val_loss: 4.4744 - val_out_loss: 4.7232 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4319 - out_loss: 4.6364 - rbf_fourier_loss: 4.2275 - val_loss: 4.4738 - val_out_loss: 4.7218 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4440 - out_loss: 4.6582 - rbf_fourier_loss: 4.2299 - val_loss: 4.4710 - val_out_loss: 4.7164 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4373 - out_loss: 4.6473 - rbf_fourier_loss: 4.2272 - val_loss: 4.4708 - val_out_loss: 4.7158 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4354 - out_loss: 4.6426 - rbf_fourier_loss: 4.2282 - val_loss: 4.4733 - val_out_loss: 4.7208 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4331 - out_loss: 4.6363 - rbf_fourier_loss: 4.2299 - val_loss: 4.4721 - val_out_loss: 4.7186 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4330 - out_loss: 4.6382 - rbf_fourier_loss: 4.2277 - val_loss: 4.4736 - val_out_loss: 4.7216 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 2s 9ms/step - loss: 4.4317 - out_loss: 4.6341 - rbf_fourier_loss: 4.2294 - val_loss: 4.4726 - val_out_loss: 4.7194 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4340 - out_loss: 4.6416 - rbf_fourier_loss: 4.2264 - val_loss: 4.4732 - val_out_loss: 4.7207 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4310 - out_loss: 4.6344 - rbf_fourier_loss: 4.2277 - val_loss: 4.4702 - val_out_loss: 4.7147 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4366 - out_loss: 4.6467 - rbf_fourier_loss: 4.2264 - val_loss: 4.4668 - val_out_loss: 4.7079 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4313 - out_loss: 4.6331 - rbf_fourier_loss: 4.2294 - val_loss: 4.4666 - val_out_loss: 4.7074 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4408 - out_loss: 4.6514 - rbf_fourier_loss: 4.2301 - val_loss: 4.4701 - val_out_loss: 4.7146 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4326 - out_loss: 4.6356 - rbf_fourier_loss: 4.2295 - val_loss: 4.4697 - val_out_loss: 4.7137 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4330 - out_loss: 4.6389 - rbf_fourier_loss: 4.2271 - val_loss: 4.4703 - val_out_loss: 4.7149 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4242 - out_loss: 4.6208 - rbf_fourier_loss: 4.2276 - val_loss: 4.4656 - val_out_loss: 4.7054 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4244 - out_loss: 4.6204 - rbf_fourier_loss: 4.2285 - val_loss: 4.4692 - val_out_loss: 4.7126 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4124 - out_loss: 4.5951 - rbf_fourier_loss: 4.2296 - val_loss: 4.4708 - val_out_loss: 4.7159 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4186 - out_loss: 4.6094 - rbf_fourier_loss: 4.2278 - val_loss: 4.4680 - val_out_loss: 4.7103 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4319 - out_loss: 4.6349 - rbf_fourier_loss: 4.2290 - val_loss: 4.4705 - val_out_loss: 4.7152 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4245 - out_loss: 4.6187 - rbf_fourier_loss: 4.2302 - val_loss: 4.4649 - val_out_loss: 4.7041 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4321 - out_loss: 4.6354 - rbf_fourier_loss: 4.2288 - val_loss: 4.4703 - val_out_loss: 4.7148 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4329 - out_loss: 4.6355 - rbf_fourier_loss: 4.2302 - val_loss: 4.4687 - val_out_loss: 4.7117 - val_rbf_fourier_loss: 4.2257\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4272 - out_loss: 4.6260 - rbf_fourier_loss: 4.2285 - val_loss: 4.4690 - val_out_loss: 4.7123 - val_rbf_fourier_loss: 4.2257\n",
            "it 2/10\n",
            "acc: 11.273333333333333\n",
            "ari: 0.004212996498253546\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 4.4867 - out_loss: 4.7461 - rbf_fourier_loss: 4.2272 - val_loss: 4.4808 - val_out_loss: 4.7401 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4755 - out_loss: 4.7247 - rbf_fourier_loss: 4.2263 - val_loss: 4.4793 - val_out_loss: 4.7370 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4677 - out_loss: 4.7080 - rbf_fourier_loss: 4.2274 - val_loss: 4.4827 - val_out_loss: 4.7438 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4568 - out_loss: 4.6880 - rbf_fourier_loss: 4.2257 - val_loss: 4.4863 - val_out_loss: 4.7510 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4667 - out_loss: 4.7053 - rbf_fourier_loss: 4.2281 - val_loss: 4.4870 - val_out_loss: 4.7524 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4644 - out_loss: 4.7018 - rbf_fourier_loss: 4.2270 - val_loss: 4.4899 - val_out_loss: 4.7582 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4723 - out_loss: 4.7169 - rbf_fourier_loss: 4.2277 - val_loss: 4.4922 - val_out_loss: 4.7628 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4708 - out_loss: 4.7153 - rbf_fourier_loss: 4.2263 - val_loss: 4.4861 - val_out_loss: 4.7506 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4721 - out_loss: 4.7170 - rbf_fourier_loss: 4.2272 - val_loss: 4.4856 - val_out_loss: 4.7496 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4628 - out_loss: 4.6992 - rbf_fourier_loss: 4.2263 - val_loss: 4.4830 - val_out_loss: 4.7444 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4762 - out_loss: 4.7257 - rbf_fourier_loss: 4.2266 - val_loss: 4.4869 - val_out_loss: 4.7523 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4674 - out_loss: 4.7073 - rbf_fourier_loss: 4.2275 - val_loss: 4.4877 - val_out_loss: 4.7538 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4610 - out_loss: 4.6967 - rbf_fourier_loss: 4.2252 - val_loss: 4.4817 - val_out_loss: 4.7417 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4613 - out_loss: 4.6952 - rbf_fourier_loss: 4.2275 - val_loss: 4.4861 - val_out_loss: 4.7505 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4688 - out_loss: 4.7119 - rbf_fourier_loss: 4.2257 - val_loss: 4.4813 - val_out_loss: 4.7411 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4684 - out_loss: 4.7105 - rbf_fourier_loss: 4.2263 - val_loss: 4.4823 - val_out_loss: 4.7429 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4585 - out_loss: 4.6875 - rbf_fourier_loss: 4.2295 - val_loss: 4.4819 - val_out_loss: 4.7423 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4657 - out_loss: 4.7044 - rbf_fourier_loss: 4.2271 - val_loss: 4.4839 - val_out_loss: 4.7463 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4746 - out_loss: 4.7216 - rbf_fourier_loss: 4.2276 - val_loss: 4.4799 - val_out_loss: 4.7382 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4584 - out_loss: 4.6889 - rbf_fourier_loss: 4.2279 - val_loss: 4.4801 - val_out_loss: 4.7386 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4558 - out_loss: 4.6867 - rbf_fourier_loss: 4.2249 - val_loss: 4.4764 - val_out_loss: 4.7312 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4575 - out_loss: 4.6884 - rbf_fourier_loss: 4.2267 - val_loss: 4.4727 - val_out_loss: 4.7238 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4601 - out_loss: 4.6956 - rbf_fourier_loss: 4.2246 - val_loss: 4.4823 - val_out_loss: 4.7430 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4653 - out_loss: 4.7062 - rbf_fourier_loss: 4.2244 - val_loss: 4.4765 - val_out_loss: 4.7314 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4661 - out_loss: 4.7060 - rbf_fourier_loss: 4.2262 - val_loss: 4.4774 - val_out_loss: 4.7331 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4542 - out_loss: 4.6787 - rbf_fourier_loss: 4.2296 - val_loss: 4.4742 - val_out_loss: 4.7268 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4537 - out_loss: 4.6812 - rbf_fourier_loss: 4.2261 - val_loss: 4.4757 - val_out_loss: 4.7298 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4652 - out_loss: 4.7040 - rbf_fourier_loss: 4.2264 - val_loss: 4.4774 - val_out_loss: 4.7332 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4607 - out_loss: 4.6955 - rbf_fourier_loss: 4.2259 - val_loss: 4.4759 - val_out_loss: 4.7302 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4516 - out_loss: 4.6759 - rbf_fourier_loss: 4.2273 - val_loss: 4.4737 - val_out_loss: 4.7258 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4499 - out_loss: 4.6715 - rbf_fourier_loss: 4.2282 - val_loss: 4.4723 - val_out_loss: 4.7230 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4661 - out_loss: 4.7052 - rbf_fourier_loss: 4.2270 - val_loss: 4.4716 - val_out_loss: 4.7216 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4457 - out_loss: 4.6657 - rbf_fourier_loss: 4.2256 - val_loss: 4.4680 - val_out_loss: 4.7145 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4569 - out_loss: 4.6867 - rbf_fourier_loss: 4.2270 - val_loss: 4.4708 - val_out_loss: 4.7201 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4652 - out_loss: 4.7041 - rbf_fourier_loss: 4.2263 - val_loss: 4.4716 - val_out_loss: 4.7216 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4516 - out_loss: 4.6772 - rbf_fourier_loss: 4.2260 - val_loss: 4.4685 - val_out_loss: 4.7154 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4619 - out_loss: 4.6979 - rbf_fourier_loss: 4.2259 - val_loss: 4.4706 - val_out_loss: 4.7197 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4566 - out_loss: 4.6881 - rbf_fourier_loss: 4.2250 - val_loss: 4.4739 - val_out_loss: 4.7263 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4592 - out_loss: 4.6899 - rbf_fourier_loss: 4.2285 - val_loss: 4.4693 - val_out_loss: 4.7170 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4404 - out_loss: 4.6549 - rbf_fourier_loss: 4.2260 - val_loss: 4.4679 - val_out_loss: 4.7143 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4487 - out_loss: 4.6694 - rbf_fourier_loss: 4.2280 - val_loss: 4.4683 - val_out_loss: 4.7150 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4373 - out_loss: 4.6484 - rbf_fourier_loss: 4.2262 - val_loss: 4.4682 - val_out_loss: 4.7148 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4489 - out_loss: 4.6723 - rbf_fourier_loss: 4.2255 - val_loss: 4.4723 - val_out_loss: 4.7230 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4623 - out_loss: 4.6984 - rbf_fourier_loss: 4.2261 - val_loss: 4.4703 - val_out_loss: 4.7191 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4396 - out_loss: 4.6519 - rbf_fourier_loss: 4.2273 - val_loss: 4.4683 - val_out_loss: 4.7150 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4536 - out_loss: 4.6791 - rbf_fourier_loss: 4.2280 - val_loss: 4.4663 - val_out_loss: 4.7110 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4419 - out_loss: 4.6589 - rbf_fourier_loss: 4.2250 - val_loss: 4.4672 - val_out_loss: 4.7128 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4560 - out_loss: 4.6827 - rbf_fourier_loss: 4.2292 - val_loss: 4.4659 - val_out_loss: 4.7101 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4492 - out_loss: 4.6702 - rbf_fourier_loss: 4.2282 - val_loss: 4.4690 - val_out_loss: 4.7164 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4609 - out_loss: 4.6956 - rbf_fourier_loss: 4.2263 - val_loss: 4.4692 - val_out_loss: 4.7168 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4531 - out_loss: 4.6784 - rbf_fourier_loss: 4.2277 - val_loss: 4.4689 - val_out_loss: 4.7162 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4466 - out_loss: 4.6631 - rbf_fourier_loss: 4.2300 - val_loss: 4.4683 - val_out_loss: 4.7150 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4471 - out_loss: 4.6680 - rbf_fourier_loss: 4.2261 - val_loss: 4.4675 - val_out_loss: 4.7134 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4460 - out_loss: 4.6629 - rbf_fourier_loss: 4.2292 - val_loss: 4.4670 - val_out_loss: 4.7124 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4438 - out_loss: 4.6603 - rbf_fourier_loss: 4.2273 - val_loss: 4.4652 - val_out_loss: 4.7088 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4574 - out_loss: 4.6860 - rbf_fourier_loss: 4.2288 - val_loss: 4.4618 - val_out_loss: 4.7021 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4439 - out_loss: 4.6607 - rbf_fourier_loss: 4.2271 - val_loss: 4.4641 - val_out_loss: 4.7067 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4449 - out_loss: 4.6629 - rbf_fourier_loss: 4.2270 - val_loss: 4.4616 - val_out_loss: 4.7016 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4347 - out_loss: 4.6458 - rbf_fourier_loss: 4.2235 - val_loss: 4.4629 - val_out_loss: 4.7042 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4343 - out_loss: 4.6431 - rbf_fourier_loss: 4.2255 - val_loss: 4.4652 - val_out_loss: 4.7088 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4485 - out_loss: 4.6689 - rbf_fourier_loss: 4.2280 - val_loss: 4.4656 - val_out_loss: 4.7096 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4356 - out_loss: 4.6445 - rbf_fourier_loss: 4.2266 - val_loss: 4.4629 - val_out_loss: 4.7042 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4296 - out_loss: 4.6316 - rbf_fourier_loss: 4.2276 - val_loss: 4.4654 - val_out_loss: 4.7093 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4420 - out_loss: 4.6577 - rbf_fourier_loss: 4.2262 - val_loss: 4.4674 - val_out_loss: 4.7133 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4376 - out_loss: 4.6487 - rbf_fourier_loss: 4.2266 - val_loss: 4.4676 - val_out_loss: 4.7137 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4487 - out_loss: 4.6705 - rbf_fourier_loss: 4.2270 - val_loss: 4.4690 - val_out_loss: 4.7165 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4263 - out_loss: 4.6272 - rbf_fourier_loss: 4.2255 - val_loss: 4.4720 - val_out_loss: 4.7224 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4553 - out_loss: 4.6821 - rbf_fourier_loss: 4.2286 - val_loss: 4.4700 - val_out_loss: 4.7185 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4400 - out_loss: 4.6529 - rbf_fourier_loss: 4.2272 - val_loss: 4.4652 - val_out_loss: 4.7087 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4344 - out_loss: 4.6406 - rbf_fourier_loss: 4.2283 - val_loss: 4.4676 - val_out_loss: 4.7136 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4265 - out_loss: 4.6258 - rbf_fourier_loss: 4.2272 - val_loss: 4.4631 - val_out_loss: 4.7047 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4288 - out_loss: 4.6279 - rbf_fourier_loss: 4.2296 - val_loss: 4.4624 - val_out_loss: 4.7033 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4499 - out_loss: 4.6743 - rbf_fourier_loss: 4.2256 - val_loss: 4.4633 - val_out_loss: 4.7049 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4370 - out_loss: 4.6483 - rbf_fourier_loss: 4.2256 - val_loss: 4.4670 - val_out_loss: 4.7124 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4351 - out_loss: 4.6417 - rbf_fourier_loss: 4.2286 - val_loss: 4.4615 - val_out_loss: 4.7015 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4518 - out_loss: 4.6772 - rbf_fourier_loss: 4.2264 - val_loss: 4.4638 - val_out_loss: 4.7059 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4388 - out_loss: 4.6493 - rbf_fourier_loss: 4.2283 - val_loss: 4.4658 - val_out_loss: 4.7101 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4226 - out_loss: 4.6201 - rbf_fourier_loss: 4.2250 - val_loss: 4.4633 - val_out_loss: 4.7050 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4343 - out_loss: 4.6427 - rbf_fourier_loss: 4.2258 - val_loss: 4.4650 - val_out_loss: 4.7083 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4336 - out_loss: 4.6428 - rbf_fourier_loss: 4.2243 - val_loss: 4.4636 - val_out_loss: 4.7055 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4377 - out_loss: 4.6509 - rbf_fourier_loss: 4.2245 - val_loss: 4.4639 - val_out_loss: 4.7062 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4188 - out_loss: 4.6087 - rbf_fourier_loss: 4.2288 - val_loss: 4.4670 - val_out_loss: 4.7124 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4204 - out_loss: 4.6122 - rbf_fourier_loss: 4.2285 - val_loss: 4.4688 - val_out_loss: 4.7160 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4327 - out_loss: 4.6364 - rbf_fourier_loss: 4.2290 - val_loss: 4.4698 - val_out_loss: 4.7180 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4291 - out_loss: 4.6316 - rbf_fourier_loss: 4.2266 - val_loss: 4.4715 - val_out_loss: 4.7214 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4368 - out_loss: 4.6465 - rbf_fourier_loss: 4.2271 - val_loss: 4.4732 - val_out_loss: 4.7248 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4379 - out_loss: 4.6508 - rbf_fourier_loss: 4.2250 - val_loss: 4.4721 - val_out_loss: 4.7226 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4372 - out_loss: 4.6471 - rbf_fourier_loss: 4.2274 - val_loss: 4.4715 - val_out_loss: 4.7215 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4255 - out_loss: 4.6244 - rbf_fourier_loss: 4.2266 - val_loss: 4.4701 - val_out_loss: 4.7186 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4290 - out_loss: 4.6292 - rbf_fourier_loss: 4.2287 - val_loss: 4.4680 - val_out_loss: 4.7145 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4391 - out_loss: 4.6507 - rbf_fourier_loss: 4.2275 - val_loss: 4.4685 - val_out_loss: 4.7153 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4399 - out_loss: 4.6513 - rbf_fourier_loss: 4.2284 - val_loss: 4.4693 - val_out_loss: 4.7169 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4278 - out_loss: 4.6294 - rbf_fourier_loss: 4.2262 - val_loss: 4.4690 - val_out_loss: 4.7165 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4270 - out_loss: 4.6259 - rbf_fourier_loss: 4.2280 - val_loss: 4.4668 - val_out_loss: 4.7121 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4222 - out_loss: 4.6177 - rbf_fourier_loss: 4.2267 - val_loss: 4.4660 - val_out_loss: 4.7105 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4346 - out_loss: 4.6427 - rbf_fourier_loss: 4.2265 - val_loss: 4.4663 - val_out_loss: 4.7110 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4205 - out_loss: 4.6149 - rbf_fourier_loss: 4.2262 - val_loss: 4.4689 - val_out_loss: 4.7162 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4205 - out_loss: 4.6140 - rbf_fourier_loss: 4.2271 - val_loss: 4.4690 - val_out_loss: 4.7165 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4229 - out_loss: 4.6171 - rbf_fourier_loss: 4.2287 - val_loss: 4.4663 - val_out_loss: 4.7110 - val_rbf_fourier_loss: 4.2216\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4243 - out_loss: 4.6202 - rbf_fourier_loss: 4.2284 - val_loss: 4.4632 - val_out_loss: 4.7048 - val_rbf_fourier_loss: 4.2216\n",
            "it 2/10\n",
            "acc: 11.316666666666666\n",
            "ari: 0.0012018220085049556\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 4.4730 - out_loss: 4.7212 - rbf_fourier_loss: 4.2248 - val_loss: 4.4721 - val_out_loss: 4.7183 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4782 - out_loss: 4.7320 - rbf_fourier_loss: 4.2244 - val_loss: 4.4707 - val_out_loss: 4.7156 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4852 - out_loss: 4.7429 - rbf_fourier_loss: 4.2276 - val_loss: 4.4642 - val_out_loss: 4.7027 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4847 - out_loss: 4.7425 - rbf_fourier_loss: 4.2268 - val_loss: 4.4590 - val_out_loss: 4.6921 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4697 - out_loss: 4.7137 - rbf_fourier_loss: 4.2257 - val_loss: 4.4613 - val_out_loss: 4.6967 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4740 - out_loss: 4.7202 - rbf_fourier_loss: 4.2279 - val_loss: 4.4614 - val_out_loss: 4.6970 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4719 - out_loss: 4.7181 - rbf_fourier_loss: 4.2257 - val_loss: 4.4557 - val_out_loss: 4.6857 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4745 - out_loss: 4.7231 - rbf_fourier_loss: 4.2258 - val_loss: 4.4597 - val_out_loss: 4.6936 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4713 - out_loss: 4.7156 - rbf_fourier_loss: 4.2270 - val_loss: 4.4576 - val_out_loss: 4.6894 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4660 - out_loss: 4.7058 - rbf_fourier_loss: 4.2262 - val_loss: 4.4551 - val_out_loss: 4.6844 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4728 - out_loss: 4.7212 - rbf_fourier_loss: 4.2244 - val_loss: 4.4489 - val_out_loss: 4.6719 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4587 - out_loss: 4.6911 - rbf_fourier_loss: 4.2263 - val_loss: 4.4503 - val_out_loss: 4.6748 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4714 - out_loss: 4.7171 - rbf_fourier_loss: 4.2256 - val_loss: 4.4565 - val_out_loss: 4.6871 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4653 - out_loss: 4.7041 - rbf_fourier_loss: 4.2264 - val_loss: 4.4562 - val_out_loss: 4.6866 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4616 - out_loss: 4.6987 - rbf_fourier_loss: 4.2246 - val_loss: 4.4550 - val_out_loss: 4.6843 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4639 - out_loss: 4.7018 - rbf_fourier_loss: 4.2260 - val_loss: 4.4528 - val_out_loss: 4.6799 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4649 - out_loss: 4.7010 - rbf_fourier_loss: 4.2287 - val_loss: 4.4516 - val_out_loss: 4.6774 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4664 - out_loss: 4.7059 - rbf_fourier_loss: 4.2268 - val_loss: 4.4580 - val_out_loss: 4.6902 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4625 - out_loss: 4.6974 - rbf_fourier_loss: 4.2276 - val_loss: 4.4574 - val_out_loss: 4.6890 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4738 - out_loss: 4.7219 - rbf_fourier_loss: 4.2257 - val_loss: 4.4580 - val_out_loss: 4.6902 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4591 - out_loss: 4.6935 - rbf_fourier_loss: 4.2246 - val_loss: 4.4594 - val_out_loss: 4.6931 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4555 - out_loss: 4.6852 - rbf_fourier_loss: 4.2258 - val_loss: 4.4589 - val_out_loss: 4.6921 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4636 - out_loss: 4.7020 - rbf_fourier_loss: 4.2253 - val_loss: 4.4575 - val_out_loss: 4.6892 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4624 - out_loss: 4.6965 - rbf_fourier_loss: 4.2284 - val_loss: 4.4588 - val_out_loss: 4.6918 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4535 - out_loss: 4.6796 - rbf_fourier_loss: 4.2274 - val_loss: 4.4613 - val_out_loss: 4.6969 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4563 - out_loss: 4.6841 - rbf_fourier_loss: 4.2285 - val_loss: 4.4591 - val_out_loss: 4.6925 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4474 - out_loss: 4.6657 - rbf_fourier_loss: 4.2290 - val_loss: 4.4587 - val_out_loss: 4.6916 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4609 - out_loss: 4.6953 - rbf_fourier_loss: 4.2266 - val_loss: 4.4598 - val_out_loss: 4.6939 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4590 - out_loss: 4.6907 - rbf_fourier_loss: 4.2273 - val_loss: 4.4560 - val_out_loss: 4.6863 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4682 - out_loss: 4.7105 - rbf_fourier_loss: 4.2260 - val_loss: 4.4532 - val_out_loss: 4.6805 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4562 - out_loss: 4.6838 - rbf_fourier_loss: 4.2287 - val_loss: 4.4550 - val_out_loss: 4.6843 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4540 - out_loss: 4.6826 - rbf_fourier_loss: 4.2254 - val_loss: 4.4566 - val_out_loss: 4.6875 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4410 - out_loss: 4.6563 - rbf_fourier_loss: 4.2257 - val_loss: 4.4611 - val_out_loss: 4.6963 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4506 - out_loss: 4.6730 - rbf_fourier_loss: 4.2281 - val_loss: 4.4600 - val_out_loss: 4.6942 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4514 - out_loss: 4.6764 - rbf_fourier_loss: 4.2264 - val_loss: 4.4606 - val_out_loss: 4.6954 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4580 - out_loss: 4.6884 - rbf_fourier_loss: 4.2275 - val_loss: 4.4612 - val_out_loss: 4.6965 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4433 - out_loss: 4.6599 - rbf_fourier_loss: 4.2267 - val_loss: 4.4594 - val_out_loss: 4.6930 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4553 - out_loss: 4.6874 - rbf_fourier_loss: 4.2233 - val_loss: 4.4603 - val_out_loss: 4.6949 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4575 - out_loss: 4.6899 - rbf_fourier_loss: 4.2251 - val_loss: 4.4597 - val_out_loss: 4.6937 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4542 - out_loss: 4.6810 - rbf_fourier_loss: 4.2273 - val_loss: 4.4592 - val_out_loss: 4.6927 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4508 - out_loss: 4.6757 - rbf_fourier_loss: 4.2259 - val_loss: 4.4600 - val_out_loss: 4.6943 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4519 - out_loss: 4.6781 - rbf_fourier_loss: 4.2258 - val_loss: 4.4589 - val_out_loss: 4.6920 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4424 - out_loss: 4.6588 - rbf_fourier_loss: 4.2260 - val_loss: 4.4602 - val_out_loss: 4.6947 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4519 - out_loss: 4.6775 - rbf_fourier_loss: 4.2263 - val_loss: 4.4584 - val_out_loss: 4.6909 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4364 - out_loss: 4.6455 - rbf_fourier_loss: 4.2273 - val_loss: 4.4518 - val_out_loss: 4.6779 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4367 - out_loss: 4.6480 - rbf_fourier_loss: 4.2254 - val_loss: 4.4565 - val_out_loss: 4.6873 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4599 - out_loss: 4.6947 - rbf_fourier_loss: 4.2252 - val_loss: 4.4533 - val_out_loss: 4.6809 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4645 - out_loss: 4.7042 - rbf_fourier_loss: 4.2249 - val_loss: 4.4513 - val_out_loss: 4.6767 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4393 - out_loss: 4.6507 - rbf_fourier_loss: 4.2278 - val_loss: 4.4499 - val_out_loss: 4.6740 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4406 - out_loss: 4.6517 - rbf_fourier_loss: 4.2295 - val_loss: 4.4545 - val_out_loss: 4.6832 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4517 - out_loss: 4.6777 - rbf_fourier_loss: 4.2258 - val_loss: 4.4589 - val_out_loss: 4.6919 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4530 - out_loss: 4.6790 - rbf_fourier_loss: 4.2270 - val_loss: 4.4588 - val_out_loss: 4.6918 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4405 - out_loss: 4.6524 - rbf_fourier_loss: 4.2286 - val_loss: 4.4542 - val_out_loss: 4.6826 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4321 - out_loss: 4.6377 - rbf_fourier_loss: 4.2265 - val_loss: 4.4568 - val_out_loss: 4.6878 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4455 - out_loss: 4.6652 - rbf_fourier_loss: 4.2258 - val_loss: 4.4538 - val_out_loss: 4.6818 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4460 - out_loss: 4.6671 - rbf_fourier_loss: 4.2249 - val_loss: 4.4561 - val_out_loss: 4.6864 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4498 - out_loss: 4.6729 - rbf_fourier_loss: 4.2267 - val_loss: 4.4575 - val_out_loss: 4.6893 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4483 - out_loss: 4.6700 - rbf_fourier_loss: 4.2265 - val_loss: 4.4577 - val_out_loss: 4.6896 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4453 - out_loss: 4.6636 - rbf_fourier_loss: 4.2270 - val_loss: 4.4580 - val_out_loss: 4.6901 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4427 - out_loss: 4.6608 - rbf_fourier_loss: 4.2246 - val_loss: 4.4584 - val_out_loss: 4.6911 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4348 - out_loss: 4.6415 - rbf_fourier_loss: 4.2281 - val_loss: 4.4594 - val_out_loss: 4.6930 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4394 - out_loss: 4.6530 - rbf_fourier_loss: 4.2258 - val_loss: 4.4592 - val_out_loss: 4.6925 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4416 - out_loss: 4.6560 - rbf_fourier_loss: 4.2273 - val_loss: 4.4587 - val_out_loss: 4.6916 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4453 - out_loss: 4.6639 - rbf_fourier_loss: 4.2266 - val_loss: 4.4597 - val_out_loss: 4.6936 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4288 - out_loss: 4.6314 - rbf_fourier_loss: 4.2262 - val_loss: 4.4578 - val_out_loss: 4.6897 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4414 - out_loss: 4.6565 - rbf_fourier_loss: 4.2264 - val_loss: 4.4648 - val_out_loss: 4.7038 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4344 - out_loss: 4.6416 - rbf_fourier_loss: 4.2272 - val_loss: 4.4629 - val_out_loss: 4.7000 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4295 - out_loss: 4.6334 - rbf_fourier_loss: 4.2256 - val_loss: 4.4674 - val_out_loss: 4.7091 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4447 - out_loss: 4.6614 - rbf_fourier_loss: 4.2279 - val_loss: 4.4648 - val_out_loss: 4.7038 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4432 - out_loss: 4.6608 - rbf_fourier_loss: 4.2256 - val_loss: 4.4606 - val_out_loss: 4.6955 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4243 - out_loss: 4.6215 - rbf_fourier_loss: 4.2270 - val_loss: 4.4595 - val_out_loss: 4.6933 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4394 - out_loss: 4.6507 - rbf_fourier_loss: 4.2282 - val_loss: 4.4597 - val_out_loss: 4.6937 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4318 - out_loss: 4.6410 - rbf_fourier_loss: 4.2226 - val_loss: 4.4593 - val_out_loss: 4.6927 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4367 - out_loss: 4.6465 - rbf_fourier_loss: 4.2268 - val_loss: 4.4597 - val_out_loss: 4.6936 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4304 - out_loss: 4.6361 - rbf_fourier_loss: 4.2248 - val_loss: 4.4604 - val_out_loss: 4.6951 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4404 - out_loss: 4.6555 - rbf_fourier_loss: 4.2253 - val_loss: 4.4602 - val_out_loss: 4.6946 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4350 - out_loss: 4.6442 - rbf_fourier_loss: 4.2258 - val_loss: 4.4585 - val_out_loss: 4.6913 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4290 - out_loss: 4.6338 - rbf_fourier_loss: 4.2242 - val_loss: 4.4606 - val_out_loss: 4.6954 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4340 - out_loss: 4.6421 - rbf_fourier_loss: 4.2259 - val_loss: 4.4632 - val_out_loss: 4.7006 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4380 - out_loss: 4.6489 - rbf_fourier_loss: 4.2272 - val_loss: 4.4637 - val_out_loss: 4.7017 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4395 - out_loss: 4.6517 - rbf_fourier_loss: 4.2273 - val_loss: 4.4584 - val_out_loss: 4.6910 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4329 - out_loss: 4.6381 - rbf_fourier_loss: 4.2277 - val_loss: 4.4561 - val_out_loss: 4.6864 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4281 - out_loss: 4.6290 - rbf_fourier_loss: 4.2272 - val_loss: 4.4569 - val_out_loss: 4.6880 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4287 - out_loss: 4.6287 - rbf_fourier_loss: 4.2287 - val_loss: 4.4558 - val_out_loss: 4.6859 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4229 - out_loss: 4.6220 - rbf_fourier_loss: 4.2238 - val_loss: 4.4593 - val_out_loss: 4.6929 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4283 - out_loss: 4.6303 - rbf_fourier_loss: 4.2263 - val_loss: 4.4574 - val_out_loss: 4.6890 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4369 - out_loss: 4.6466 - rbf_fourier_loss: 4.2272 - val_loss: 4.4562 - val_out_loss: 4.6866 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4317 - out_loss: 4.6346 - rbf_fourier_loss: 4.2289 - val_loss: 4.4563 - val_out_loss: 4.6867 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4215 - out_loss: 4.6161 - rbf_fourier_loss: 4.2268 - val_loss: 4.4565 - val_out_loss: 4.6873 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4283 - out_loss: 4.6317 - rbf_fourier_loss: 4.2248 - val_loss: 4.4592 - val_out_loss: 4.6927 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4293 - out_loss: 4.6324 - rbf_fourier_loss: 4.2262 - val_loss: 4.4587 - val_out_loss: 4.6915 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4282 - out_loss: 4.6299 - rbf_fourier_loss: 4.2266 - val_loss: 4.4587 - val_out_loss: 4.6916 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4335 - out_loss: 4.6408 - rbf_fourier_loss: 4.2262 - val_loss: 4.4606 - val_out_loss: 4.6953 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4291 - out_loss: 4.6307 - rbf_fourier_loss: 4.2275 - val_loss: 4.4563 - val_out_loss: 4.6867 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4277 - out_loss: 4.6289 - rbf_fourier_loss: 4.2266 - val_loss: 4.4567 - val_out_loss: 4.6877 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4242 - out_loss: 4.6198 - rbf_fourier_loss: 4.2286 - val_loss: 4.4570 - val_out_loss: 4.6881 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4279 - out_loss: 4.6275 - rbf_fourier_loss: 4.2282 - val_loss: 4.4568 - val_out_loss: 4.6878 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 4.4429 - out_loss: 4.6594 - rbf_fourier_loss: 4.2265 - val_loss: 4.4541 - val_out_loss: 4.6824 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.4365 - out_loss: 4.6450 - rbf_fourier_loss: 4.2280 - val_loss: 4.4542 - val_out_loss: 4.6826 - val_rbf_fourier_loss: 4.2258\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.4221 - out_loss: 4.6183 - rbf_fourier_loss: 4.2259 - val_loss: 4.4521 - val_out_loss: 4.6785 - val_rbf_fourier_loss: 4.2258\n",
            "it 2/10\n",
            "acc: 11.301666666666668\n",
            "ari: 0.0018448589973527345\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 20ms/step - loss: 4.9571 - out_loss: 5.7039 - rbf_fourier_loss: 4.2102 - val_loss: 4.9639 - val_out_loss: 5.7080 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9583 - out_loss: 5.7077 - rbf_fourier_loss: 4.2089 - val_loss: 4.9644 - val_out_loss: 5.7090 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9592 - out_loss: 5.7094 - rbf_fourier_loss: 4.2090 - val_loss: 4.9622 - val_out_loss: 5.7047 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9530 - out_loss: 5.6966 - rbf_fourier_loss: 4.2094 - val_loss: 4.9610 - val_out_loss: 5.7022 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9486 - out_loss: 5.6892 - rbf_fourier_loss: 4.2081 - val_loss: 4.9585 - val_out_loss: 5.6972 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9494 - out_loss: 5.6910 - rbf_fourier_loss: 4.2078 - val_loss: 4.9606 - val_out_loss: 5.7014 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9659 - out_loss: 5.7233 - rbf_fourier_loss: 4.2086 - val_loss: 4.9576 - val_out_loss: 5.6954 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9527 - out_loss: 5.6960 - rbf_fourier_loss: 4.2095 - val_loss: 4.9602 - val_out_loss: 5.7006 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9364 - out_loss: 5.6626 - rbf_fourier_loss: 4.2101 - val_loss: 4.9613 - val_out_loss: 5.7028 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9480 - out_loss: 5.6872 - rbf_fourier_loss: 4.2087 - val_loss: 4.9586 - val_out_loss: 5.6974 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9366 - out_loss: 5.6612 - rbf_fourier_loss: 4.2121 - val_loss: 4.9574 - val_out_loss: 5.6950 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9512 - out_loss: 5.6929 - rbf_fourier_loss: 4.2095 - val_loss: 4.9551 - val_out_loss: 5.6904 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9463 - out_loss: 5.6835 - rbf_fourier_loss: 4.2091 - val_loss: 4.9577 - val_out_loss: 5.6956 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9519 - out_loss: 5.6931 - rbf_fourier_loss: 4.2107 - val_loss: 4.9546 - val_out_loss: 5.6894 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9580 - out_loss: 5.7074 - rbf_fourier_loss: 4.2085 - val_loss: 4.9572 - val_out_loss: 5.6946 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9450 - out_loss: 5.6800 - rbf_fourier_loss: 4.2100 - val_loss: 4.9576 - val_out_loss: 5.6954 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9473 - out_loss: 5.6822 - rbf_fourier_loss: 4.2124 - val_loss: 4.9567 - val_out_loss: 5.6935 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9513 - out_loss: 5.6940 - rbf_fourier_loss: 4.2087 - val_loss: 4.9552 - val_out_loss: 5.6906 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9423 - out_loss: 5.6741 - rbf_fourier_loss: 4.2105 - val_loss: 4.9542 - val_out_loss: 5.6886 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9604 - out_loss: 5.7114 - rbf_fourier_loss: 4.2093 - val_loss: 4.9576 - val_out_loss: 5.6953 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 2s 9ms/step - loss: 4.9403 - out_loss: 5.6719 - rbf_fourier_loss: 4.2087 - val_loss: 4.9616 - val_out_loss: 5.7034 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 2s 9ms/step - loss: 4.9433 - out_loss: 5.6767 - rbf_fourier_loss: 4.2098 - val_loss: 4.9560 - val_out_loss: 5.6922 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9331 - out_loss: 5.6576 - rbf_fourier_loss: 4.2085 - val_loss: 4.9517 - val_out_loss: 5.6836 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9348 - out_loss: 5.6601 - rbf_fourier_loss: 4.2094 - val_loss: 4.9464 - val_out_loss: 5.6731 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9413 - out_loss: 5.6720 - rbf_fourier_loss: 4.2106 - val_loss: 4.9482 - val_out_loss: 5.6766 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 2s 9ms/step - loss: 4.9375 - out_loss: 5.6666 - rbf_fourier_loss: 4.2084 - val_loss: 4.9470 - val_out_loss: 5.6742 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9528 - out_loss: 5.6969 - rbf_fourier_loss: 4.2087 - val_loss: 4.9440 - val_out_loss: 5.6683 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9506 - out_loss: 5.6918 - rbf_fourier_loss: 4.2094 - val_loss: 4.9451 - val_out_loss: 5.6705 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9445 - out_loss: 5.6789 - rbf_fourier_loss: 4.2100 - val_loss: 4.9477 - val_out_loss: 5.6756 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9322 - out_loss: 5.6546 - rbf_fourier_loss: 4.2099 - val_loss: 4.9472 - val_out_loss: 5.6747 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9329 - out_loss: 5.6532 - rbf_fourier_loss: 4.2126 - val_loss: 4.9489 - val_out_loss: 5.6781 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9426 - out_loss: 5.6756 - rbf_fourier_loss: 4.2095 - val_loss: 4.9463 - val_out_loss: 5.6727 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9176 - out_loss: 5.6273 - rbf_fourier_loss: 4.2079 - val_loss: 4.9473 - val_out_loss: 5.6748 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9303 - out_loss: 5.6519 - rbf_fourier_loss: 4.2087 - val_loss: 4.9457 - val_out_loss: 5.6717 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9317 - out_loss: 5.6551 - rbf_fourier_loss: 4.2082 - val_loss: 4.9436 - val_out_loss: 5.6674 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9339 - out_loss: 5.6560 - rbf_fourier_loss: 4.2118 - val_loss: 4.9410 - val_out_loss: 5.6621 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9284 - out_loss: 5.6472 - rbf_fourier_loss: 4.2095 - val_loss: 4.9423 - val_out_loss: 5.6649 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9424 - out_loss: 5.6761 - rbf_fourier_loss: 4.2086 - val_loss: 4.9409 - val_out_loss: 5.6620 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9416 - out_loss: 5.6762 - rbf_fourier_loss: 4.2070 - val_loss: 4.9402 - val_out_loss: 5.6607 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9229 - out_loss: 5.6364 - rbf_fourier_loss: 4.2093 - val_loss: 4.9388 - val_out_loss: 5.6578 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9392 - out_loss: 5.6700 - rbf_fourier_loss: 4.2085 - val_loss: 4.9374 - val_out_loss: 5.6550 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9455 - out_loss: 5.6828 - rbf_fourier_loss: 4.2081 - val_loss: 4.9346 - val_out_loss: 5.6493 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9269 - out_loss: 5.6439 - rbf_fourier_loss: 4.2099 - val_loss: 4.9342 - val_out_loss: 5.6486 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9351 - out_loss: 5.6598 - rbf_fourier_loss: 4.2103 - val_loss: 4.9345 - val_out_loss: 5.6493 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9342 - out_loss: 5.6600 - rbf_fourier_loss: 4.2085 - val_loss: 4.9338 - val_out_loss: 5.6477 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9382 - out_loss: 5.6670 - rbf_fourier_loss: 4.2095 - val_loss: 4.9381 - val_out_loss: 5.6565 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9212 - out_loss: 5.6316 - rbf_fourier_loss: 4.2109 - val_loss: 4.9380 - val_out_loss: 5.6562 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9332 - out_loss: 5.6577 - rbf_fourier_loss: 4.2087 - val_loss: 4.9407 - val_out_loss: 5.6617 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9193 - out_loss: 5.6297 - rbf_fourier_loss: 4.2089 - val_loss: 4.9417 - val_out_loss: 5.6635 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9331 - out_loss: 5.6579 - rbf_fourier_loss: 4.2084 - val_loss: 4.9428 - val_out_loss: 5.6657 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9335 - out_loss: 5.6567 - rbf_fourier_loss: 4.2102 - val_loss: 4.9429 - val_out_loss: 5.6661 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9343 - out_loss: 5.6628 - rbf_fourier_loss: 4.2058 - val_loss: 4.9444 - val_out_loss: 5.6691 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9343 - out_loss: 5.6574 - rbf_fourier_loss: 4.2112 - val_loss: 4.9441 - val_out_loss: 5.6684 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9341 - out_loss: 5.6592 - rbf_fourier_loss: 4.2090 - val_loss: 4.9422 - val_out_loss: 5.6646 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9218 - out_loss: 5.6347 - rbf_fourier_loss: 4.2089 - val_loss: 4.9416 - val_out_loss: 5.6635 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9368 - out_loss: 5.6646 - rbf_fourier_loss: 4.2090 - val_loss: 4.9420 - val_out_loss: 5.6642 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9289 - out_loss: 5.6484 - rbf_fourier_loss: 4.2093 - val_loss: 4.9405 - val_out_loss: 5.6611 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9290 - out_loss: 5.6484 - rbf_fourier_loss: 4.2095 - val_loss: 4.9440 - val_out_loss: 5.6682 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9324 - out_loss: 5.6539 - rbf_fourier_loss: 4.2109 - val_loss: 4.9441 - val_out_loss: 5.6684 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9244 - out_loss: 5.6376 - rbf_fourier_loss: 4.2113 - val_loss: 4.9431 - val_out_loss: 5.6665 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9255 - out_loss: 5.6436 - rbf_fourier_loss: 4.2075 - val_loss: 4.9437 - val_out_loss: 5.6676 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9184 - out_loss: 5.6256 - rbf_fourier_loss: 4.2112 - val_loss: 4.9466 - val_out_loss: 5.6733 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9357 - out_loss: 5.6610 - rbf_fourier_loss: 4.2105 - val_loss: 4.9467 - val_out_loss: 5.6736 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9311 - out_loss: 5.6546 - rbf_fourier_loss: 4.2077 - val_loss: 4.9433 - val_out_loss: 5.6667 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9244 - out_loss: 5.6375 - rbf_fourier_loss: 4.2112 - val_loss: 4.9443 - val_out_loss: 5.6688 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9246 - out_loss: 5.6385 - rbf_fourier_loss: 4.2107 - val_loss: 4.9438 - val_out_loss: 5.6678 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9297 - out_loss: 5.6503 - rbf_fourier_loss: 4.2091 - val_loss: 4.9453 - val_out_loss: 5.6708 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9133 - out_loss: 5.6188 - rbf_fourier_loss: 4.2077 - val_loss: 4.9431 - val_out_loss: 5.6664 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9343 - out_loss: 5.6614 - rbf_fourier_loss: 4.2072 - val_loss: 4.9428 - val_out_loss: 5.6657 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9285 - out_loss: 5.6482 - rbf_fourier_loss: 4.2087 - val_loss: 4.9446 - val_out_loss: 5.6693 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9291 - out_loss: 5.6482 - rbf_fourier_loss: 4.2100 - val_loss: 4.9442 - val_out_loss: 5.6686 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9199 - out_loss: 5.6306 - rbf_fourier_loss: 4.2092 - val_loss: 4.9420 - val_out_loss: 5.6643 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9256 - out_loss: 5.6428 - rbf_fourier_loss: 4.2084 - val_loss: 4.9424 - val_out_loss: 5.6650 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9228 - out_loss: 5.6388 - rbf_fourier_loss: 4.2069 - val_loss: 4.9438 - val_out_loss: 5.6677 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9168 - out_loss: 5.6244 - rbf_fourier_loss: 4.2092 - val_loss: 4.9431 - val_out_loss: 5.6665 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9226 - out_loss: 5.6355 - rbf_fourier_loss: 4.2096 - val_loss: 4.9415 - val_out_loss: 5.6633 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9128 - out_loss: 5.6162 - rbf_fourier_loss: 4.2095 - val_loss: 4.9435 - val_out_loss: 5.6672 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9154 - out_loss: 5.6209 - rbf_fourier_loss: 4.2099 - val_loss: 4.9419 - val_out_loss: 5.6640 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9222 - out_loss: 5.6355 - rbf_fourier_loss: 4.2089 - val_loss: 4.9443 - val_out_loss: 5.6688 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9189 - out_loss: 5.6253 - rbf_fourier_loss: 4.2124 - val_loss: 4.9421 - val_out_loss: 5.6644 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9114 - out_loss: 5.6133 - rbf_fourier_loss: 4.2095 - val_loss: 4.9451 - val_out_loss: 5.6704 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9220 - out_loss: 5.6350 - rbf_fourier_loss: 4.2090 - val_loss: 4.9438 - val_out_loss: 5.6677 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9112 - out_loss: 5.6137 - rbf_fourier_loss: 4.2087 - val_loss: 4.9446 - val_out_loss: 5.6694 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9179 - out_loss: 5.6294 - rbf_fourier_loss: 4.2063 - val_loss: 4.9433 - val_out_loss: 5.6668 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9193 - out_loss: 5.6289 - rbf_fourier_loss: 4.2097 - val_loss: 4.9401 - val_out_loss: 5.6605 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9140 - out_loss: 5.6186 - rbf_fourier_loss: 4.2094 - val_loss: 4.9378 - val_out_loss: 5.6559 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9209 - out_loss: 5.6314 - rbf_fourier_loss: 4.2104 - val_loss: 4.9384 - val_out_loss: 5.6569 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9258 - out_loss: 5.6418 - rbf_fourier_loss: 4.2098 - val_loss: 4.9391 - val_out_loss: 5.6584 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9079 - out_loss: 5.6070 - rbf_fourier_loss: 4.2088 - val_loss: 4.9413 - val_out_loss: 5.6628 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9184 - out_loss: 5.6267 - rbf_fourier_loss: 4.2100 - val_loss: 4.9414 - val_out_loss: 5.6631 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9142 - out_loss: 5.6206 - rbf_fourier_loss: 4.2077 - val_loss: 4.9421 - val_out_loss: 5.6644 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9166 - out_loss: 5.6235 - rbf_fourier_loss: 4.2097 - val_loss: 4.9424 - val_out_loss: 5.6650 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9145 - out_loss: 5.6190 - rbf_fourier_loss: 4.2100 - val_loss: 4.9461 - val_out_loss: 5.6724 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9124 - out_loss: 5.6154 - rbf_fourier_loss: 4.2093 - val_loss: 4.9442 - val_out_loss: 5.6686 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9134 - out_loss: 5.6193 - rbf_fourier_loss: 4.2075 - val_loss: 4.9426 - val_out_loss: 5.6653 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9192 - out_loss: 5.6289 - rbf_fourier_loss: 4.2095 - val_loss: 4.9428 - val_out_loss: 5.6658 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9135 - out_loss: 5.6159 - rbf_fourier_loss: 4.2111 - val_loss: 4.9413 - val_out_loss: 5.6628 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 4.9073 - out_loss: 5.6064 - rbf_fourier_loss: 4.2083 - val_loss: 4.9389 - val_out_loss: 5.6581 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9153 - out_loss: 5.6224 - rbf_fourier_loss: 4.2083 - val_loss: 4.9420 - val_out_loss: 5.6643 - val_rbf_fourier_loss: 4.2198\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 4.9127 - out_loss: 5.6143 - rbf_fourier_loss: 4.2110 - val_loss: 4.9410 - val_out_loss: 5.6622 - val_rbf_fourier_loss: 4.2198\n",
            "it 2/10\n",
            "acc: 12.178333333333333\n",
            "ari: 0.1324897860323144\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 1.9558 - out_loss: 2.2751 - rbf_fourier_loss: 1.6364 - val_loss: 1.9518 - val_out_loss: 2.2690 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9554 - out_loss: 2.2743 - rbf_fourier_loss: 1.6364 - val_loss: 1.9507 - val_out_loss: 2.2667 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9502 - out_loss: 2.2641 - rbf_fourier_loss: 1.6363 - val_loss: 1.9505 - val_out_loss: 2.2664 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9539 - out_loss: 2.2715 - rbf_fourier_loss: 1.6363 - val_loss: 1.9506 - val_out_loss: 2.2666 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9540 - out_loss: 2.2717 - rbf_fourier_loss: 1.6363 - val_loss: 1.9486 - val_out_loss: 2.2626 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9436 - out_loss: 2.2507 - rbf_fourier_loss: 1.6365 - val_loss: 1.9492 - val_out_loss: 2.2638 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9542 - out_loss: 2.2721 - rbf_fourier_loss: 1.6363 - val_loss: 1.9451 - val_out_loss: 2.2555 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9500 - out_loss: 2.2635 - rbf_fourier_loss: 1.6365 - val_loss: 1.9498 - val_out_loss: 2.2650 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9565 - out_loss: 2.2767 - rbf_fourier_loss: 1.6362 - val_loss: 1.9481 - val_out_loss: 2.2616 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9549 - out_loss: 2.2733 - rbf_fourier_loss: 1.6366 - val_loss: 1.9479 - val_out_loss: 2.2611 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9545 - out_loss: 2.2724 - rbf_fourier_loss: 1.6366 - val_loss: 1.9465 - val_out_loss: 2.2583 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9483 - out_loss: 2.2604 - rbf_fourier_loss: 1.6363 - val_loss: 1.9482 - val_out_loss: 2.2618 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9475 - out_loss: 2.2585 - rbf_fourier_loss: 1.6366 - val_loss: 1.9477 - val_out_loss: 2.2607 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9520 - out_loss: 2.2672 - rbf_fourier_loss: 1.6368 - val_loss: 1.9460 - val_out_loss: 2.2574 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9493 - out_loss: 2.2622 - rbf_fourier_loss: 1.6364 - val_loss: 1.9504 - val_out_loss: 2.2662 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9479 - out_loss: 2.2595 - rbf_fourier_loss: 1.6364 - val_loss: 1.9510 - val_out_loss: 2.2673 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9474 - out_loss: 2.2581 - rbf_fourier_loss: 1.6367 - val_loss: 1.9525 - val_out_loss: 2.2703 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9553 - out_loss: 2.2741 - rbf_fourier_loss: 1.6364 - val_loss: 1.9543 - val_out_loss: 2.2739 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9551 - out_loss: 2.2738 - rbf_fourier_loss: 1.6364 - val_loss: 1.9528 - val_out_loss: 2.2710 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9492 - out_loss: 2.2617 - rbf_fourier_loss: 1.6367 - val_loss: 1.9507 - val_out_loss: 2.2667 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9492 - out_loss: 2.2619 - rbf_fourier_loss: 1.6364 - val_loss: 1.9476 - val_out_loss: 2.2605 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9471 - out_loss: 2.2578 - rbf_fourier_loss: 1.6365 - val_loss: 1.9491 - val_out_loss: 2.2635 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9503 - out_loss: 2.2640 - rbf_fourier_loss: 1.6365 - val_loss: 1.9488 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9500 - out_loss: 2.2634 - rbf_fourier_loss: 1.6365 - val_loss: 1.9488 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9473 - out_loss: 2.2582 - rbf_fourier_loss: 1.6365 - val_loss: 1.9488 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9476 - out_loss: 2.2585 - rbf_fourier_loss: 1.6367 - val_loss: 1.9494 - val_out_loss: 2.2641 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9510 - out_loss: 2.2656 - rbf_fourier_loss: 1.6364 - val_loss: 1.9502 - val_out_loss: 2.2658 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9483 - out_loss: 2.2600 - rbf_fourier_loss: 1.6367 - val_loss: 1.9500 - val_out_loss: 2.2654 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9492 - out_loss: 2.2620 - rbf_fourier_loss: 1.6363 - val_loss: 1.9500 - val_out_loss: 2.2653 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9536 - out_loss: 2.2709 - rbf_fourier_loss: 1.6364 - val_loss: 1.9500 - val_out_loss: 2.2653 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9463 - out_loss: 2.2562 - rbf_fourier_loss: 1.6364 - val_loss: 1.9522 - val_out_loss: 2.2698 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9427 - out_loss: 2.2489 - rbf_fourier_loss: 1.6365 - val_loss: 1.9522 - val_out_loss: 2.2698 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9430 - out_loss: 2.2497 - rbf_fourier_loss: 1.6364 - val_loss: 1.9496 - val_out_loss: 2.2645 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9487 - out_loss: 2.2606 - rbf_fourier_loss: 1.6367 - val_loss: 1.9459 - val_out_loss: 2.2572 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9542 - out_loss: 2.2717 - rbf_fourier_loss: 1.6366 - val_loss: 1.9484 - val_out_loss: 2.2622 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9572 - out_loss: 2.2776 - rbf_fourier_loss: 1.6367 - val_loss: 1.9485 - val_out_loss: 2.2623 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9484 - out_loss: 2.2602 - rbf_fourier_loss: 1.6366 - val_loss: 1.9497 - val_out_loss: 2.2648 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9511 - out_loss: 2.2657 - rbf_fourier_loss: 1.6366 - val_loss: 1.9505 - val_out_loss: 2.2663 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9452 - out_loss: 2.2541 - rbf_fourier_loss: 1.6363 - val_loss: 1.9505 - val_out_loss: 2.2663 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9468 - out_loss: 2.2573 - rbf_fourier_loss: 1.6364 - val_loss: 1.9516 - val_out_loss: 2.2686 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9508 - out_loss: 2.2650 - rbf_fourier_loss: 1.6366 - val_loss: 1.9534 - val_out_loss: 2.2722 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9443 - out_loss: 2.2523 - rbf_fourier_loss: 1.6364 - val_loss: 1.9503 - val_out_loss: 2.2659 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9550 - out_loss: 2.2735 - rbf_fourier_loss: 1.6366 - val_loss: 1.9536 - val_out_loss: 2.2726 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9468 - out_loss: 2.2570 - rbf_fourier_loss: 1.6367 - val_loss: 1.9533 - val_out_loss: 2.2720 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9436 - out_loss: 2.2508 - rbf_fourier_loss: 1.6364 - val_loss: 1.9517 - val_out_loss: 2.2688 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9437 - out_loss: 2.2508 - rbf_fourier_loss: 1.6367 - val_loss: 1.9512 - val_out_loss: 2.2678 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9418 - out_loss: 2.2470 - rbf_fourier_loss: 1.6365 - val_loss: 1.9504 - val_out_loss: 2.2661 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9472 - out_loss: 2.2576 - rbf_fourier_loss: 1.6367 - val_loss: 1.9506 - val_out_loss: 2.2665 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9545 - out_loss: 2.2724 - rbf_fourier_loss: 1.6365 - val_loss: 1.9488 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9387 - out_loss: 2.2409 - rbf_fourier_loss: 1.6366 - val_loss: 1.9495 - val_out_loss: 2.2643 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9480 - out_loss: 2.2593 - rbf_fourier_loss: 1.6367 - val_loss: 1.9530 - val_out_loss: 2.2713 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9443 - out_loss: 2.2520 - rbf_fourier_loss: 1.6366 - val_loss: 1.9561 - val_out_loss: 2.2776 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9418 - out_loss: 2.2470 - rbf_fourier_loss: 1.6367 - val_loss: 1.9552 - val_out_loss: 2.2758 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9475 - out_loss: 2.2585 - rbf_fourier_loss: 1.6366 - val_loss: 1.9537 - val_out_loss: 2.2727 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9526 - out_loss: 2.2685 - rbf_fourier_loss: 1.6366 - val_loss: 1.9561 - val_out_loss: 2.2775 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9420 - out_loss: 2.2475 - rbf_fourier_loss: 1.6365 - val_loss: 1.9550 - val_out_loss: 2.2753 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9440 - out_loss: 2.2516 - rbf_fourier_loss: 1.6363 - val_loss: 1.9568 - val_out_loss: 2.2789 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9426 - out_loss: 2.2485 - rbf_fourier_loss: 1.6366 - val_loss: 1.9569 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9483 - out_loss: 2.2602 - rbf_fourier_loss: 1.6364 - val_loss: 1.9573 - val_out_loss: 2.2799 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9456 - out_loss: 2.2550 - rbf_fourier_loss: 1.6363 - val_loss: 1.9590 - val_out_loss: 2.2833 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9436 - out_loss: 2.2507 - rbf_fourier_loss: 1.6366 - val_loss: 1.9573 - val_out_loss: 2.2799 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9459 - out_loss: 2.2554 - rbf_fourier_loss: 1.6365 - val_loss: 1.9601 - val_out_loss: 2.2856 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9397 - out_loss: 2.2431 - rbf_fourier_loss: 1.6364 - val_loss: 1.9606 - val_out_loss: 2.2865 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9358 - out_loss: 2.2351 - rbf_fourier_loss: 1.6366 - val_loss: 1.9604 - val_out_loss: 2.2861 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9442 - out_loss: 2.2520 - rbf_fourier_loss: 1.6365 - val_loss: 1.9599 - val_out_loss: 2.2852 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9309 - out_loss: 2.2253 - rbf_fourier_loss: 1.6366 - val_loss: 1.9611 - val_out_loss: 2.2875 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9349 - out_loss: 2.2333 - rbf_fourier_loss: 1.6365 - val_loss: 1.9604 - val_out_loss: 2.2862 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9413 - out_loss: 2.2460 - rbf_fourier_loss: 1.6365 - val_loss: 1.9591 - val_out_loss: 2.2835 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9409 - out_loss: 2.2449 - rbf_fourier_loss: 1.6368 - val_loss: 1.9577 - val_out_loss: 2.2807 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9367 - out_loss: 2.2372 - rbf_fourier_loss: 1.6363 - val_loss: 1.9569 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9397 - out_loss: 2.2432 - rbf_fourier_loss: 1.6363 - val_loss: 1.9549 - val_out_loss: 2.2753 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9370 - out_loss: 2.2375 - rbf_fourier_loss: 1.6364 - val_loss: 1.9575 - val_out_loss: 2.2804 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9361 - out_loss: 2.2355 - rbf_fourier_loss: 1.6366 - val_loss: 1.9580 - val_out_loss: 2.2814 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9400 - out_loss: 2.2436 - rbf_fourier_loss: 1.6364 - val_loss: 1.9595 - val_out_loss: 2.2844 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9437 - out_loss: 2.2510 - rbf_fourier_loss: 1.6363 - val_loss: 1.9575 - val_out_loss: 2.2804 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9412 - out_loss: 2.2457 - rbf_fourier_loss: 1.6367 - val_loss: 1.9559 - val_out_loss: 2.2772 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9377 - out_loss: 2.2393 - rbf_fourier_loss: 1.6362 - val_loss: 1.9549 - val_out_loss: 2.2751 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9384 - out_loss: 2.2403 - rbf_fourier_loss: 1.6364 - val_loss: 1.9551 - val_out_loss: 2.2756 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9398 - out_loss: 2.2429 - rbf_fourier_loss: 1.6367 - val_loss: 1.9522 - val_out_loss: 2.2698 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9371 - out_loss: 2.2377 - rbf_fourier_loss: 1.6365 - val_loss: 1.9509 - val_out_loss: 2.2672 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9413 - out_loss: 2.2460 - rbf_fourier_loss: 1.6365 - val_loss: 1.9512 - val_out_loss: 2.2678 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9378 - out_loss: 2.2391 - rbf_fourier_loss: 1.6365 - val_loss: 1.9509 - val_out_loss: 2.2672 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9388 - out_loss: 2.2409 - rbf_fourier_loss: 1.6367 - val_loss: 1.9506 - val_out_loss: 2.2665 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9357 - out_loss: 2.2348 - rbf_fourier_loss: 1.6366 - val_loss: 1.9490 - val_out_loss: 2.2634 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9435 - out_loss: 2.2506 - rbf_fourier_loss: 1.6364 - val_loss: 1.9489 - val_out_loss: 2.2631 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9341 - out_loss: 2.2318 - rbf_fourier_loss: 1.6364 - val_loss: 1.9494 - val_out_loss: 2.2641 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9347 - out_loss: 2.2329 - rbf_fourier_loss: 1.6365 - val_loss: 1.9503 - val_out_loss: 2.2659 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9338 - out_loss: 2.2310 - rbf_fourier_loss: 1.6367 - val_loss: 1.9504 - val_out_loss: 2.2662 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9381 - out_loss: 2.2398 - rbf_fourier_loss: 1.6364 - val_loss: 1.9514 - val_out_loss: 2.2681 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9313 - out_loss: 2.2264 - rbf_fourier_loss: 1.6362 - val_loss: 1.9506 - val_out_loss: 2.2666 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9359 - out_loss: 2.2353 - rbf_fourier_loss: 1.6365 - val_loss: 1.9488 - val_out_loss: 2.2630 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9323 - out_loss: 2.2280 - rbf_fourier_loss: 1.6365 - val_loss: 1.9481 - val_out_loss: 2.2616 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9386 - out_loss: 2.2405 - rbf_fourier_loss: 1.6367 - val_loss: 1.9477 - val_out_loss: 2.2607 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9347 - out_loss: 2.2327 - rbf_fourier_loss: 1.6366 - val_loss: 1.9494 - val_out_loss: 2.2642 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9303 - out_loss: 2.2241 - rbf_fourier_loss: 1.6365 - val_loss: 1.9501 - val_out_loss: 2.2655 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9365 - out_loss: 2.2367 - rbf_fourier_loss: 1.6362 - val_loss: 1.9516 - val_out_loss: 2.2685 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9263 - out_loss: 2.2160 - rbf_fourier_loss: 1.6366 - val_loss: 1.9495 - val_out_loss: 2.2643 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9294 - out_loss: 2.2222 - rbf_fourier_loss: 1.6365 - val_loss: 1.9496 - val_out_loss: 2.2646 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9393 - out_loss: 2.2421 - rbf_fourier_loss: 1.6365 - val_loss: 1.9495 - val_out_loss: 2.2643 - val_rbf_fourier_loss: 1.6346\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9306 - out_loss: 2.2243 - rbf_fourier_loss: 1.6368 - val_loss: 1.9509 - val_out_loss: 2.2672 - val_rbf_fourier_loss: 1.6346\n",
            "it 2/10\n",
            "acc: 11.276666666666667\n",
            "ari: 0.003451120670321452\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 18ms/step - loss: 1.9524 - out_loss: 2.2696 - rbf_fourier_loss: 1.6353 - val_loss: 1.9540 - val_out_loss: 2.2746 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9563 - out_loss: 2.2771 - rbf_fourier_loss: 1.6355 - val_loss: 1.9554 - val_out_loss: 2.2774 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9466 - out_loss: 2.2580 - rbf_fourier_loss: 1.6352 - val_loss: 1.9542 - val_out_loss: 2.2750 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9536 - out_loss: 2.2718 - rbf_fourier_loss: 1.6354 - val_loss: 1.9566 - val_out_loss: 2.2798 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9441 - out_loss: 2.2529 - rbf_fourier_loss: 1.6354 - val_loss: 1.9553 - val_out_loss: 2.2772 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9488 - out_loss: 2.2620 - rbf_fourier_loss: 1.6355 - val_loss: 1.9549 - val_out_loss: 2.2764 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9438 - out_loss: 2.2523 - rbf_fourier_loss: 1.6352 - val_loss: 1.9575 - val_out_loss: 2.2816 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9495 - out_loss: 2.2638 - rbf_fourier_loss: 1.6352 - val_loss: 1.9575 - val_out_loss: 2.2817 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9601 - out_loss: 2.2848 - rbf_fourier_loss: 1.6354 - val_loss: 1.9595 - val_out_loss: 2.2855 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9476 - out_loss: 2.2599 - rbf_fourier_loss: 1.6353 - val_loss: 1.9593 - val_out_loss: 2.2851 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9528 - out_loss: 2.2705 - rbf_fourier_loss: 1.6351 - val_loss: 1.9623 - val_out_loss: 2.2913 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9536 - out_loss: 2.2718 - rbf_fourier_loss: 1.6354 - val_loss: 1.9586 - val_out_loss: 2.2837 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9527 - out_loss: 2.2701 - rbf_fourier_loss: 1.6353 - val_loss: 1.9552 - val_out_loss: 2.2770 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9427 - out_loss: 2.2501 - rbf_fourier_loss: 1.6353 - val_loss: 1.9582 - val_out_loss: 2.2829 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9478 - out_loss: 2.2601 - rbf_fourier_loss: 1.6354 - val_loss: 1.9573 - val_out_loss: 2.2811 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9494 - out_loss: 2.2637 - rbf_fourier_loss: 1.6352 - val_loss: 1.9589 - val_out_loss: 2.2845 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9502 - out_loss: 2.2651 - rbf_fourier_loss: 1.6353 - val_loss: 1.9567 - val_out_loss: 2.2799 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9521 - out_loss: 2.2687 - rbf_fourier_loss: 1.6355 - val_loss: 1.9597 - val_out_loss: 2.2859 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 1.9512 - out_loss: 2.2671 - rbf_fourier_loss: 1.6354 - val_loss: 1.9557 - val_out_loss: 2.2781 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9505 - out_loss: 2.2657 - rbf_fourier_loss: 1.6353 - val_loss: 1.9557 - val_out_loss: 2.2781 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9523 - out_loss: 2.2693 - rbf_fourier_loss: 1.6353 - val_loss: 1.9568 - val_out_loss: 2.2801 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9484 - out_loss: 2.2617 - rbf_fourier_loss: 1.6352 - val_loss: 1.9551 - val_out_loss: 2.2767 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9411 - out_loss: 2.2468 - rbf_fourier_loss: 1.6353 - val_loss: 1.9552 - val_out_loss: 2.2769 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9462 - out_loss: 2.2570 - rbf_fourier_loss: 1.6354 - val_loss: 1.9563 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9485 - out_loss: 2.2617 - rbf_fourier_loss: 1.6353 - val_loss: 1.9562 - val_out_loss: 2.2790 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9458 - out_loss: 2.2562 - rbf_fourier_loss: 1.6354 - val_loss: 1.9552 - val_out_loss: 2.2771 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9517 - out_loss: 2.2681 - rbf_fourier_loss: 1.6353 - val_loss: 1.9555 - val_out_loss: 2.2775 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9457 - out_loss: 2.2558 - rbf_fourier_loss: 1.6356 - val_loss: 1.9565 - val_out_loss: 2.2796 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9468 - out_loss: 2.2581 - rbf_fourier_loss: 1.6355 - val_loss: 1.9549 - val_out_loss: 2.2763 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9458 - out_loss: 2.2563 - rbf_fourier_loss: 1.6354 - val_loss: 1.9551 - val_out_loss: 2.2768 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9407 - out_loss: 2.2461 - rbf_fourier_loss: 1.6352 - val_loss: 1.9548 - val_out_loss: 2.2761 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9453 - out_loss: 2.2552 - rbf_fourier_loss: 1.6354 - val_loss: 1.9539 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9457 - out_loss: 2.2562 - rbf_fourier_loss: 1.6351 - val_loss: 1.9577 - val_out_loss: 2.2819 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9469 - out_loss: 2.2584 - rbf_fourier_loss: 1.6354 - val_loss: 1.9551 - val_out_loss: 2.2767 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9496 - out_loss: 2.2639 - rbf_fourier_loss: 1.6353 - val_loss: 1.9532 - val_out_loss: 2.2730 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9480 - out_loss: 2.2605 - rbf_fourier_loss: 1.6355 - val_loss: 1.9536 - val_out_loss: 2.2738 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9372 - out_loss: 2.2391 - rbf_fourier_loss: 1.6354 - val_loss: 1.9552 - val_out_loss: 2.2770 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9435 - out_loss: 2.2519 - rbf_fourier_loss: 1.6351 - val_loss: 1.9550 - val_out_loss: 2.2766 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9404 - out_loss: 2.2454 - rbf_fourier_loss: 1.6355 - val_loss: 1.9573 - val_out_loss: 2.2811 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9517 - out_loss: 2.2680 - rbf_fourier_loss: 1.6353 - val_loss: 1.9578 - val_out_loss: 2.2821 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9448 - out_loss: 2.2542 - rbf_fourier_loss: 1.6353 - val_loss: 1.9570 - val_out_loss: 2.2806 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9412 - out_loss: 2.2473 - rbf_fourier_loss: 1.6351 - val_loss: 1.9557 - val_out_loss: 2.2779 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9381 - out_loss: 2.2409 - rbf_fourier_loss: 1.6353 - val_loss: 1.9590 - val_out_loss: 2.2845 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9420 - out_loss: 2.2485 - rbf_fourier_loss: 1.6355 - val_loss: 1.9560 - val_out_loss: 2.2786 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9408 - out_loss: 2.2460 - rbf_fourier_loss: 1.6355 - val_loss: 1.9579 - val_out_loss: 2.2823 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9480 - out_loss: 2.2609 - rbf_fourier_loss: 1.6352 - val_loss: 1.9585 - val_out_loss: 2.2836 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9395 - out_loss: 2.2437 - rbf_fourier_loss: 1.6353 - val_loss: 1.9596 - val_out_loss: 2.2858 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9347 - out_loss: 2.2337 - rbf_fourier_loss: 1.6356 - val_loss: 1.9585 - val_out_loss: 2.2836 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9475 - out_loss: 2.2596 - rbf_fourier_loss: 1.6354 - val_loss: 1.9607 - val_out_loss: 2.2879 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9406 - out_loss: 2.2460 - rbf_fourier_loss: 1.6352 - val_loss: 1.9599 - val_out_loss: 2.2864 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9439 - out_loss: 2.2525 - rbf_fourier_loss: 1.6353 - val_loss: 1.9597 - val_out_loss: 2.2861 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9386 - out_loss: 2.2418 - rbf_fourier_loss: 1.6354 - val_loss: 1.9594 - val_out_loss: 2.2854 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9317 - out_loss: 2.2280 - rbf_fourier_loss: 1.6355 - val_loss: 1.9605 - val_out_loss: 2.2875 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9420 - out_loss: 2.2487 - rbf_fourier_loss: 1.6354 - val_loss: 1.9588 - val_out_loss: 2.2842 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9370 - out_loss: 2.2387 - rbf_fourier_loss: 1.6354 - val_loss: 1.9574 - val_out_loss: 2.2814 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9422 - out_loss: 2.2490 - rbf_fourier_loss: 1.6355 - val_loss: 1.9585 - val_out_loss: 2.2836 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9429 - out_loss: 2.2506 - rbf_fourier_loss: 1.6353 - val_loss: 1.9585 - val_out_loss: 2.2836 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9394 - out_loss: 2.2435 - rbf_fourier_loss: 1.6353 - val_loss: 1.9586 - val_out_loss: 2.2837 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9456 - out_loss: 2.2559 - rbf_fourier_loss: 1.6353 - val_loss: 1.9587 - val_out_loss: 2.2839 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9366 - out_loss: 2.2378 - rbf_fourier_loss: 1.6355 - val_loss: 1.9573 - val_out_loss: 2.2812 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9435 - out_loss: 2.2516 - rbf_fourier_loss: 1.6353 - val_loss: 1.9595 - val_out_loss: 2.2857 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9341 - out_loss: 2.2328 - rbf_fourier_loss: 1.6354 - val_loss: 1.9607 - val_out_loss: 2.2881 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9392 - out_loss: 2.2428 - rbf_fourier_loss: 1.6355 - val_loss: 1.9603 - val_out_loss: 2.2873 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9440 - out_loss: 2.2526 - rbf_fourier_loss: 1.6353 - val_loss: 1.9611 - val_out_loss: 2.2887 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9420 - out_loss: 2.2488 - rbf_fourier_loss: 1.6353 - val_loss: 1.9593 - val_out_loss: 2.2851 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9386 - out_loss: 2.2418 - rbf_fourier_loss: 1.6354 - val_loss: 1.9596 - val_out_loss: 2.2857 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9375 - out_loss: 2.2399 - rbf_fourier_loss: 1.6352 - val_loss: 1.9600 - val_out_loss: 2.2866 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9377 - out_loss: 2.2401 - rbf_fourier_loss: 1.6354 - val_loss: 1.9591 - val_out_loss: 2.2848 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9351 - out_loss: 2.2348 - rbf_fourier_loss: 1.6353 - val_loss: 1.9595 - val_out_loss: 2.2856 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9376 - out_loss: 2.2398 - rbf_fourier_loss: 1.6353 - val_loss: 1.9564 - val_out_loss: 2.2794 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9413 - out_loss: 2.2471 - rbf_fourier_loss: 1.6355 - val_loss: 1.9583 - val_out_loss: 2.2832 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9436 - out_loss: 2.2518 - rbf_fourier_loss: 1.6354 - val_loss: 1.9602 - val_out_loss: 2.2869 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9450 - out_loss: 2.2545 - rbf_fourier_loss: 1.6354 - val_loss: 1.9610 - val_out_loss: 2.2886 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9336 - out_loss: 2.2319 - rbf_fourier_loss: 1.6354 - val_loss: 1.9615 - val_out_loss: 2.2896 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9399 - out_loss: 2.2445 - rbf_fourier_loss: 1.6353 - val_loss: 1.9638 - val_out_loss: 2.2942 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9366 - out_loss: 2.2380 - rbf_fourier_loss: 1.6353 - val_loss: 1.9589 - val_out_loss: 2.2843 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9332 - out_loss: 2.2312 - rbf_fourier_loss: 1.6353 - val_loss: 1.9605 - val_out_loss: 2.2875 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9346 - out_loss: 2.2338 - rbf_fourier_loss: 1.6354 - val_loss: 1.9617 - val_out_loss: 2.2899 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9398 - out_loss: 2.2441 - rbf_fourier_loss: 1.6354 - val_loss: 1.9629 - val_out_loss: 2.2923 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9389 - out_loss: 2.2426 - rbf_fourier_loss: 1.6352 - val_loss: 1.9637 - val_out_loss: 2.2939 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9275 - out_loss: 2.2195 - rbf_fourier_loss: 1.6355 - val_loss: 1.9630 - val_out_loss: 2.2926 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9254 - out_loss: 2.2155 - rbf_fourier_loss: 1.6352 - val_loss: 1.9626 - val_out_loss: 2.2918 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9307 - out_loss: 2.2261 - rbf_fourier_loss: 1.6353 - val_loss: 1.9643 - val_out_loss: 2.2952 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9329 - out_loss: 2.2306 - rbf_fourier_loss: 1.6353 - val_loss: 1.9617 - val_out_loss: 2.2900 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9367 - out_loss: 2.2381 - rbf_fourier_loss: 1.6353 - val_loss: 1.9621 - val_out_loss: 2.2909 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9342 - out_loss: 2.2332 - rbf_fourier_loss: 1.6353 - val_loss: 1.9626 - val_out_loss: 2.2917 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9317 - out_loss: 2.2279 - rbf_fourier_loss: 1.6355 - val_loss: 1.9624 - val_out_loss: 2.2914 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9391 - out_loss: 2.2429 - rbf_fourier_loss: 1.6354 - val_loss: 1.9622 - val_out_loss: 2.2909 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9317 - out_loss: 2.2281 - rbf_fourier_loss: 1.6353 - val_loss: 1.9625 - val_out_loss: 2.2916 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9293 - out_loss: 2.2232 - rbf_fourier_loss: 1.6353 - val_loss: 1.9614 - val_out_loss: 2.2894 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9366 - out_loss: 2.2378 - rbf_fourier_loss: 1.6353 - val_loss: 1.9615 - val_out_loss: 2.2896 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9298 - out_loss: 2.2242 - rbf_fourier_loss: 1.6354 - val_loss: 1.9631 - val_out_loss: 2.2928 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9380 - out_loss: 2.2409 - rbf_fourier_loss: 1.6352 - val_loss: 1.9624 - val_out_loss: 2.2913 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9419 - out_loss: 2.2486 - rbf_fourier_loss: 1.6353 - val_loss: 1.9602 - val_out_loss: 2.2869 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9336 - out_loss: 2.2319 - rbf_fourier_loss: 1.6353 - val_loss: 1.9592 - val_out_loss: 2.2851 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9277 - out_loss: 2.2200 - rbf_fourier_loss: 1.6353 - val_loss: 1.9606 - val_out_loss: 2.2878 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9336 - out_loss: 2.2316 - rbf_fourier_loss: 1.6356 - val_loss: 1.9577 - val_out_loss: 2.2821 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9285 - out_loss: 2.2218 - rbf_fourier_loss: 1.6352 - val_loss: 1.9596 - val_out_loss: 2.2859 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9291 - out_loss: 2.2226 - rbf_fourier_loss: 1.6355 - val_loss: 1.9580 - val_out_loss: 2.2825 - val_rbf_fourier_loss: 1.6334\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9329 - out_loss: 2.2306 - rbf_fourier_loss: 1.6352 - val_loss: 1.9572 - val_out_loss: 2.2810 - val_rbf_fourier_loss: 1.6334\n",
            "it 2/10\n",
            "acc: 11.24\n",
            "ari: 0.0029713152535025805\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 1.9549 - out_loss: 2.2746 - rbf_fourier_loss: 1.6351 - val_loss: 1.9509 - val_out_loss: 2.2685 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9475 - out_loss: 2.2597 - rbf_fourier_loss: 1.6353 - val_loss: 1.9498 - val_out_loss: 2.2663 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9539 - out_loss: 2.2724 - rbf_fourier_loss: 1.6354 - val_loss: 1.9513 - val_out_loss: 2.2692 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9580 - out_loss: 2.2807 - rbf_fourier_loss: 1.6353 - val_loss: 1.9496 - val_out_loss: 2.2659 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9630 - out_loss: 2.2906 - rbf_fourier_loss: 1.6354 - val_loss: 1.9477 - val_out_loss: 2.2622 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9598 - out_loss: 2.2844 - rbf_fourier_loss: 1.6351 - val_loss: 1.9497 - val_out_loss: 2.2660 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9568 - out_loss: 2.2784 - rbf_fourier_loss: 1.6353 - val_loss: 1.9480 - val_out_loss: 2.2626 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9584 - out_loss: 2.2815 - rbf_fourier_loss: 1.6352 - val_loss: 1.9502 - val_out_loss: 2.2671 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9456 - out_loss: 2.2556 - rbf_fourier_loss: 1.6355 - val_loss: 1.9517 - val_out_loss: 2.2700 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9492 - out_loss: 2.2631 - rbf_fourier_loss: 1.6353 - val_loss: 1.9509 - val_out_loss: 2.2685 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9483 - out_loss: 2.2615 - rbf_fourier_loss: 1.6352 - val_loss: 1.9499 - val_out_loss: 2.2666 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9496 - out_loss: 2.2638 - rbf_fourier_loss: 1.6354 - val_loss: 1.9505 - val_out_loss: 2.2676 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9428 - out_loss: 2.2502 - rbf_fourier_loss: 1.6353 - val_loss: 1.9508 - val_out_loss: 2.2683 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9500 - out_loss: 2.2645 - rbf_fourier_loss: 1.6355 - val_loss: 1.9509 - val_out_loss: 2.2685 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9536 - out_loss: 2.2720 - rbf_fourier_loss: 1.6353 - val_loss: 1.9520 - val_out_loss: 2.2706 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9523 - out_loss: 2.2693 - rbf_fourier_loss: 1.6353 - val_loss: 1.9547 - val_out_loss: 2.2761 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9496 - out_loss: 2.2641 - rbf_fourier_loss: 1.6352 - val_loss: 1.9538 - val_out_loss: 2.2743 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9525 - out_loss: 2.2697 - rbf_fourier_loss: 1.6353 - val_loss: 1.9532 - val_out_loss: 2.2731 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9442 - out_loss: 2.2533 - rbf_fourier_loss: 1.6351 - val_loss: 1.9547 - val_out_loss: 2.2761 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9513 - out_loss: 2.2673 - rbf_fourier_loss: 1.6353 - val_loss: 1.9564 - val_out_loss: 2.2795 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9524 - out_loss: 2.2695 - rbf_fourier_loss: 1.6353 - val_loss: 1.9547 - val_out_loss: 2.2761 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9485 - out_loss: 2.2617 - rbf_fourier_loss: 1.6353 - val_loss: 1.9583 - val_out_loss: 2.2832 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9465 - out_loss: 2.2576 - rbf_fourier_loss: 1.6354 - val_loss: 1.9568 - val_out_loss: 2.2802 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9512 - out_loss: 2.2670 - rbf_fourier_loss: 1.6354 - val_loss: 1.9591 - val_out_loss: 2.2850 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9503 - out_loss: 2.2650 - rbf_fourier_loss: 1.6355 - val_loss: 1.9597 - val_out_loss: 2.2861 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9445 - out_loss: 2.2538 - rbf_fourier_loss: 1.6352 - val_loss: 1.9576 - val_out_loss: 2.2820 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9457 - out_loss: 2.2563 - rbf_fourier_loss: 1.6352 - val_loss: 1.9575 - val_out_loss: 2.2817 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9577 - out_loss: 2.2802 - rbf_fourier_loss: 1.6353 - val_loss: 1.9590 - val_out_loss: 2.2847 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9515 - out_loss: 2.2674 - rbf_fourier_loss: 1.6356 - val_loss: 1.9563 - val_out_loss: 2.2793 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9451 - out_loss: 2.2548 - rbf_fourier_loss: 1.6354 - val_loss: 1.9561 - val_out_loss: 2.2789 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9556 - out_loss: 2.2759 - rbf_fourier_loss: 1.6352 - val_loss: 1.9566 - val_out_loss: 2.2798 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9469 - out_loss: 2.2585 - rbf_fourier_loss: 1.6352 - val_loss: 1.9560 - val_out_loss: 2.2788 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9520 - out_loss: 2.2687 - rbf_fourier_loss: 1.6354 - val_loss: 1.9559 - val_out_loss: 2.2785 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9463 - out_loss: 2.2574 - rbf_fourier_loss: 1.6353 - val_loss: 1.9530 - val_out_loss: 2.2727 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9415 - out_loss: 2.2479 - rbf_fourier_loss: 1.6351 - val_loss: 1.9537 - val_out_loss: 2.2740 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9397 - out_loss: 2.2440 - rbf_fourier_loss: 1.6354 - val_loss: 1.9550 - val_out_loss: 2.2767 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9444 - out_loss: 2.2534 - rbf_fourier_loss: 1.6354 - val_loss: 1.9562 - val_out_loss: 2.2790 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9454 - out_loss: 2.2554 - rbf_fourier_loss: 1.6354 - val_loss: 1.9598 - val_out_loss: 2.2863 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9381 - out_loss: 2.2407 - rbf_fourier_loss: 1.6355 - val_loss: 1.9596 - val_out_loss: 2.2858 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9503 - out_loss: 2.2653 - rbf_fourier_loss: 1.6353 - val_loss: 1.9590 - val_out_loss: 2.2846 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9552 - out_loss: 2.2753 - rbf_fourier_loss: 1.6352 - val_loss: 1.9586 - val_out_loss: 2.2838 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9356 - out_loss: 2.2360 - rbf_fourier_loss: 1.6353 - val_loss: 1.9563 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9439 - out_loss: 2.2526 - rbf_fourier_loss: 1.6352 - val_loss: 1.9579 - val_out_loss: 2.2824 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9458 - out_loss: 2.2562 - rbf_fourier_loss: 1.6354 - val_loss: 1.9563 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9482 - out_loss: 2.2608 - rbf_fourier_loss: 1.6355 - val_loss: 1.9566 - val_out_loss: 2.2799 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9495 - out_loss: 2.2635 - rbf_fourier_loss: 1.6354 - val_loss: 1.9539 - val_out_loss: 2.2744 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9423 - out_loss: 2.2492 - rbf_fourier_loss: 1.6353 - val_loss: 1.9559 - val_out_loss: 2.2785 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9488 - out_loss: 2.2620 - rbf_fourier_loss: 1.6355 - val_loss: 1.9561 - val_out_loss: 2.2788 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9416 - out_loss: 2.2480 - rbf_fourier_loss: 1.6353 - val_loss: 1.9567 - val_out_loss: 2.2801 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9440 - out_loss: 2.2527 - rbf_fourier_loss: 1.6354 - val_loss: 1.9570 - val_out_loss: 2.2806 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9422 - out_loss: 2.2491 - rbf_fourier_loss: 1.6353 - val_loss: 1.9569 - val_out_loss: 2.2805 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9444 - out_loss: 2.2533 - rbf_fourier_loss: 1.6355 - val_loss: 1.9545 - val_out_loss: 2.2757 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9442 - out_loss: 2.2531 - rbf_fourier_loss: 1.6352 - val_loss: 1.9549 - val_out_loss: 2.2764 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9377 - out_loss: 2.2403 - rbf_fourier_loss: 1.6352 - val_loss: 1.9563 - val_out_loss: 2.2793 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9416 - out_loss: 2.2480 - rbf_fourier_loss: 1.6352 - val_loss: 1.9567 - val_out_loss: 2.2800 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9415 - out_loss: 2.2478 - rbf_fourier_loss: 1.6351 - val_loss: 1.9557 - val_out_loss: 2.2780 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9339 - out_loss: 2.2326 - rbf_fourier_loss: 1.6352 - val_loss: 1.9552 - val_out_loss: 2.2772 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9367 - out_loss: 2.2380 - rbf_fourier_loss: 1.6353 - val_loss: 1.9569 - val_out_loss: 2.2805 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9397 - out_loss: 2.2440 - rbf_fourier_loss: 1.6354 - val_loss: 1.9558 - val_out_loss: 2.2782 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9365 - out_loss: 2.2377 - rbf_fourier_loss: 1.6354 - val_loss: 1.9574 - val_out_loss: 2.2815 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9409 - out_loss: 2.2466 - rbf_fourier_loss: 1.6352 - val_loss: 1.9553 - val_out_loss: 2.2773 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9433 - out_loss: 2.2513 - rbf_fourier_loss: 1.6353 - val_loss: 1.9512 - val_out_loss: 2.2690 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9428 - out_loss: 2.2504 - rbf_fourier_loss: 1.6352 - val_loss: 1.9524 - val_out_loss: 2.2715 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9402 - out_loss: 2.2451 - rbf_fourier_loss: 1.6353 - val_loss: 1.9554 - val_out_loss: 2.2775 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9424 - out_loss: 2.2494 - rbf_fourier_loss: 1.6353 - val_loss: 1.9549 - val_out_loss: 2.2764 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9412 - out_loss: 2.2472 - rbf_fourier_loss: 1.6353 - val_loss: 1.9549 - val_out_loss: 2.2765 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9385 - out_loss: 2.2418 - rbf_fourier_loss: 1.6352 - val_loss: 1.9517 - val_out_loss: 2.2701 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9430 - out_loss: 2.2505 - rbf_fourier_loss: 1.6355 - val_loss: 1.9558 - val_out_loss: 2.2784 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9373 - out_loss: 2.2393 - rbf_fourier_loss: 1.6352 - val_loss: 1.9608 - val_out_loss: 2.2883 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9409 - out_loss: 2.2464 - rbf_fourier_loss: 1.6355 - val_loss: 1.9598 - val_out_loss: 2.2862 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9343 - out_loss: 2.2332 - rbf_fourier_loss: 1.6353 - val_loss: 1.9597 - val_out_loss: 2.2861 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9386 - out_loss: 2.2421 - rbf_fourier_loss: 1.6351 - val_loss: 1.9574 - val_out_loss: 2.2814 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9362 - out_loss: 2.2369 - rbf_fourier_loss: 1.6355 - val_loss: 1.9568 - val_out_loss: 2.2803 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9400 - out_loss: 2.2447 - rbf_fourier_loss: 1.6353 - val_loss: 1.9555 - val_out_loss: 2.2777 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9310 - out_loss: 2.2266 - rbf_fourier_loss: 1.6355 - val_loss: 1.9565 - val_out_loss: 2.2797 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9394 - out_loss: 2.2434 - rbf_fourier_loss: 1.6353 - val_loss: 1.9587 - val_out_loss: 2.2841 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9361 - out_loss: 2.2370 - rbf_fourier_loss: 1.6353 - val_loss: 1.9607 - val_out_loss: 2.2880 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9373 - out_loss: 2.2394 - rbf_fourier_loss: 1.6352 - val_loss: 1.9572 - val_out_loss: 2.2810 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9370 - out_loss: 2.2391 - rbf_fourier_loss: 1.6350 - val_loss: 1.9563 - val_out_loss: 2.2792 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9392 - out_loss: 2.2431 - rbf_fourier_loss: 1.6353 - val_loss: 1.9566 - val_out_loss: 2.2798 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9271 - out_loss: 2.2190 - rbf_fourier_loss: 1.6352 - val_loss: 1.9582 - val_out_loss: 2.2830 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9387 - out_loss: 2.2423 - rbf_fourier_loss: 1.6351 - val_loss: 1.9588 - val_out_loss: 2.2842 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9365 - out_loss: 2.2377 - rbf_fourier_loss: 1.6352 - val_loss: 1.9597 - val_out_loss: 2.2860 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9416 - out_loss: 2.2480 - rbf_fourier_loss: 1.6352 - val_loss: 1.9591 - val_out_loss: 2.2849 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9380 - out_loss: 2.2406 - rbf_fourier_loss: 1.6355 - val_loss: 1.9600 - val_out_loss: 2.2866 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9325 - out_loss: 2.2296 - rbf_fourier_loss: 1.6353 - val_loss: 1.9604 - val_out_loss: 2.2874 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9373 - out_loss: 2.2390 - rbf_fourier_loss: 1.6356 - val_loss: 1.9606 - val_out_loss: 2.2879 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9348 - out_loss: 2.2341 - rbf_fourier_loss: 1.6354 - val_loss: 1.9614 - val_out_loss: 2.2895 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9320 - out_loss: 2.2289 - rbf_fourier_loss: 1.6351 - val_loss: 1.9616 - val_out_loss: 2.2898 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9354 - out_loss: 2.2354 - rbf_fourier_loss: 1.6354 - val_loss: 1.9592 - val_out_loss: 2.2851 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9382 - out_loss: 2.2411 - rbf_fourier_loss: 1.6353 - val_loss: 1.9566 - val_out_loss: 2.2799 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9340 - out_loss: 2.2329 - rbf_fourier_loss: 1.6350 - val_loss: 1.9583 - val_out_loss: 2.2833 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9295 - out_loss: 2.2238 - rbf_fourier_loss: 1.6352 - val_loss: 1.9610 - val_out_loss: 2.2887 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9210 - out_loss: 2.2067 - rbf_fourier_loss: 1.6353 - val_loss: 1.9615 - val_out_loss: 2.2897 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9327 - out_loss: 2.2302 - rbf_fourier_loss: 1.6353 - val_loss: 1.9616 - val_out_loss: 2.2899 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 1.9311 - out_loss: 2.2272 - rbf_fourier_loss: 1.6349 - val_loss: 1.9594 - val_out_loss: 2.2855 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9274 - out_loss: 2.2194 - rbf_fourier_loss: 1.6354 - val_loss: 1.9595 - val_out_loss: 2.2857 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9287 - out_loss: 2.2219 - rbf_fourier_loss: 1.6355 - val_loss: 1.9585 - val_out_loss: 2.2837 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9269 - out_loss: 2.2186 - rbf_fourier_loss: 1.6353 - val_loss: 1.9588 - val_out_loss: 2.2843 - val_rbf_fourier_loss: 1.6333\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 1.9261 - out_loss: 2.2172 - rbf_fourier_loss: 1.6350 - val_loss: 1.9629 - val_out_loss: 2.2924 - val_rbf_fourier_loss: 1.6333\n",
            "it 2/10\n",
            "acc: 11.236666666666666\n",
            "ari: 0.0\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 2.2644 - out_loss: 2.9019 - rbf_fourier_loss: 1.6270 - val_loss: 2.2485 - val_out_loss: 2.8654 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2531 - out_loss: 2.8800 - rbf_fourier_loss: 1.6263 - val_loss: 2.2443 - val_out_loss: 2.8570 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2563 - out_loss: 2.8857 - rbf_fourier_loss: 1.6268 - val_loss: 2.2450 - val_out_loss: 2.8584 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2552 - out_loss: 2.8837 - rbf_fourier_loss: 1.6267 - val_loss: 2.2466 - val_out_loss: 2.8616 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2547 - out_loss: 2.8830 - rbf_fourier_loss: 1.6264 - val_loss: 2.2472 - val_out_loss: 2.8629 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2525 - out_loss: 2.8777 - rbf_fourier_loss: 1.6273 - val_loss: 2.2494 - val_out_loss: 2.8672 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2499 - out_loss: 2.8735 - rbf_fourier_loss: 1.6263 - val_loss: 2.2502 - val_out_loss: 2.8688 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2506 - out_loss: 2.8748 - rbf_fourier_loss: 1.6264 - val_loss: 2.2505 - val_out_loss: 2.8694 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2498 - out_loss: 2.8736 - rbf_fourier_loss: 1.6259 - val_loss: 2.2513 - val_out_loss: 2.8710 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2486 - out_loss: 2.8708 - rbf_fourier_loss: 1.6265 - val_loss: 2.2526 - val_out_loss: 2.8736 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2477 - out_loss: 2.8689 - rbf_fourier_loss: 1.6265 - val_loss: 2.2534 - val_out_loss: 2.8752 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2565 - out_loss: 2.8870 - rbf_fourier_loss: 1.6261 - val_loss: 2.2549 - val_out_loss: 2.8783 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2534 - out_loss: 2.8806 - rbf_fourier_loss: 1.6262 - val_loss: 2.2535 - val_out_loss: 2.8754 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2433 - out_loss: 2.8601 - rbf_fourier_loss: 1.6264 - val_loss: 2.2570 - val_out_loss: 2.8824 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2531 - out_loss: 2.8792 - rbf_fourier_loss: 1.6270 - val_loss: 2.2555 - val_out_loss: 2.8794 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2563 - out_loss: 2.8859 - rbf_fourier_loss: 1.6266 - val_loss: 2.2529 - val_out_loss: 2.8742 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2571 - out_loss: 2.8870 - rbf_fourier_loss: 1.6272 - val_loss: 2.2588 - val_out_loss: 2.8861 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2514 - out_loss: 2.8758 - rbf_fourier_loss: 1.6269 - val_loss: 2.2585 - val_out_loss: 2.8853 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2590 - out_loss: 2.8916 - rbf_fourier_loss: 1.6264 - val_loss: 2.2595 - val_out_loss: 2.8874 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2507 - out_loss: 2.8745 - rbf_fourier_loss: 1.6268 - val_loss: 2.2576 - val_out_loss: 2.8835 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2500 - out_loss: 2.8730 - rbf_fourier_loss: 1.6270 - val_loss: 2.2552 - val_out_loss: 2.8788 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2552 - out_loss: 2.8841 - rbf_fourier_loss: 1.6264 - val_loss: 2.2549 - val_out_loss: 2.8782 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2554 - out_loss: 2.8841 - rbf_fourier_loss: 1.6268 - val_loss: 2.2547 - val_out_loss: 2.8778 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2526 - out_loss: 2.8781 - rbf_fourier_loss: 1.6271 - val_loss: 2.2547 - val_out_loss: 2.8779 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2506 - out_loss: 2.8745 - rbf_fourier_loss: 1.6267 - val_loss: 2.2545 - val_out_loss: 2.8775 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2491 - out_loss: 2.8719 - rbf_fourier_loss: 1.6263 - val_loss: 2.2545 - val_out_loss: 2.8774 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2488 - out_loss: 2.8705 - rbf_fourier_loss: 1.6270 - val_loss: 2.2542 - val_out_loss: 2.8767 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2518 - out_loss: 2.8772 - rbf_fourier_loss: 1.6264 - val_loss: 2.2545 - val_out_loss: 2.8775 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2458 - out_loss: 2.8651 - rbf_fourier_loss: 1.6264 - val_loss: 2.2561 - val_out_loss: 2.8806 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2517 - out_loss: 2.8767 - rbf_fourier_loss: 1.6268 - val_loss: 2.2578 - val_out_loss: 2.8840 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2494 - out_loss: 2.8719 - rbf_fourier_loss: 1.6269 - val_loss: 2.2556 - val_out_loss: 2.8796 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2539 - out_loss: 2.8817 - rbf_fourier_loss: 1.6260 - val_loss: 2.2591 - val_out_loss: 2.8865 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2436 - out_loss: 2.8606 - rbf_fourier_loss: 1.6265 - val_loss: 2.2590 - val_out_loss: 2.8864 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2560 - out_loss: 2.8858 - rbf_fourier_loss: 1.6262 - val_loss: 2.2591 - val_out_loss: 2.8867 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2517 - out_loss: 2.8762 - rbf_fourier_loss: 1.6272 - val_loss: 2.2588 - val_out_loss: 2.8861 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2547 - out_loss: 2.8825 - rbf_fourier_loss: 1.6269 - val_loss: 2.2575 - val_out_loss: 2.8834 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2451 - out_loss: 2.8631 - rbf_fourier_loss: 1.6272 - val_loss: 2.2602 - val_out_loss: 2.8888 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2537 - out_loss: 2.8814 - rbf_fourier_loss: 1.6260 - val_loss: 2.2617 - val_out_loss: 2.8919 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2510 - out_loss: 2.8755 - rbf_fourier_loss: 1.6265 - val_loss: 2.2620 - val_out_loss: 2.8924 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2485 - out_loss: 2.8706 - rbf_fourier_loss: 1.6265 - val_loss: 2.2604 - val_out_loss: 2.8892 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2371 - out_loss: 2.8475 - rbf_fourier_loss: 1.6267 - val_loss: 2.2600 - val_out_loss: 2.8885 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2514 - out_loss: 2.8762 - rbf_fourier_loss: 1.6266 - val_loss: 2.2597 - val_out_loss: 2.8878 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2433 - out_loss: 2.8596 - rbf_fourier_loss: 1.6270 - val_loss: 2.2607 - val_out_loss: 2.8897 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2448 - out_loss: 2.8626 - rbf_fourier_loss: 1.6270 - val_loss: 2.2579 - val_out_loss: 2.8843 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2463 - out_loss: 2.8659 - rbf_fourier_loss: 1.6266 - val_loss: 2.2581 - val_out_loss: 2.8847 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2500 - out_loss: 2.8732 - rbf_fourier_loss: 1.6268 - val_loss: 2.2603 - val_out_loss: 2.8889 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2471 - out_loss: 2.8671 - rbf_fourier_loss: 1.6270 - val_loss: 2.2573 - val_out_loss: 2.8830 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2430 - out_loss: 2.8586 - rbf_fourier_loss: 1.6273 - val_loss: 2.2581 - val_out_loss: 2.8846 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2375 - out_loss: 2.8483 - rbf_fourier_loss: 1.6266 - val_loss: 2.2568 - val_out_loss: 2.8820 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2425 - out_loss: 2.8590 - rbf_fourier_loss: 1.6261 - val_loss: 2.2586 - val_out_loss: 2.8856 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2399 - out_loss: 2.8527 - rbf_fourier_loss: 1.6271 - val_loss: 2.2576 - val_out_loss: 2.8837 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2430 - out_loss: 2.8592 - rbf_fourier_loss: 1.6268 - val_loss: 2.2581 - val_out_loss: 2.8847 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2480 - out_loss: 2.8690 - rbf_fourier_loss: 1.6270 - val_loss: 2.2581 - val_out_loss: 2.8846 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2419 - out_loss: 2.8575 - rbf_fourier_loss: 1.6262 - val_loss: 2.2573 - val_out_loss: 2.8831 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2449 - out_loss: 2.8631 - rbf_fourier_loss: 1.6267 - val_loss: 2.2574 - val_out_loss: 2.8831 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2380 - out_loss: 2.8490 - rbf_fourier_loss: 1.6269 - val_loss: 2.2546 - val_out_loss: 2.8776 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2411 - out_loss: 2.8555 - rbf_fourier_loss: 1.6267 - val_loss: 2.2570 - val_out_loss: 2.8824 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2413 - out_loss: 2.8563 - rbf_fourier_loss: 1.6262 - val_loss: 2.2561 - val_out_loss: 2.8806 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2376 - out_loss: 2.8487 - rbf_fourier_loss: 1.6265 - val_loss: 2.2562 - val_out_loss: 2.8807 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2432 - out_loss: 2.8598 - rbf_fourier_loss: 1.6266 - val_loss: 2.2552 - val_out_loss: 2.8789 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2388 - out_loss: 2.8510 - rbf_fourier_loss: 1.6267 - val_loss: 2.2576 - val_out_loss: 2.8835 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2443 - out_loss: 2.8627 - rbf_fourier_loss: 1.6259 - val_loss: 2.2570 - val_out_loss: 2.8825 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2379 - out_loss: 2.8493 - rbf_fourier_loss: 1.6266 - val_loss: 2.2566 - val_out_loss: 2.8816 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2416 - out_loss: 2.8564 - rbf_fourier_loss: 1.6268 - val_loss: 2.2613 - val_out_loss: 2.8911 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2439 - out_loss: 2.8613 - rbf_fourier_loss: 1.6266 - val_loss: 2.2582 - val_out_loss: 2.8849 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2439 - out_loss: 2.8614 - rbf_fourier_loss: 1.6264 - val_loss: 2.2576 - val_out_loss: 2.8836 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2401 - out_loss: 2.8537 - rbf_fourier_loss: 1.6264 - val_loss: 2.2572 - val_out_loss: 2.8828 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2423 - out_loss: 2.8579 - rbf_fourier_loss: 1.6267 - val_loss: 2.2574 - val_out_loss: 2.8832 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2408 - out_loss: 2.8551 - rbf_fourier_loss: 1.6266 - val_loss: 2.2572 - val_out_loss: 2.8828 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2387 - out_loss: 2.8507 - rbf_fourier_loss: 1.6266 - val_loss: 2.2575 - val_out_loss: 2.8835 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2381 - out_loss: 2.8503 - rbf_fourier_loss: 1.6260 - val_loss: 2.2597 - val_out_loss: 2.8878 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2503 - out_loss: 2.8735 - rbf_fourier_loss: 1.6270 - val_loss: 2.2593 - val_out_loss: 2.8871 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2330 - out_loss: 2.8390 - rbf_fourier_loss: 1.6270 - val_loss: 2.2601 - val_out_loss: 2.8887 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2360 - out_loss: 2.8447 - rbf_fourier_loss: 1.6273 - val_loss: 2.2612 - val_out_loss: 2.8908 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2356 - out_loss: 2.8446 - rbf_fourier_loss: 1.6267 - val_loss: 2.2590 - val_out_loss: 2.8864 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2410 - out_loss: 2.8557 - rbf_fourier_loss: 1.6263 - val_loss: 2.2577 - val_out_loss: 2.8838 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2386 - out_loss: 2.8506 - rbf_fourier_loss: 1.6266 - val_loss: 2.2610 - val_out_loss: 2.8905 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2441 - out_loss: 2.8613 - rbf_fourier_loss: 1.6268 - val_loss: 2.2621 - val_out_loss: 2.8926 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2359 - out_loss: 2.8449 - rbf_fourier_loss: 1.6269 - val_loss: 2.2590 - val_out_loss: 2.8864 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2343 - out_loss: 2.8421 - rbf_fourier_loss: 1.6266 - val_loss: 2.2591 - val_out_loss: 2.8866 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2400 - out_loss: 2.8535 - rbf_fourier_loss: 1.6264 - val_loss: 2.2596 - val_out_loss: 2.8876 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2386 - out_loss: 2.8506 - rbf_fourier_loss: 1.6266 - val_loss: 2.2604 - val_out_loss: 2.8891 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2442 - out_loss: 2.8618 - rbf_fourier_loss: 1.6266 - val_loss: 2.2607 - val_out_loss: 2.8899 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2482 - out_loss: 2.8697 - rbf_fourier_loss: 1.6267 - val_loss: 2.2610 - val_out_loss: 2.8905 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2341 - out_loss: 2.8419 - rbf_fourier_loss: 1.6262 - val_loss: 2.2629 - val_out_loss: 2.8941 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2374 - out_loss: 2.8480 - rbf_fourier_loss: 1.6268 - val_loss: 2.2617 - val_out_loss: 2.8917 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2341 - out_loss: 2.8413 - rbf_fourier_loss: 1.6268 - val_loss: 2.2645 - val_out_loss: 2.8973 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2357 - out_loss: 2.8450 - rbf_fourier_loss: 1.6264 - val_loss: 2.2658 - val_out_loss: 2.9001 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2400 - out_loss: 2.8533 - rbf_fourier_loss: 1.6266 - val_loss: 2.2651 - val_out_loss: 2.8987 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2331 - out_loss: 2.8392 - rbf_fourier_loss: 1.6269 - val_loss: 2.2680 - val_out_loss: 2.9044 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2331 - out_loss: 2.8395 - rbf_fourier_loss: 1.6267 - val_loss: 2.2651 - val_out_loss: 2.8985 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2473 - out_loss: 2.8679 - rbf_fourier_loss: 1.6267 - val_loss: 2.2644 - val_out_loss: 2.8973 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2353 - out_loss: 2.8441 - rbf_fourier_loss: 1.6266 - val_loss: 2.2623 - val_out_loss: 2.8931 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2423 - out_loss: 2.8574 - rbf_fourier_loss: 1.6272 - val_loss: 2.2664 - val_out_loss: 2.9012 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 2.2364 - out_loss: 2.8461 - rbf_fourier_loss: 1.6267 - val_loss: 2.2662 - val_out_loss: 2.9008 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2331 - out_loss: 2.8394 - rbf_fourier_loss: 1.6268 - val_loss: 2.2670 - val_out_loss: 2.9024 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2325 - out_loss: 2.8386 - rbf_fourier_loss: 1.6264 - val_loss: 2.2653 - val_out_loss: 2.8989 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2309 - out_loss: 2.8355 - rbf_fourier_loss: 1.6262 - val_loss: 2.2648 - val_out_loss: 2.8980 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2290 - out_loss: 2.8314 - rbf_fourier_loss: 1.6266 - val_loss: 2.2640 - val_out_loss: 2.8963 - val_rbf_fourier_loss: 1.6316\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 2.2402 - out_loss: 2.8537 - rbf_fourier_loss: 1.6266 - val_loss: 2.2649 - val_out_loss: 2.8983 - val_rbf_fourier_loss: 1.6316\n",
            "it 2/10\n",
            "acc: 12.17\n",
            "ari: 0.1605903356671997\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 17ms/step - loss: 0.2656 - out_loss: 0.6219 - rbf_fourier_loss: -0.0906 - val_loss: 0.2625 - val_out_loss: 0.6173 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2658 - out_loss: 0.6225 - rbf_fourier_loss: -0.0908 - val_loss: 0.2624 - val_out_loss: 0.6171 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2664 - out_loss: 0.6253 - rbf_fourier_loss: -0.0925 - val_loss: 0.2605 - val_out_loss: 0.6133 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2643 - out_loss: 0.6196 - rbf_fourier_loss: -0.0910 - val_loss: 0.2607 - val_out_loss: 0.6136 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2629 - out_loss: 0.6165 - rbf_fourier_loss: -0.0907 - val_loss: 0.2599 - val_out_loss: 0.6121 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2621 - out_loss: 0.6156 - rbf_fourier_loss: -0.0913 - val_loss: 0.2610 - val_out_loss: 0.6143 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2570 - out_loss: 0.6070 - rbf_fourier_loss: -0.0929 - val_loss: 0.2583 - val_out_loss: 0.6088 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2628 - out_loss: 0.6170 - rbf_fourier_loss: -0.0914 - val_loss: 0.2581 - val_out_loss: 0.6084 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2551 - out_loss: 0.6021 - rbf_fourier_loss: -0.0920 - val_loss: 0.2560 - val_out_loss: 0.6043 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2542 - out_loss: 0.5992 - rbf_fourier_loss: -0.0909 - val_loss: 0.2553 - val_out_loss: 0.6028 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2516 - out_loss: 0.5952 - rbf_fourier_loss: -0.0919 - val_loss: 0.2540 - val_out_loss: 0.6003 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2492 - out_loss: 0.5906 - rbf_fourier_loss: -0.0921 - val_loss: 0.2527 - val_out_loss: 0.5977 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2503 - out_loss: 0.5922 - rbf_fourier_loss: -0.0915 - val_loss: 0.2503 - val_out_loss: 0.5928 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2453 - out_loss: 0.5816 - rbf_fourier_loss: -0.0911 - val_loss: 0.2481 - val_out_loss: 0.5885 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2463 - out_loss: 0.5859 - rbf_fourier_loss: -0.0932 - val_loss: 0.2469 - val_out_loss: 0.5861 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2455 - out_loss: 0.5823 - rbf_fourier_loss: -0.0913 - val_loss: 0.2467 - val_out_loss: 0.5856 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 0.2423 - out_loss: 0.5758 - rbf_fourier_loss: -0.0913 - val_loss: 0.2432 - val_out_loss: 0.5787 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2367 - out_loss: 0.5658 - rbf_fourier_loss: -0.0925 - val_loss: 0.2383 - val_out_loss: 0.5688 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2306 - out_loss: 0.5526 - rbf_fourier_loss: -0.0915 - val_loss: 0.2315 - val_out_loss: 0.5553 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2280 - out_loss: 0.5484 - rbf_fourier_loss: -0.0924 - val_loss: 0.2263 - val_out_loss: 0.5448 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2201 - out_loss: 0.5314 - rbf_fourier_loss: -0.0912 - val_loss: 0.2186 - val_out_loss: 0.5294 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2154 - out_loss: 0.5215 - rbf_fourier_loss: -0.0908 - val_loss: 0.2057 - val_out_loss: 0.5036 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.1938 - out_loss: 0.4797 - rbf_fourier_loss: -0.0922 - val_loss: 0.1834 - val_out_loss: 0.4590 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1658 - out_loss: 0.4247 - rbf_fourier_loss: -0.0930 - val_loss: 0.1249 - val_out_loss: 0.3420 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.0599 - out_loss: 0.2102 - rbf_fourier_loss: -0.0905 - val_loss: -0.5485 - val_out_loss: -1.0048 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.6124 - out_loss: -1.1327 - rbf_fourier_loss: -0.0921 - val_loss: -0.5938 - val_out_loss: -1.0953 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.6763 - out_loss: -1.2601 - rbf_fourier_loss: -0.0925 - val_loss: -0.6112 - val_out_loss: -1.1302 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7000 - out_loss: -1.3077 - rbf_fourier_loss: -0.0923 - val_loss: -0.6250 - val_out_loss: -1.1577 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7180 - out_loss: -1.3452 - rbf_fourier_loss: -0.0908 - val_loss: -0.6309 - val_out_loss: -1.1696 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7394 - out_loss: -1.3876 - rbf_fourier_loss: -0.0911 - val_loss: -0.7052 - val_out_loss: -1.3182 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7297 - out_loss: -1.3682 - rbf_fourier_loss: -0.0911 - val_loss: -0.6404 - val_out_loss: -1.1885 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7325 - out_loss: -1.3728 - rbf_fourier_loss: -0.0921 - val_loss: -0.6748 - val_out_loss: -1.2573 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7347 - out_loss: -1.3785 - rbf_fourier_loss: -0.0909 - val_loss: -0.6480 - val_out_loss: -1.2037 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7318 - out_loss: -1.3728 - rbf_fourier_loss: -0.0908 - val_loss: -0.6735 - val_out_loss: -1.2548 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7441 - out_loss: -1.3980 - rbf_fourier_loss: -0.0902 - val_loss: -0.6695 - val_out_loss: -1.2468 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7429 - out_loss: -1.3951 - rbf_fourier_loss: -0.0907 - val_loss: -0.7054 - val_out_loss: -1.3185 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7414 - out_loss: -1.3919 - rbf_fourier_loss: -0.0910 - val_loss: -0.6420 - val_out_loss: -1.1917 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7427 - out_loss: -1.3929 - rbf_fourier_loss: -0.0926 - val_loss: -0.6797 - val_out_loss: -1.2672 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7465 - out_loss: -1.4017 - rbf_fourier_loss: -0.0913 - val_loss: -0.7026 - val_out_loss: -1.3130 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7437 - out_loss: -1.3953 - rbf_fourier_loss: -0.0921 - val_loss: -0.6901 - val_out_loss: -1.2879 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7460 - out_loss: -1.3987 - rbf_fourier_loss: -0.0932 - val_loss: -0.7151 - val_out_loss: -1.3379 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7484 - out_loss: -1.4049 - rbf_fourier_loss: -0.0919 - val_loss: -0.6656 - val_out_loss: -1.2389 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7430 - out_loss: -1.3948 - rbf_fourier_loss: -0.0912 - val_loss: -0.6577 - val_out_loss: -1.2232 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7574 - out_loss: -1.4235 - rbf_fourier_loss: -0.0914 - val_loss: -0.6838 - val_out_loss: -1.2753 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7449 - out_loss: -1.3969 - rbf_fourier_loss: -0.0930 - val_loss: -0.7047 - val_out_loss: -1.3172 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7489 - out_loss: -1.4066 - rbf_fourier_loss: -0.0912 - val_loss: -0.7238 - val_out_loss: -1.3553 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7559 - out_loss: -1.4190 - rbf_fourier_loss: -0.0928 - val_loss: -0.6936 - val_out_loss: -1.2950 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7579 - out_loss: -1.4241 - rbf_fourier_loss: -0.0916 - val_loss: -0.6635 - val_out_loss: -1.2347 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7434 - out_loss: -1.3955 - rbf_fourier_loss: -0.0912 - val_loss: -0.7209 - val_out_loss: -1.3495 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7458 - out_loss: -1.3995 - rbf_fourier_loss: -0.0921 - val_loss: -0.6883 - val_out_loss: -1.2844 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7517 - out_loss: -1.4110 - rbf_fourier_loss: -0.0923 - val_loss: -0.6862 - val_out_loss: -1.2802 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7446 - out_loss: -1.3985 - rbf_fourier_loss: -0.0906 - val_loss: -0.6718 - val_out_loss: -1.2513 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7403 - out_loss: -1.3883 - rbf_fourier_loss: -0.0924 - val_loss: -0.7136 - val_out_loss: -1.3349 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7473 - out_loss: -1.4035 - rbf_fourier_loss: -0.0912 - val_loss: -0.7118 - val_out_loss: -1.3314 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7416 - out_loss: -1.3907 - rbf_fourier_loss: -0.0926 - val_loss: -0.7079 - val_out_loss: -1.3235 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7452 - out_loss: -1.3995 - rbf_fourier_loss: -0.0908 - val_loss: -0.6734 - val_out_loss: -1.2546 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7443 - out_loss: -1.3966 - rbf_fourier_loss: -0.0919 - val_loss: -0.6709 - val_out_loss: -1.2495 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7467 - out_loss: -1.4021 - rbf_fourier_loss: -0.0913 - val_loss: -0.6713 - val_out_loss: -1.2503 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7418 - out_loss: -1.3924 - rbf_fourier_loss: -0.0913 - val_loss: -0.6892 - val_out_loss: -1.2861 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7437 - out_loss: -1.3961 - rbf_fourier_loss: -0.0914 - val_loss: -0.6886 - val_out_loss: -1.2849 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7458 - out_loss: -1.4002 - rbf_fourier_loss: -0.0915 - val_loss: -0.6850 - val_out_loss: -1.2778 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7524 - out_loss: -1.4129 - rbf_fourier_loss: -0.0920 - val_loss: -0.7168 - val_out_loss: -1.3414 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7488 - out_loss: -1.4039 - rbf_fourier_loss: -0.0937 - val_loss: -0.6908 - val_out_loss: -1.2894 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7524 - out_loss: -1.4129 - rbf_fourier_loss: -0.0919 - val_loss: -0.6596 - val_out_loss: -1.2270 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7482 - out_loss: -1.4043 - rbf_fourier_loss: -0.0922 - val_loss: -0.6706 - val_out_loss: -1.2489 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7494 - out_loss: -1.4080 - rbf_fourier_loss: -0.0909 - val_loss: -0.6853 - val_out_loss: -1.2784 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7474 - out_loss: -1.4034 - rbf_fourier_loss: -0.0914 - val_loss: -0.6916 - val_out_loss: -1.2910 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7465 - out_loss: -1.4013 - rbf_fourier_loss: -0.0917 - val_loss: -0.7271 - val_out_loss: -1.3620 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7517 - out_loss: -1.4118 - rbf_fourier_loss: -0.0917 - val_loss: -0.7255 - val_out_loss: -1.3587 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7508 - out_loss: -1.4094 - rbf_fourier_loss: -0.0922 - val_loss: -0.6204 - val_out_loss: -1.1485 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7444 - out_loss: -1.3979 - rbf_fourier_loss: -0.0908 - val_loss: -0.7252 - val_out_loss: -1.3582 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7453 - out_loss: -1.3994 - rbf_fourier_loss: -0.0912 - val_loss: -0.6936 - val_out_loss: -1.2949 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7389 - out_loss: -1.3868 - rbf_fourier_loss: -0.0909 - val_loss: -0.7118 - val_out_loss: -1.3313 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7493 - out_loss: -1.4085 - rbf_fourier_loss: -0.0900 - val_loss: -0.7225 - val_out_loss: -1.3527 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7471 - out_loss: -1.4032 - rbf_fourier_loss: -0.0910 - val_loss: -0.6754 - val_out_loss: -1.2585 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7496 - out_loss: -1.4085 - rbf_fourier_loss: -0.0907 - val_loss: -0.6840 - val_out_loss: -1.2758 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7457 - out_loss: -1.3986 - rbf_fourier_loss: -0.0929 - val_loss: -0.6982 - val_out_loss: -1.3041 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7489 - out_loss: -1.4075 - rbf_fourier_loss: -0.0902 - val_loss: -0.6958 - val_out_loss: -1.2993 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7480 - out_loss: -1.4046 - rbf_fourier_loss: -0.0914 - val_loss: -0.7185 - val_out_loss: -1.3448 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7400 - out_loss: -1.3902 - rbf_fourier_loss: -0.0899 - val_loss: -0.6772 - val_out_loss: -1.2621 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7420 - out_loss: -1.3927 - rbf_fourier_loss: -0.0913 - val_loss: -0.6948 - val_out_loss: -1.2974 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7459 - out_loss: -1.3996 - rbf_fourier_loss: -0.0923 - val_loss: -0.6932 - val_out_loss: -1.2942 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7477 - out_loss: -1.4032 - rbf_fourier_loss: -0.0923 - val_loss: -0.6857 - val_out_loss: -1.2793 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7437 - out_loss: -1.3945 - rbf_fourier_loss: -0.0930 - val_loss: -0.6694 - val_out_loss: -1.2465 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.7330 - out_loss: -1.3741 - rbf_fourier_loss: -0.0918 - val_loss: -0.7095 - val_out_loss: -1.3267 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7477 - out_loss: -1.4032 - rbf_fourier_loss: -0.0922 - val_loss: -0.6999 - val_out_loss: -1.3075 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7426 - out_loss: -1.3929 - rbf_fourier_loss: -0.0923 - val_loss: -0.7277 - val_out_loss: -1.3632 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7442 - out_loss: -1.3967 - rbf_fourier_loss: -0.0917 - val_loss: -0.6959 - val_out_loss: -1.2996 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7516 - out_loss: -1.4122 - rbf_fourier_loss: -0.0910 - val_loss: -0.6998 - val_out_loss: -1.3074 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7469 - out_loss: -1.4013 - rbf_fourier_loss: -0.0926 - val_loss: -0.6856 - val_out_loss: -1.2790 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7427 - out_loss: -1.3955 - rbf_fourier_loss: -0.0898 - val_loss: -0.6762 - val_out_loss: -1.2601 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7400 - out_loss: -1.3893 - rbf_fourier_loss: -0.0908 - val_loss: -0.6514 - val_out_loss: -1.2106 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7467 - out_loss: -1.4013 - rbf_fourier_loss: -0.0920 - val_loss: -0.6701 - val_out_loss: -1.2479 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7493 - out_loss: -1.4056 - rbf_fourier_loss: -0.0929 - val_loss: -0.6672 - val_out_loss: -1.2422 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7428 - out_loss: -1.3945 - rbf_fourier_loss: -0.0911 - val_loss: -0.6973 - val_out_loss: -1.3024 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7421 - out_loss: -1.3944 - rbf_fourier_loss: -0.0897 - val_loss: -0.7150 - val_out_loss: -1.3377 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7428 - out_loss: -1.3927 - rbf_fourier_loss: -0.0928 - val_loss: -0.6957 - val_out_loss: -1.2993 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7473 - out_loss: -1.4031 - rbf_fourier_loss: -0.0914 - val_loss: -0.6893 - val_out_loss: -1.2864 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7469 - out_loss: -1.4004 - rbf_fourier_loss: -0.0934 - val_loss: -0.6560 - val_out_loss: -1.2197 - val_rbf_fourier_loss: -0.0922\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7476 - out_loss: -1.4025 - rbf_fourier_loss: -0.0927 - val_loss: -0.7265 - val_out_loss: -1.3608 - val_rbf_fourier_loss: -0.0922\n",
            "it 2/10\n",
            "acc: 11.335\n",
            "ari: 0.004225855533395388\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 19ms/step - loss: 0.2683 - out_loss: 0.6304 - rbf_fourier_loss: -0.0939 - val_loss: 0.2698 - val_out_loss: 0.6327 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2675 - out_loss: 0.6269 - rbf_fourier_loss: -0.0920 - val_loss: 0.2674 - val_out_loss: 0.6278 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2641 - out_loss: 0.6206 - rbf_fourier_loss: -0.0925 - val_loss: 0.2677 - val_out_loss: 0.6286 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2637 - out_loss: 0.6192 - rbf_fourier_loss: -0.0918 - val_loss: 0.2663 - val_out_loss: 0.6257 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2622 - out_loss: 0.6172 - rbf_fourier_loss: -0.0927 - val_loss: 0.2665 - val_out_loss: 0.6261 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2576 - out_loss: 0.6071 - rbf_fourier_loss: -0.0919 - val_loss: 0.2673 - val_out_loss: 0.6277 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2601 - out_loss: 0.6128 - rbf_fourier_loss: -0.0927 - val_loss: 0.2656 - val_out_loss: 0.6243 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2605 - out_loss: 0.6125 - rbf_fourier_loss: -0.0915 - val_loss: 0.2641 - val_out_loss: 0.6213 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2491 - out_loss: 0.5908 - rbf_fourier_loss: -0.0925 - val_loss: 0.2625 - val_out_loss: 0.6182 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2527 - out_loss: 0.5971 - rbf_fourier_loss: -0.0917 - val_loss: 0.2609 - val_out_loss: 0.6148 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2503 - out_loss: 0.5932 - rbf_fourier_loss: -0.0926 - val_loss: 0.2594 - val_out_loss: 0.6118 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2570 - out_loss: 0.6058 - rbf_fourier_loss: -0.0919 - val_loss: 0.2572 - val_out_loss: 0.6075 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2522 - out_loss: 0.5965 - rbf_fourier_loss: -0.0922 - val_loss: 0.2546 - val_out_loss: 0.6022 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2512 - out_loss: 0.5942 - rbf_fourier_loss: -0.0918 - val_loss: 0.2513 - val_out_loss: 0.5957 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2474 - out_loss: 0.5861 - rbf_fourier_loss: -0.0913 - val_loss: 0.2474 - val_out_loss: 0.5879 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2429 - out_loss: 0.5790 - rbf_fourier_loss: -0.0931 - val_loss: 0.2441 - val_out_loss: 0.5813 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2403 - out_loss: 0.5718 - rbf_fourier_loss: -0.0913 - val_loss: 0.2434 - val_out_loss: 0.5798 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2394 - out_loss: 0.5718 - rbf_fourier_loss: -0.0930 - val_loss: 0.2407 - val_out_loss: 0.5745 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2344 - out_loss: 0.5599 - rbf_fourier_loss: -0.0912 - val_loss: 0.2380 - val_out_loss: 0.5691 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2325 - out_loss: 0.5563 - rbf_fourier_loss: -0.0913 - val_loss: 0.2307 - val_out_loss: 0.5544 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2205 - out_loss: 0.5331 - rbf_fourier_loss: -0.0920 - val_loss: 0.2188 - val_out_loss: 0.5307 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2159 - out_loss: 0.5236 - rbf_fourier_loss: -0.0917 - val_loss: 0.2105 - val_out_loss: 0.5140 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2015 - out_loss: 0.4944 - rbf_fourier_loss: -0.0913 - val_loss: 0.1912 - val_out_loss: 0.4754 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1782 - out_loss: 0.4481 - rbf_fourier_loss: -0.0917 - val_loss: 0.1500 - val_out_loss: 0.3931 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.1237 - out_loss: 0.3394 - rbf_fourier_loss: -0.0921 - val_loss: -0.1683 - val_out_loss: -0.2436 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.4457 - out_loss: -0.7989 - rbf_fourier_loss: -0.0924 - val_loss: -0.6231 - val_out_loss: -1.1532 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0630 - out_loss: -2.0346 - rbf_fourier_loss: -0.0913 - val_loss: -1.3913 - val_out_loss: -2.6896 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4117 - out_loss: -2.7314 - rbf_fourier_loss: -0.0920 - val_loss: -1.4062 - val_out_loss: -2.7194 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4208 - out_loss: -2.7504 - rbf_fourier_loss: -0.0913 - val_loss: -1.4139 - val_out_loss: -2.7348 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4107 - out_loss: -2.7300 - rbf_fourier_loss: -0.0914 - val_loss: -1.4039 - val_out_loss: -2.7148 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4008 - out_loss: -2.7101 - rbf_fourier_loss: -0.0914 - val_loss: -1.3967 - val_out_loss: -2.7003 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3951 - out_loss: -2.6986 - rbf_fourier_loss: -0.0917 - val_loss: -1.3348 - val_out_loss: -2.5765 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3777 - out_loss: -2.6645 - rbf_fourier_loss: -0.0910 - val_loss: -1.3842 - val_out_loss: -2.6754 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3513 - out_loss: -2.6103 - rbf_fourier_loss: -0.0922 - val_loss: -1.3476 - val_out_loss: -2.6021 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3208 - out_loss: -2.5497 - rbf_fourier_loss: -0.0919 - val_loss: -1.3228 - val_out_loss: -2.5526 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3375 - out_loss: -2.5831 - rbf_fourier_loss: -0.0920 - val_loss: -1.3440 - val_out_loss: -2.5950 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2927 - out_loss: -2.4924 - rbf_fourier_loss: -0.0930 - val_loss: -1.3586 - val_out_loss: -2.6241 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2937 - out_loss: -2.4975 - rbf_fourier_loss: -0.0899 - val_loss: -1.3057 - val_out_loss: -2.5183 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2953 - out_loss: -2.4992 - rbf_fourier_loss: -0.0915 - val_loss: -1.3170 - val_out_loss: -2.5410 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2857 - out_loss: -2.4798 - rbf_fourier_loss: -0.0916 - val_loss: -1.2955 - val_out_loss: -2.4979 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2737 - out_loss: -2.4544 - rbf_fourier_loss: -0.0930 - val_loss: -1.2913 - val_out_loss: -2.4895 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2681 - out_loss: -2.4426 - rbf_fourier_loss: -0.0935 - val_loss: -1.2948 - val_out_loss: -2.4965 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2378 - out_loss: -2.3840 - rbf_fourier_loss: -0.0916 - val_loss: -1.2885 - val_out_loss: -2.4839 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2684 - out_loss: -2.4462 - rbf_fourier_loss: -0.0906 - val_loss: -1.2357 - val_out_loss: -2.3784 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2784 - out_loss: -2.4633 - rbf_fourier_loss: -0.0935 - val_loss: -1.2390 - val_out_loss: -2.3849 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2564 - out_loss: -2.4206 - rbf_fourier_loss: -0.0922 - val_loss: -1.2653 - val_out_loss: -2.4376 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2216 - out_loss: -2.3500 - rbf_fourier_loss: -0.0932 - val_loss: -1.2784 - val_out_loss: -2.4636 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2120 - out_loss: -2.3315 - rbf_fourier_loss: -0.0925 - val_loss: -1.2103 - val_out_loss: -2.3276 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2490 - out_loss: -2.4064 - rbf_fourier_loss: -0.0915 - val_loss: -1.2528 - val_out_loss: -2.4126 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2277 - out_loss: -2.3641 - rbf_fourier_loss: -0.0912 - val_loss: -1.2601 - val_out_loss: -2.4271 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2422 - out_loss: -2.3928 - rbf_fourier_loss: -0.0915 - val_loss: -1.2362 - val_out_loss: -2.3793 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2045 - out_loss: -2.3161 - rbf_fourier_loss: -0.0928 - val_loss: -1.2333 - val_out_loss: -2.3735 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2090 - out_loss: -2.3253 - rbf_fourier_loss: -0.0927 - val_loss: -1.2217 - val_out_loss: -2.3503 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2018 - out_loss: -2.3122 - rbf_fourier_loss: -0.0915 - val_loss: -1.2432 - val_out_loss: -2.3934 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2136 - out_loss: -2.3363 - rbf_fourier_loss: -0.0909 - val_loss: -1.2227 - val_out_loss: -2.3523 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2263 - out_loss: -2.3607 - rbf_fourier_loss: -0.0919 - val_loss: -1.2399 - val_out_loss: -2.3867 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2084 - out_loss: -2.3256 - rbf_fourier_loss: -0.0912 - val_loss: -1.1504 - val_out_loss: -2.2078 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2041 - out_loss: -2.3163 - rbf_fourier_loss: -0.0919 - val_loss: -1.1739 - val_out_loss: -2.2546 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2356 - out_loss: -2.3793 - rbf_fourier_loss: -0.0919 - val_loss: -1.1894 - val_out_loss: -2.2857 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1592 - out_loss: -2.2252 - rbf_fourier_loss: -0.0932 - val_loss: -1.1373 - val_out_loss: -2.1815 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2176 - out_loss: -2.3443 - rbf_fourier_loss: -0.0908 - val_loss: -1.1121 - val_out_loss: -2.1312 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1256 - out_loss: -2.1594 - rbf_fourier_loss: -0.0917 - val_loss: -1.1152 - val_out_loss: -2.1373 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1546 - out_loss: -2.2180 - rbf_fourier_loss: -0.0911 - val_loss: -1.0764 - val_out_loss: -2.0597 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1516 - out_loss: -2.2114 - rbf_fourier_loss: -0.0919 - val_loss: -1.0730 - val_out_loss: -2.0529 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1339 - out_loss: -2.1767 - rbf_fourier_loss: -0.0912 - val_loss: -1.1098 - val_out_loss: -2.1266 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2120 - out_loss: -2.3311 - rbf_fourier_loss: -0.0930 - val_loss: -1.0632 - val_out_loss: -2.0333 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1251 - out_loss: -2.1579 - rbf_fourier_loss: -0.0923 - val_loss: -1.0583 - val_out_loss: -2.0235 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1583 - out_loss: -2.2260 - rbf_fourier_loss: -0.0905 - val_loss: -1.0924 - val_out_loss: -2.0917 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1955 - out_loss: -2.3002 - rbf_fourier_loss: -0.0909 - val_loss: -1.1260 - val_out_loss: -2.1588 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1384 - out_loss: -2.1858 - rbf_fourier_loss: -0.0909 - val_loss: -1.0779 - val_out_loss: -2.0627 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1357 - out_loss: -2.1808 - rbf_fourier_loss: -0.0906 - val_loss: -1.0288 - val_out_loss: -1.9646 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0919 - out_loss: -2.0911 - rbf_fourier_loss: -0.0927 - val_loss: -1.0304 - val_out_loss: -1.9677 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1703 - out_loss: -2.2482 - rbf_fourier_loss: -0.0923 - val_loss: -1.0399 - val_out_loss: -1.9867 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1300 - out_loss: -2.1684 - rbf_fourier_loss: -0.0916 - val_loss: -1.0159 - val_out_loss: -1.9387 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0929 - out_loss: -2.0945 - rbf_fourier_loss: -0.0912 - val_loss: -1.0421 - val_out_loss: -1.9912 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1055 - out_loss: -2.1191 - rbf_fourier_loss: -0.0918 - val_loss: -1.0023 - val_out_loss: -1.9116 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1303 - out_loss: -2.1688 - rbf_fourier_loss: -0.0919 - val_loss: -1.0531 - val_out_loss: -2.0132 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1348 - out_loss: -2.1774 - rbf_fourier_loss: -0.0922 - val_loss: -1.0702 - val_out_loss: -2.0474 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1432 - out_loss: -2.1933 - rbf_fourier_loss: -0.0931 - val_loss: -0.9993 - val_out_loss: -1.9055 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1553 - out_loss: -2.2197 - rbf_fourier_loss: -0.0908 - val_loss: -1.0201 - val_out_loss: -1.9472 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1524 - out_loss: -2.2142 - rbf_fourier_loss: -0.0906 - val_loss: -1.0319 - val_out_loss: -1.9707 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1251 - out_loss: -2.1586 - rbf_fourier_loss: -0.0915 - val_loss: -0.9862 - val_out_loss: -1.8793 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1295 - out_loss: -2.1683 - rbf_fourier_loss: -0.0908 - val_loss: -0.9847 - val_out_loss: -1.8764 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0644 - out_loss: -2.0359 - rbf_fourier_loss: -0.0930 - val_loss: -0.9754 - val_out_loss: -1.8577 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1220 - out_loss: -2.1523 - rbf_fourier_loss: -0.0918 - val_loss: -0.9852 - val_out_loss: -1.8772 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0740 - out_loss: -2.0571 - rbf_fourier_loss: -0.0909 - val_loss: -0.9709 - val_out_loss: -1.8487 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1004 - out_loss: -2.1098 - rbf_fourier_loss: -0.0911 - val_loss: -0.9752 - val_out_loss: -1.8572 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1197 - out_loss: -2.1478 - rbf_fourier_loss: -0.0916 - val_loss: -1.0013 - val_out_loss: -1.9095 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1560 - out_loss: -2.2218 - rbf_fourier_loss: -0.0902 - val_loss: -0.9770 - val_out_loss: -1.8610 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1105 - out_loss: -2.1285 - rbf_fourier_loss: -0.0924 - val_loss: -1.0048 - val_out_loss: -1.9165 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1082 - out_loss: -2.1247 - rbf_fourier_loss: -0.0917 - val_loss: -0.9492 - val_out_loss: -1.8053 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1063 - out_loss: -2.1198 - rbf_fourier_loss: -0.0929 - val_loss: -1.0038 - val_out_loss: -1.9146 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0779 - out_loss: -2.0634 - rbf_fourier_loss: -0.0924 - val_loss: -0.9894 - val_out_loss: -1.8858 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1264 - out_loss: -2.1609 - rbf_fourier_loss: -0.0919 - val_loss: -1.0136 - val_out_loss: -1.9341 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1004 - out_loss: -2.1084 - rbf_fourier_loss: -0.0924 - val_loss: -0.9984 - val_out_loss: -1.9037 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1028 - out_loss: -2.1141 - rbf_fourier_loss: -0.0916 - val_loss: -0.9397 - val_out_loss: -1.7863 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1311 - out_loss: -2.1718 - rbf_fourier_loss: -0.0904 - val_loss: -1.0254 - val_out_loss: -1.9576 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1085 - out_loss: -2.1244 - rbf_fourier_loss: -0.0925 - val_loss: -0.9526 - val_out_loss: -1.8121 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1199 - out_loss: -2.1481 - rbf_fourier_loss: -0.0916 - val_loss: -0.9276 - val_out_loss: -1.7622 - val_rbf_fourier_loss: -0.0931\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1003 - out_loss: -2.1095 - rbf_fourier_loss: -0.0911 - val_loss: -0.9351 - val_out_loss: -1.7772 - val_rbf_fourier_loss: -0.0931\n",
            "it 2/10\n",
            "acc: 11.26\n",
            "ari: 0.0003126178949408168\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 17ms/step - loss: 0.2668 - out_loss: 0.6256 - rbf_fourier_loss: -0.0920 - val_loss: 0.2700 - val_out_loss: 0.6317 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2656 - out_loss: 0.6229 - rbf_fourier_loss: -0.0918 - val_loss: 0.2681 - val_out_loss: 0.6280 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2612 - out_loss: 0.6149 - rbf_fourier_loss: -0.0924 - val_loss: 0.2680 - val_out_loss: 0.6279 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2649 - out_loss: 0.6211 - rbf_fourier_loss: -0.0913 - val_loss: 0.2693 - val_out_loss: 0.6303 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2606 - out_loss: 0.6140 - rbf_fourier_loss: -0.0929 - val_loss: 0.2673 - val_out_loss: 0.6264 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2600 - out_loss: 0.6118 - rbf_fourier_loss: -0.0918 - val_loss: 0.2660 - val_out_loss: 0.6239 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2564 - out_loss: 0.6056 - rbf_fourier_loss: -0.0929 - val_loss: 0.2650 - val_out_loss: 0.6218 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2525 - out_loss: 0.5971 - rbf_fourier_loss: -0.0921 - val_loss: 0.2627 - val_out_loss: 0.6172 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2591 - out_loss: 0.6093 - rbf_fourier_loss: -0.0911 - val_loss: 0.2591 - val_out_loss: 0.6101 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2590 - out_loss: 0.6097 - rbf_fourier_loss: -0.0918 - val_loss: 0.2565 - val_out_loss: 0.6048 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2540 - out_loss: 0.5998 - rbf_fourier_loss: -0.0919 - val_loss: 0.2551 - val_out_loss: 0.6020 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.2491 - out_loss: 0.5906 - rbf_fourier_loss: -0.0923 - val_loss: 0.2537 - val_out_loss: 0.5993 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2487 - out_loss: 0.5896 - rbf_fourier_loss: -0.0922 - val_loss: 0.2515 - val_out_loss: 0.5949 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2455 - out_loss: 0.5845 - rbf_fourier_loss: -0.0935 - val_loss: 0.2508 - val_out_loss: 0.5935 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2416 - out_loss: 0.5759 - rbf_fourier_loss: -0.0927 - val_loss: 0.2464 - val_out_loss: 0.5847 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2450 - out_loss: 0.5827 - rbf_fourier_loss: -0.0927 - val_loss: 0.2442 - val_out_loss: 0.5801 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2415 - out_loss: 0.5759 - rbf_fourier_loss: -0.0928 - val_loss: 0.2424 - val_out_loss: 0.5766 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2293 - out_loss: 0.5502 - rbf_fourier_loss: -0.0916 - val_loss: 0.2378 - val_out_loss: 0.5673 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2351 - out_loss: 0.5612 - rbf_fourier_loss: -0.0909 - val_loss: 0.2312 - val_out_loss: 0.5543 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2254 - out_loss: 0.5417 - rbf_fourier_loss: -0.0909 - val_loss: 0.2263 - val_out_loss: 0.5444 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2193 - out_loss: 0.5300 - rbf_fourier_loss: -0.0914 - val_loss: 0.2169 - val_out_loss: 0.5257 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2061 - out_loss: 0.5039 - rbf_fourier_loss: -0.0917 - val_loss: 0.2003 - val_out_loss: 0.4924 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1937 - out_loss: 0.4790 - rbf_fourier_loss: -0.0917 - val_loss: 0.1724 - val_out_loss: 0.4367 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.1552 - out_loss: 0.4028 - rbf_fourier_loss: -0.0924 - val_loss: 0.0959 - val_out_loss: 0.2836 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.0372 - out_loss: 0.0185 - rbf_fourier_loss: -0.0928 - val_loss: -0.3812 - val_out_loss: -0.6707 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.8082 - out_loss: -1.5249 - rbf_fourier_loss: -0.0914 - val_loss: -1.3296 - val_out_loss: -2.5674 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3985 - out_loss: -2.7064 - rbf_fourier_loss: -0.0905 - val_loss: -1.4163 - val_out_loss: -2.7408 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.4223 - out_loss: -2.7528 - rbf_fourier_loss: -0.0919 - val_loss: -1.4070 - val_out_loss: -2.7222 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.4087 - out_loss: -2.7242 - rbf_fourier_loss: -0.0932 - val_loss: -1.3919 - val_out_loss: -2.6920 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3933 - out_loss: -2.6948 - rbf_fourier_loss: -0.0918 - val_loss: -1.3601 - val_out_loss: -2.6285 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3805 - out_loss: -2.6696 - rbf_fourier_loss: -0.0914 - val_loss: -1.3761 - val_out_loss: -2.6603 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.3901 - out_loss: -2.6865 - rbf_fourier_loss: -0.0937 - val_loss: -1.3837 - val_out_loss: -2.6757 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3693 - out_loss: -2.6454 - rbf_fourier_loss: -0.0931 - val_loss: -1.3669 - val_out_loss: -2.6420 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3655 - out_loss: -2.6393 - rbf_fourier_loss: -0.0917 - val_loss: -1.3657 - val_out_loss: -2.6396 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3493 - out_loss: -2.6063 - rbf_fourier_loss: -0.0923 - val_loss: -1.3462 - val_out_loss: -2.6007 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3345 - out_loss: -2.5767 - rbf_fourier_loss: -0.0923 - val_loss: -1.3372 - val_out_loss: -2.5825 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3170 - out_loss: -2.5431 - rbf_fourier_loss: -0.0908 - val_loss: -1.3285 - val_out_loss: -2.5653 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3108 - out_loss: -2.5288 - rbf_fourier_loss: -0.0928 - val_loss: -1.2965 - val_out_loss: -2.5011 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3246 - out_loss: -2.5570 - rbf_fourier_loss: -0.0922 - val_loss: -1.2483 - val_out_loss: -2.4048 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.3056 - out_loss: -2.5184 - rbf_fourier_loss: -0.0927 - val_loss: -1.3291 - val_out_loss: -2.5665 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2670 - out_loss: -2.4433 - rbf_fourier_loss: -0.0907 - val_loss: -1.2979 - val_out_loss: -2.5041 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2862 - out_loss: -2.4805 - rbf_fourier_loss: -0.0919 - val_loss: -1.2856 - val_out_loss: -2.4795 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2583 - out_loss: -2.4257 - rbf_fourier_loss: -0.0908 - val_loss: -1.2901 - val_out_loss: -2.4884 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2380 - out_loss: -2.3848 - rbf_fourier_loss: -0.0911 - val_loss: -1.2843 - val_out_loss: -2.4768 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2203 - out_loss: -2.3490 - rbf_fourier_loss: -0.0916 - val_loss: -1.2140 - val_out_loss: -2.3363 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2558 - out_loss: -2.4200 - rbf_fourier_loss: -0.0916 - val_loss: -1.2669 - val_out_loss: -2.4419 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2307 - out_loss: -2.3695 - rbf_fourier_loss: -0.0919 - val_loss: -1.2203 - val_out_loss: -2.3487 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2497 - out_loss: -2.4061 - rbf_fourier_loss: -0.0933 - val_loss: -1.2542 - val_out_loss: -2.4166 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.2542 - out_loss: -2.4160 - rbf_fourier_loss: -0.0924 - val_loss: -1.2122 - val_out_loss: -2.3325 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1770 - out_loss: -2.2616 - rbf_fourier_loss: -0.0923 - val_loss: -1.1706 - val_out_loss: -2.2494 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2080 - out_loss: -2.3228 - rbf_fourier_loss: -0.0932 - val_loss: -1.2165 - val_out_loss: -2.3411 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1731 - out_loss: -2.2549 - rbf_fourier_loss: -0.0913 - val_loss: -1.1977 - val_out_loss: -2.3036 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1890 - out_loss: -2.2865 - rbf_fourier_loss: -0.0915 - val_loss: -1.1646 - val_out_loss: -2.2374 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2010 - out_loss: -2.3107 - rbf_fourier_loss: -0.0913 - val_loss: -1.1865 - val_out_loss: -2.2813 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2064 - out_loss: -2.3206 - rbf_fourier_loss: -0.0922 - val_loss: -1.1859 - val_out_loss: -2.2800 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1881 - out_loss: -2.2856 - rbf_fourier_loss: -0.0906 - val_loss: -1.1234 - val_out_loss: -2.1549 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1574 - out_loss: -2.2228 - rbf_fourier_loss: -0.0920 - val_loss: -1.1759 - val_out_loss: -2.2599 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1365 - out_loss: -2.1806 - rbf_fourier_loss: -0.0924 - val_loss: -1.1633 - val_out_loss: -2.2349 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1860 - out_loss: -2.2803 - rbf_fourier_loss: -0.0918 - val_loss: -1.1312 - val_out_loss: -2.1706 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1664 - out_loss: -2.2405 - rbf_fourier_loss: -0.0924 - val_loss: -1.1662 - val_out_loss: -2.2405 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1491 - out_loss: -2.2058 - rbf_fourier_loss: -0.0923 - val_loss: -1.1423 - val_out_loss: -2.1929 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1429 - out_loss: -2.1937 - rbf_fourier_loss: -0.0920 - val_loss: -1.1524 - val_out_loss: -2.2130 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1949 - out_loss: -2.2964 - rbf_fourier_loss: -0.0935 - val_loss: -1.1630 - val_out_loss: -2.2342 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1428 - out_loss: -2.1945 - rbf_fourier_loss: -0.0912 - val_loss: -1.1526 - val_out_loss: -2.2133 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0936 - out_loss: -2.0967 - rbf_fourier_loss: -0.0906 - val_loss: -1.1257 - val_out_loss: -2.1596 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1180 - out_loss: -2.1434 - rbf_fourier_loss: -0.0925 - val_loss: -1.1016 - val_out_loss: -2.1114 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1345 - out_loss: -2.1755 - rbf_fourier_loss: -0.0935 - val_loss: -1.1284 - val_out_loss: -2.1650 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1619 - out_loss: -2.2310 - rbf_fourier_loss: -0.0929 - val_loss: -1.0976 - val_out_loss: -2.1034 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: -1.1421 - out_loss: -2.1923 - rbf_fourier_loss: -0.0918 - val_loss: -1.0914 - val_out_loss: -2.0909 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1327 - out_loss: -2.1727 - rbf_fourier_loss: -0.0928 - val_loss: -1.0814 - val_out_loss: -2.0710 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1851 - out_loss: -2.2781 - rbf_fourier_loss: -0.0921 - val_loss: -1.0511 - val_out_loss: -2.0104 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1570 - out_loss: -2.2232 - rbf_fourier_loss: -0.0908 - val_loss: -1.0850 - val_out_loss: -2.0782 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1866 - out_loss: -2.2813 - rbf_fourier_loss: -0.0919 - val_loss: -1.0867 - val_out_loss: -2.0816 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1624 - out_loss: -2.2349 - rbf_fourier_loss: -0.0899 - val_loss: -1.0721 - val_out_loss: -2.0525 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1481 - out_loss: -2.2025 - rbf_fourier_loss: -0.0938 - val_loss: -1.0760 - val_out_loss: -2.0602 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1120 - out_loss: -2.1321 - rbf_fourier_loss: -0.0919 - val_loss: -1.0766 - val_out_loss: -2.0614 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1279 - out_loss: -2.1637 - rbf_fourier_loss: -0.0920 - val_loss: -1.0426 - val_out_loss: -1.9934 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1152 - out_loss: -2.1376 - rbf_fourier_loss: -0.0929 - val_loss: -1.0830 - val_out_loss: -2.0743 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1017 - out_loss: -2.1110 - rbf_fourier_loss: -0.0925 - val_loss: -1.0736 - val_out_loss: -2.0553 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1375 - out_loss: -2.1827 - rbf_fourier_loss: -0.0923 - val_loss: -1.1000 - val_out_loss: -2.1082 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1234 - out_loss: -2.1533 - rbf_fourier_loss: -0.0935 - val_loss: -1.0653 - val_out_loss: -2.0388 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1482 - out_loss: -2.2048 - rbf_fourier_loss: -0.0916 - val_loss: -1.0995 - val_out_loss: -2.1073 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1246 - out_loss: -2.1574 - rbf_fourier_loss: -0.0917 - val_loss: -1.0928 - val_out_loss: -2.0937 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1483 - out_loss: -2.2040 - rbf_fourier_loss: -0.0927 - val_loss: -1.0407 - val_out_loss: -1.9896 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1017 - out_loss: -2.1112 - rbf_fourier_loss: -0.0922 - val_loss: -1.0550 - val_out_loss: -2.0182 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1368 - out_loss: -2.1814 - rbf_fourier_loss: -0.0921 - val_loss: -1.0176 - val_out_loss: -1.9434 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1106 - out_loss: -2.1268 - rbf_fourier_loss: -0.0944 - val_loss: -1.0188 - val_out_loss: -1.9458 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1096 - out_loss: -2.1257 - rbf_fourier_loss: -0.0935 - val_loss: -1.0254 - val_out_loss: -1.9589 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1312 - out_loss: -2.1719 - rbf_fourier_loss: -0.0905 - val_loss: -0.9532 - val_out_loss: -1.8145 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1358 - out_loss: -2.1793 - rbf_fourier_loss: -0.0922 - val_loss: -0.9796 - val_out_loss: -1.8674 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1787 - out_loss: -2.2670 - rbf_fourier_loss: -0.0903 - val_loss: -1.0284 - val_out_loss: -1.9651 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1344 - out_loss: -2.1771 - rbf_fourier_loss: -0.0917 - val_loss: -1.0543 - val_out_loss: -2.0168 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1137 - out_loss: -2.1354 - rbf_fourier_loss: -0.0920 - val_loss: -0.9490 - val_out_loss: -1.8063 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1189 - out_loss: -2.1457 - rbf_fourier_loss: -0.0921 - val_loss: -0.9762 - val_out_loss: -1.8606 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1488 - out_loss: -2.2052 - rbf_fourier_loss: -0.0923 - val_loss: -1.0000 - val_out_loss: -1.9081 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0947 - out_loss: -2.0985 - rbf_fourier_loss: -0.0909 - val_loss: -1.0042 - val_out_loss: -1.9166 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0857 - out_loss: -2.0798 - rbf_fourier_loss: -0.0915 - val_loss: -1.0026 - val_out_loss: -1.9135 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0714 - out_loss: -2.0506 - rbf_fourier_loss: -0.0923 - val_loss: -0.9894 - val_out_loss: -1.8870 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0818 - out_loss: -2.0725 - rbf_fourier_loss: -0.0911 - val_loss: -0.9926 - val_out_loss: -1.8934 - val_rbf_fourier_loss: -0.0918\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1191 - out_loss: -2.1470 - rbf_fourier_loss: -0.0913 - val_loss: -0.9719 - val_out_loss: -1.8519 - val_rbf_fourier_loss: -0.0918\n",
            "it 2/10\n",
            "acc: 11.253333333333334\n",
            "ari: -4.6353310263785365e-06\n",
            "it 2/10\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 17ms/step - loss: 0.4495 - out_loss: 0.9955 - rbf_fourier_loss: -0.0965 - val_loss: 0.4528 - val_out_loss: 0.9994 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4500 - out_loss: 0.9944 - rbf_fourier_loss: -0.0944 - val_loss: 0.4521 - val_out_loss: 0.9981 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4474 - out_loss: 0.9908 - rbf_fourier_loss: -0.0959 - val_loss: 0.4505 - val_out_loss: 0.9948 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4417 - out_loss: 0.9780 - rbf_fourier_loss: -0.0947 - val_loss: 0.4499 - val_out_loss: 0.9935 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4425 - out_loss: 0.9801 - rbf_fourier_loss: -0.0951 - val_loss: 0.4482 - val_out_loss: 0.9902 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4477 - out_loss: 0.9901 - rbf_fourier_loss: -0.0947 - val_loss: 0.4496 - val_out_loss: 0.9929 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4448 - out_loss: 0.9864 - rbf_fourier_loss: -0.0969 - val_loss: 0.4480 - val_out_loss: 0.9898 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4349 - out_loss: 0.9667 - rbf_fourier_loss: -0.0968 - val_loss: 0.4450 - val_out_loss: 0.9838 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4397 - out_loss: 0.9750 - rbf_fourier_loss: -0.0956 - val_loss: 0.4442 - val_out_loss: 0.9823 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4378 - out_loss: 0.9724 - rbf_fourier_loss: -0.0968 - val_loss: 0.4433 - val_out_loss: 0.9803 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4367 - out_loss: 0.9666 - rbf_fourier_loss: -0.0932 - val_loss: 0.4419 - val_out_loss: 0.9775 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4341 - out_loss: 0.9638 - rbf_fourier_loss: -0.0955 - val_loss: 0.4393 - val_out_loss: 0.9724 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4279 - out_loss: 0.9521 - rbf_fourier_loss: -0.0963 - val_loss: 0.4390 - val_out_loss: 0.9718 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4314 - out_loss: 0.9562 - rbf_fourier_loss: -0.0934 - val_loss: 0.4370 - val_out_loss: 0.9678 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4216 - out_loss: 0.9412 - rbf_fourier_loss: -0.0979 - val_loss: 0.4332 - val_out_loss: 0.9602 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4231 - out_loss: 0.9420 - rbf_fourier_loss: -0.0959 - val_loss: 0.4310 - val_out_loss: 0.9558 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4214 - out_loss: 0.9384 - rbf_fourier_loss: -0.0955 - val_loss: 0.4273 - val_out_loss: 0.9485 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4252 - out_loss: 0.9458 - rbf_fourier_loss: -0.0953 - val_loss: 0.4225 - val_out_loss: 0.9388 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.4160 - out_loss: 0.9278 - rbf_fourier_loss: -0.0957 - val_loss: 0.4191 - val_out_loss: 0.9320 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.4097 - out_loss: 0.9152 - rbf_fourier_loss: -0.0957 - val_loss: 0.4143 - val_out_loss: 0.9224 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.3993 - out_loss: 0.8958 - rbf_fourier_loss: -0.0971 - val_loss: 0.4053 - val_out_loss: 0.9045 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.3927 - out_loss: 0.8813 - rbf_fourier_loss: -0.0959 - val_loss: 0.3955 - val_out_loss: 0.8847 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: 0.3796 - out_loss: 0.8542 - rbf_fourier_loss: -0.0951 - val_loss: 0.3709 - val_out_loss: 0.8355 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 9ms/step - loss: 0.3472 - out_loss: 0.7910 - rbf_fourier_loss: -0.0966 - val_loss: 0.3176 - val_out_loss: 0.7290 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: 0.2598 - out_loss: 0.6141 - rbf_fourier_loss: -0.0945 - val_loss: -0.2482 - val_out_loss: -0.4027 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.3898 - out_loss: -0.6856 - rbf_fourier_loss: -0.0940 - val_loss: -0.3484 - val_out_loss: -0.6029 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.7209 - out_loss: -1.3466 - rbf_fourier_loss: -0.0952 - val_loss: -1.2028 - val_out_loss: -2.3118 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2375 - out_loss: -2.3796 - rbf_fourier_loss: -0.0954 - val_loss: -1.2308 - val_out_loss: -2.3678 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2332 - out_loss: -2.3721 - rbf_fourier_loss: -0.0944 - val_loss: -1.2337 - val_out_loss: -2.3737 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.2356 - out_loss: -2.3754 - rbf_fourier_loss: -0.0957 - val_loss: -1.2179 - val_out_loss: -2.3420 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1935 - out_loss: -2.2921 - rbf_fourier_loss: -0.0949 - val_loss: -1.2206 - val_out_loss: -2.3473 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1926 - out_loss: -2.2892 - rbf_fourier_loss: -0.0959 - val_loss: -1.2228 - val_out_loss: -2.3519 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1921 - out_loss: -2.2890 - rbf_fourier_loss: -0.0953 - val_loss: -1.2057 - val_out_loss: -2.3177 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1947 - out_loss: -2.2943 - rbf_fourier_loss: -0.0952 - val_loss: -1.2022 - val_out_loss: -2.3107 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1621 - out_loss: -2.2285 - rbf_fourier_loss: -0.0957 - val_loss: -1.1527 - val_out_loss: -2.2116 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1545 - out_loss: -2.2138 - rbf_fourier_loss: -0.0952 - val_loss: -1.1418 - val_out_loss: -2.1898 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1576 - out_loss: -2.2197 - rbf_fourier_loss: -0.0954 - val_loss: -1.0902 - val_out_loss: -2.0867 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1173 - out_loss: -2.1383 - rbf_fourier_loss: -0.0963 - val_loss: -1.1469 - val_out_loss: -2.2000 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1369 - out_loss: -2.1774 - rbf_fourier_loss: -0.0963 - val_loss: -1.1474 - val_out_loss: -2.2010 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.1152 - out_loss: -2.1345 - rbf_fourier_loss: -0.0958 - val_loss: -1.1242 - val_out_loss: -2.1546 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0793 - out_loss: -2.0637 - rbf_fourier_loss: -0.0950 - val_loss: -1.1285 - val_out_loss: -2.1632 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0972 - out_loss: -2.0987 - rbf_fourier_loss: -0.0957 - val_loss: -1.0721 - val_out_loss: -2.0504 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1031 - out_loss: -2.1113 - rbf_fourier_loss: -0.0949 - val_loss: -1.0769 - val_out_loss: -2.0600 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0745 - out_loss: -2.0540 - rbf_fourier_loss: -0.0950 - val_loss: -1.0508 - val_out_loss: -2.0078 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.1034 - out_loss: -2.1121 - rbf_fourier_loss: -0.0947 - val_loss: -1.0664 - val_out_loss: -2.0390 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0484 - out_loss: -2.0022 - rbf_fourier_loss: -0.0945 - val_loss: -1.0560 - val_out_loss: -2.0181 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0375 - out_loss: -1.9804 - rbf_fourier_loss: -0.0947 - val_loss: -1.0473 - val_out_loss: -2.0008 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0582 - out_loss: -2.0203 - rbf_fourier_loss: -0.0961 - val_loss: -1.0365 - val_out_loss: -1.9792 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9979 - out_loss: -1.8986 - rbf_fourier_loss: -0.0972 - val_loss: -1.0679 - val_out_loss: -2.0421 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0180 - out_loss: -1.9428 - rbf_fourier_loss: -0.0932 - val_loss: -1.0226 - val_out_loss: -1.9514 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0190 - out_loss: -1.9417 - rbf_fourier_loss: -0.0963 - val_loss: -0.9811 - val_out_loss: -1.8684 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -1.0338 - out_loss: -1.9725 - rbf_fourier_loss: -0.0952 - val_loss: -1.0271 - val_out_loss: -1.9603 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0279 - out_loss: -1.9600 - rbf_fourier_loss: -0.0958 - val_loss: -1.0234 - val_out_loss: -1.9531 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0099 - out_loss: -1.9250 - rbf_fourier_loss: -0.0948 - val_loss: -1.0105 - val_out_loss: -1.9273 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 8ms/step - loss: -0.9987 - out_loss: -1.9022 - rbf_fourier_loss: -0.0951 - val_loss: -1.0261 - val_out_loss: -1.9585 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -0.9947 - out_loss: -1.8950 - rbf_fourier_loss: -0.0943 - val_loss: -0.9919 - val_out_loss: -1.8901 - val_rbf_fourier_loss: -0.0938\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 7ms/step - loss: -1.0192 - out_loss: -1.9426 - rbf_fourier_loss: -0.0958 - val_loss: -0.9397 - val_out_loss: -1.7856 - val_rbf_fourier_loss: -0.0938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEWO8Ebj1z1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2122385f-6f2f-40b9-972f-93c6e6089dcc"
      },
      "source": [
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'__results'\n",
        "shutil.make_archive(namefile, 'zip', '/content/CKAPRI')\n",
        "files.download(namefile+'.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cc2edcef-2def-4db1-b451-a58e0ae1319d\", \"2020_08_18_04_38_18__results.zip\", 125216)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEC4JenHeBKc",
        "colab_type": "text"
      },
      "source": [
        "**Prueba 2 (Funcion fcosto1 y fcosto2 supervisado con sparse categorical crossentropy)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV86jQK5eBT0",
        "colab_type": "text"
      },
      "source": [
        "**happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0v_AYHoebyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=3\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QldZdbHReb9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/happyp2' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_happy))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(happy.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_sce(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(happy, [labels_happyo,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(happy)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_happyo)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_happyo,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_happyo,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_happyo,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_happyo,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FJKYe6tfHn0",
        "colab_type": "text"
      },
      "source": [
        "**Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8efofiZfHxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=2\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMCSgKrXfH5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/moonsp2' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_moonso))\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(moons.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_sce(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(moons, [labels_moonso,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(moons)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_moonso)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_moonso,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_moonso,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_moonso,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_moonso,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOfvzxUYfYXC",
        "colab_type": "text"
      },
      "source": [
        "**mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_m8F5kOfYgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=10\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oZB9Fq4fYuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/mnistp2' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(ytrain))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_sce(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(Xtrain, [ytraino,Xtrain], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0.3)\n",
        "      [y_pred,_] = model.predict(Xtrain)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,ytraino)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(ytraino,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(ytraino,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(ytraino,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(ytraino,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGX_lozB1_30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'__results'\n",
        "shutil.make_archive(namefile, 'zip', '/content/CKAPRI')\n",
        "files.download(namefile+'.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsovPqttf9O9",
        "colab_type": "text"
      },
      "source": [
        "**Funcion fcosto1 y fcosto2 supervisado con mean square error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVZ9B7Mcf9Yv",
        "colab_type": "text"
      },
      "source": [
        "**Happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGebaEwgMz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=3\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g5KpccwgM8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e66eb0d0-6c90-44c9-e6fd-68e77fd434b5"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/happyp3' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_happy))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(happy.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_mse(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(happy)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_happyo)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_happyo,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_happyo,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_happyo,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_happyo,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 224ms/step - loss: 1.5966 - out_loss: 0.3331 - rbf_fourier_loss: 2.8601\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5260 - out_loss: 0.2586 - rbf_fourier_loss: 2.7935\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5195 - out_loss: 0.2265 - rbf_fourier_loss: 2.8124\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5027 - out_loss: 0.1890 - rbf_fourier_loss: 2.8164\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4974 - out_loss: 0.1811 - rbf_fourier_loss: 2.8137\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5033 - out_loss: 0.1882 - rbf_fourier_loss: 2.8184\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4893 - out_loss: 0.1867 - rbf_fourier_loss: 2.7919\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4912 - out_loss: 0.1847 - rbf_fourier_loss: 2.7978\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5072 - out_loss: 0.1865 - rbf_fourier_loss: 2.8279\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4946 - out_loss: 0.1879 - rbf_fourier_loss: 2.8013\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4601 - out_loss: 0.1274 - rbf_fourier_loss: 2.7927\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4287 - out_loss: 0.0816 - rbf_fourier_loss: 2.7757\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4278 - out_loss: 0.0361 - rbf_fourier_loss: 2.8196\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3986 - out_loss: 0.0013 - rbf_fourier_loss: 2.7958\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4057 - out_loss: 3.7897e-04 - rbf_fourier_loss: 2.8109\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4026 - out_loss: 1.7808e-04 - rbf_fourier_loss: 2.8051\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3957 - out_loss: 1.4345e-04 - rbf_fourier_loss: 2.7912\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4000 - out_loss: 1.1014e-04 - rbf_fourier_loss: 2.7999\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3960 - out_loss: 6.5680e-05 - rbf_fourier_loss: 2.7919\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4108 - out_loss: 4.0213e-05 - rbf_fourier_loss: 2.8216\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4082 - out_loss: 3.1729e-05 - rbf_fourier_loss: 2.8163\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4162 - out_loss: 2.1669e-05 - rbf_fourier_loss: 2.8323\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3979 - out_loss: 1.6270e-05 - rbf_fourier_loss: 2.7957\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4046 - out_loss: 8.9571e-06 - rbf_fourier_loss: 2.8093\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3973 - out_loss: 9.4609e-06 - rbf_fourier_loss: 2.7946\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3984 - out_loss: 5.8147e-06 - rbf_fourier_loss: 2.7967\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4041 - out_loss: 4.9237e-06 - rbf_fourier_loss: 2.8081\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4006 - out_loss: 3.8325e-06 - rbf_fourier_loss: 2.8012\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3983 - out_loss: 3.0742e-06 - rbf_fourier_loss: 2.7965\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3927 - out_loss: 2.7195e-06 - rbf_fourier_loss: 2.7854\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3818 - out_loss: 2.4291e-06 - rbf_fourier_loss: 2.7636\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3965 - out_loss: 1.8551e-06 - rbf_fourier_loss: 2.7931\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4116 - out_loss: 1.2382e-06 - rbf_fourier_loss: 2.8232\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4085 - out_loss: 1.1617e-06 - rbf_fourier_loss: 2.8169\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3995 - out_loss: 8.9101e-07 - rbf_fourier_loss: 2.7989\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3952 - out_loss: 8.1949e-07 - rbf_fourier_loss: 2.7904\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4031 - out_loss: 5.4948e-07 - rbf_fourier_loss: 2.8062\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4153 - out_loss: 4.2036e-07 - rbf_fourier_loss: 2.8307\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4040 - out_loss: 3.0690e-07 - rbf_fourier_loss: 2.8080\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4091 - out_loss: 2.2813e-07 - rbf_fourier_loss: 2.8182\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4149 - out_loss: 2.2037e-07 - rbf_fourier_loss: 2.8297\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4174 - out_loss: 1.2674e-07 - rbf_fourier_loss: 2.8349\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4019 - out_loss: 1.1590e-07 - rbf_fourier_loss: 2.8039\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3974 - out_loss: 7.3931e-08 - rbf_fourier_loss: 2.7948\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4162 - out_loss: 7.2123e-08 - rbf_fourier_loss: 2.8325\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3901 - out_loss: 5.9932e-08 - rbf_fourier_loss: 2.7801\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4052 - out_loss: 4.6092e-08 - rbf_fourier_loss: 2.8103\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4117 - out_loss: 2.5737e-08 - rbf_fourier_loss: 2.8234\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4197 - out_loss: 2.6831e-08 - rbf_fourier_loss: 2.8394\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4036 - out_loss: 1.9301e-08 - rbf_fourier_loss: 2.8072\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4173 - out_loss: 2.1160e-08 - rbf_fourier_loss: 2.8345\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4225 - out_loss: 1.7074e-08 - rbf_fourier_loss: 2.8450\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4005 - out_loss: 1.5336e-08 - rbf_fourier_loss: 2.8010\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4155 - out_loss: 1.2533e-08 - rbf_fourier_loss: 2.8310\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4012 - out_loss: 1.1144e-08 - rbf_fourier_loss: 2.8024\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4138 - out_loss: 1.0219e-08 - rbf_fourier_loss: 2.8275\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3960 - out_loss: 7.6670e-09 - rbf_fourier_loss: 2.7920\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4011 - out_loss: 7.3589e-09 - rbf_fourier_loss: 2.8022\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3894 - out_loss: 4.9961e-09 - rbf_fourier_loss: 2.7788\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3983 - out_loss: 6.0088e-09 - rbf_fourier_loss: 2.7965\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4162 - out_loss: 5.5469e-09 - rbf_fourier_loss: 2.8324\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4133 - out_loss: 5.8759e-09 - rbf_fourier_loss: 2.8266\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4074 - out_loss: 4.2513e-09 - rbf_fourier_loss: 2.8148\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3999 - out_loss: 3.9598e-09 - rbf_fourier_loss: 2.7998\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4141 - out_loss: 3.8513e-09 - rbf_fourier_loss: 2.8282\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3988 - out_loss: 3.7522e-09 - rbf_fourier_loss: 2.7977\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4146 - out_loss: 2.5694e-09 - rbf_fourier_loss: 2.8293\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3930 - out_loss: 3.2018e-09 - rbf_fourier_loss: 2.7861\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4049 - out_loss: 2.8857e-09 - rbf_fourier_loss: 2.8097\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4134 - out_loss: 2.3869e-09 - rbf_fourier_loss: 2.8268\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4220 - out_loss: 2.7408e-09 - rbf_fourier_loss: 2.8441\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4019 - out_loss: 2.5458e-09 - rbf_fourier_loss: 2.8038\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3853 - out_loss: 2.5697e-09 - rbf_fourier_loss: 2.7707\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4167 - out_loss: 2.4512e-09 - rbf_fourier_loss: 2.8334\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3977 - out_loss: 2.2805e-09 - rbf_fourier_loss: 2.7953\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3950 - out_loss: 2.1205e-09 - rbf_fourier_loss: 2.7899\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4130 - out_loss: 2.4289e-09 - rbf_fourier_loss: 2.8260\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4103 - out_loss: 2.6623e-09 - rbf_fourier_loss: 2.8205\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3986 - out_loss: 1.8726e-09 - rbf_fourier_loss: 2.7973\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4217 - out_loss: 1.7258e-09 - rbf_fourier_loss: 2.8434\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4004 - out_loss: 1.7084e-09 - rbf_fourier_loss: 2.8007\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4068 - out_loss: 1.9915e-09 - rbf_fourier_loss: 2.8135\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4037 - out_loss: 1.9565e-09 - rbf_fourier_loss: 2.8073\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3942 - out_loss: 1.5944e-09 - rbf_fourier_loss: 2.7884\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4070 - out_loss: 1.9530e-09 - rbf_fourier_loss: 2.8141\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3978 - out_loss: 1.6269e-09 - rbf_fourier_loss: 2.7956\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3902 - out_loss: 1.4426e-09 - rbf_fourier_loss: 2.7804\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4175 - out_loss: 1.4853e-09 - rbf_fourier_loss: 2.8349\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4129 - out_loss: 1.2643e-09 - rbf_fourier_loss: 2.8257\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4066 - out_loss: 1.7609e-09 - rbf_fourier_loss: 2.8132\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3925 - out_loss: 1.3565e-09 - rbf_fourier_loss: 2.7850\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3844 - out_loss: 1.2083e-09 - rbf_fourier_loss: 2.7689\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4013 - out_loss: 1.4732e-09 - rbf_fourier_loss: 2.8026\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4087 - out_loss: 1.4283e-09 - rbf_fourier_loss: 2.8174\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4172 - out_loss: 1.1568e-09 - rbf_fourier_loss: 2.8343\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3927 - out_loss: 1.1335e-09 - rbf_fourier_loss: 2.7853\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4049 - out_loss: 1.1167e-09 - rbf_fourier_loss: 2.8098\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4223 - out_loss: 1.2876e-09 - rbf_fourier_loss: 2.8447\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3996 - out_loss: 1.2112e-09 - rbf_fourier_loss: 2.7991\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4093 - out_loss: 1.1089e-09 - rbf_fourier_loss: 2.8187\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 211ms/step - loss: 1.4990 - out_loss: 0.4012 - rbf_fourier_loss: 2.5967\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4663 - out_loss: 0.3098 - rbf_fourier_loss: 2.6227\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3657 - out_loss: 0.1238 - rbf_fourier_loss: 2.6077\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3643 - out_loss: 0.1153 - rbf_fourier_loss: 2.6132\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3772 - out_loss: 0.1206 - rbf_fourier_loss: 2.6337\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3598 - out_loss: 0.1144 - rbf_fourier_loss: 2.6052\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3498 - out_loss: 0.1041 - rbf_fourier_loss: 2.5955\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3466 - out_loss: 0.0810 - rbf_fourier_loss: 2.6123\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3133 - out_loss: 0.0345 - rbf_fourier_loss: 2.5922\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2951 - out_loss: 0.0013 - rbf_fourier_loss: 2.5890\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3054 - out_loss: 4.2452e-04 - rbf_fourier_loss: 2.6104\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2980 - out_loss: 5.7609e-04 - rbf_fourier_loss: 2.5953\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3139 - out_loss: 4.7047e-04 - rbf_fourier_loss: 2.6273\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3228 - out_loss: 2.9871e-04 - rbf_fourier_loss: 2.6453\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3039 - out_loss: 1.8630e-04 - rbf_fourier_loss: 2.6075\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3059 - out_loss: 1.2004e-04 - rbf_fourier_loss: 2.6117\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2999 - out_loss: 7.3504e-05 - rbf_fourier_loss: 2.5997\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3024 - out_loss: 9.7286e-05 - rbf_fourier_loss: 2.6047\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3085 - out_loss: 1.0427e-04 - rbf_fourier_loss: 2.6170\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3082 - out_loss: 6.0185e-05 - rbf_fourier_loss: 2.6163\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3168 - out_loss: 2.4559e-05 - rbf_fourier_loss: 2.6335\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3005 - out_loss: 3.1041e-05 - rbf_fourier_loss: 2.6009\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3078 - out_loss: 3.1837e-05 - rbf_fourier_loss: 2.6155\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3222 - out_loss: 2.0332e-05 - rbf_fourier_loss: 2.6444\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2935 - out_loss: 1.5521e-05 - rbf_fourier_loss: 2.5870\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2951 - out_loss: 1.1961e-05 - rbf_fourier_loss: 2.5902\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2940 - out_loss: 8.5790e-06 - rbf_fourier_loss: 2.5881\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3022 - out_loss: 1.0168e-04 - rbf_fourier_loss: 2.6043\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3098 - out_loss: 3.8888e-06 - rbf_fourier_loss: 2.6195\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3092 - out_loss: 2.9548e-06 - rbf_fourier_loss: 2.6184\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3130 - out_loss: 3.4732e-06 - rbf_fourier_loss: 2.6259\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3134 - out_loss: 3.1595e-06 - rbf_fourier_loss: 2.6268\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3143 - out_loss: 3.5361e-06 - rbf_fourier_loss: 2.6287\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3075 - out_loss: 2.1380e-06 - rbf_fourier_loss: 2.6149\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3066 - out_loss: 1.7733e-06 - rbf_fourier_loss: 2.6131\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3059 - out_loss: 2.2613e-06 - rbf_fourier_loss: 2.6119\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2991 - out_loss: 1.2219e-06 - rbf_fourier_loss: 2.5982\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3213 - out_loss: 1.2485e-06 - rbf_fourier_loss: 2.6427\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3097 - out_loss: 1.0022e-06 - rbf_fourier_loss: 2.6193\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3091 - out_loss: 9.1994e-07 - rbf_fourier_loss: 2.6181\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3103 - out_loss: 6.0882e-07 - rbf_fourier_loss: 2.6206\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3097 - out_loss: 6.3378e-07 - rbf_fourier_loss: 2.6193\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3056 - out_loss: 3.4580e-05 - rbf_fourier_loss: 2.6111\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3005 - out_loss: 9.7902e-07 - rbf_fourier_loss: 2.6010\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2990 - out_loss: 5.9433e-07 - rbf_fourier_loss: 2.5980\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3108 - out_loss: 3.4370e-07 - rbf_fourier_loss: 2.6217\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3123 - out_loss: 3.4669e-07 - rbf_fourier_loss: 2.6247\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3025 - out_loss: 2.0820e-07 - rbf_fourier_loss: 2.6049\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3000 - out_loss: 1.9732e-07 - rbf_fourier_loss: 2.5999\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3223 - out_loss: 1.5717e-07 - rbf_fourier_loss: 2.6446\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2783 - out_loss: 1.5135e-07 - rbf_fourier_loss: 2.5567\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3039 - out_loss: 1.1527e-07 - rbf_fourier_loss: 2.6078\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3033 - out_loss: 2.2185e-07 - rbf_fourier_loss: 2.6067\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2829 - out_loss: 1.0655e-07 - rbf_fourier_loss: 2.5659\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2994 - out_loss: 9.0051e-08 - rbf_fourier_loss: 2.5988\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3229 - out_loss: 2.5987e-07 - rbf_fourier_loss: 2.6459\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3068 - out_loss: 9.3380e-08 - rbf_fourier_loss: 2.6136\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3202 - out_loss: 7.5590e-08 - rbf_fourier_loss: 2.6404\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3177 - out_loss: 7.9597e-08 - rbf_fourier_loss: 2.6354\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2949 - out_loss: 7.6145e-08 - rbf_fourier_loss: 2.5898\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3155 - out_loss: 5.1682e-08 - rbf_fourier_loss: 2.6310\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3201 - out_loss: 5.3114e-08 - rbf_fourier_loss: 2.6402\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2985 - out_loss: 4.1285e-08 - rbf_fourier_loss: 2.5971\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3154 - out_loss: 2.2991e-07 - rbf_fourier_loss: 2.6308\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3100 - out_loss: 3.2712e-08 - rbf_fourier_loss: 2.6200\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3054 - out_loss: 3.3331e-08 - rbf_fourier_loss: 2.6109\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3032 - out_loss: 3.1371e-08 - rbf_fourier_loss: 2.6064\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2987 - out_loss: 2.2354e-08 - rbf_fourier_loss: 2.5974\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3086 - out_loss: 3.0286e-08 - rbf_fourier_loss: 2.6171\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3088 - out_loss: 2.3184e-08 - rbf_fourier_loss: 2.6176\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3224 - out_loss: 2.2131e-08 - rbf_fourier_loss: 2.6449\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3133 - out_loss: 1.5607e-08 - rbf_fourier_loss: 2.6267\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2865 - out_loss: 2.4449e-08 - rbf_fourier_loss: 2.5730\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3005 - out_loss: 1.6074e-08 - rbf_fourier_loss: 2.6009\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2855 - out_loss: 1.8778e-08 - rbf_fourier_loss: 2.5710\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2964 - out_loss: 1.4809e-08 - rbf_fourier_loss: 2.5927\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3146 - out_loss: 1.3336e-08 - rbf_fourier_loss: 2.6293\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3056 - out_loss: 1.0622e-08 - rbf_fourier_loss: 2.6111\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3042 - out_loss: 2.1867e-08 - rbf_fourier_loss: 2.6084\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2966 - out_loss: 1.5765e-08 - rbf_fourier_loss: 2.5932\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3041 - out_loss: 9.4361e-09 - rbf_fourier_loss: 2.6082\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3111 - out_loss: 1.0112e-08 - rbf_fourier_loss: 2.6221\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3071 - out_loss: 1.2389e-08 - rbf_fourier_loss: 2.6141\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2932 - out_loss: 9.2854e-09 - rbf_fourier_loss: 2.5865\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3183 - out_loss: 1.1413e-08 - rbf_fourier_loss: 2.6367\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3197 - out_loss: 1.0558e-08 - rbf_fourier_loss: 2.6393\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3002 - out_loss: 8.7061e-09 - rbf_fourier_loss: 2.6003\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3149 - out_loss: 8.2262e-09 - rbf_fourier_loss: 2.6298\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3016 - out_loss: 8.4714e-09 - rbf_fourier_loss: 2.6032\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3044 - out_loss: 7.6381e-09 - rbf_fourier_loss: 2.6087\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3139 - out_loss: 1.0466e-08 - rbf_fourier_loss: 2.6278\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2869 - out_loss: 8.3900e-09 - rbf_fourier_loss: 2.5738\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3055 - out_loss: 8.6421e-09 - rbf_fourier_loss: 2.6110\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2997 - out_loss: 7.0222e-09 - rbf_fourier_loss: 2.5994\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3019 - out_loss: 8.3344e-09 - rbf_fourier_loss: 2.6037\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2855 - out_loss: 9.6284e-09 - rbf_fourier_loss: 2.5709\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3069 - out_loss: 7.3327e-09 - rbf_fourier_loss: 2.6139\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3134 - out_loss: 7.3784e-09 - rbf_fourier_loss: 2.6268\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2943 - out_loss: 5.6335e-09 - rbf_fourier_loss: 2.5885\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2817 - out_loss: 7.2794e-09 - rbf_fourier_loss: 2.5634\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 214ms/step - loss: 1.5013 - out_loss: 0.2354 - rbf_fourier_loss: 2.7673\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4744 - out_loss: 0.1615 - rbf_fourier_loss: 2.7873\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4539 - out_loss: 0.1445 - rbf_fourier_loss: 2.7634\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4621 - out_loss: 0.1332 - rbf_fourier_loss: 2.7910\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4624 - out_loss: 0.1527 - rbf_fourier_loss: 2.7721\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4709 - out_loss: 0.1539 - rbf_fourier_loss: 2.7880\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4573 - out_loss: 0.1396 - rbf_fourier_loss: 2.7750\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4483 - out_loss: 0.1436 - rbf_fourier_loss: 2.7529\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4789 - out_loss: 0.1459 - rbf_fourier_loss: 2.8119\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4640 - out_loss: 0.1443 - rbf_fourier_loss: 2.7837\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4672 - out_loss: 0.1201 - rbf_fourier_loss: 2.8143\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4055 - out_loss: 0.0240 - rbf_fourier_loss: 2.7870\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4068 - out_loss: 0.0190 - rbf_fourier_loss: 2.7946\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4068 - out_loss: 0.0128 - rbf_fourier_loss: 2.8007\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4024 - out_loss: 0.0157 - rbf_fourier_loss: 2.7892\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4068 - out_loss: 0.0134 - rbf_fourier_loss: 2.8002\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4048 - out_loss: 0.0086 - rbf_fourier_loss: 2.8010\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3882 - out_loss: 0.0120 - rbf_fourier_loss: 2.7645\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4187 - out_loss: 0.0044 - rbf_fourier_loss: 2.8329\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4047 - out_loss: 0.0155 - rbf_fourier_loss: 2.7938\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3788 - out_loss: 0.0035 - rbf_fourier_loss: 2.7542\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4070 - out_loss: 0.0033 - rbf_fourier_loss: 2.8107\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4014 - out_loss: 0.0019 - rbf_fourier_loss: 2.8009\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3931 - out_loss: 0.0016 - rbf_fourier_loss: 2.7846\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3991 - out_loss: 0.0020 - rbf_fourier_loss: 2.7961\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3953 - out_loss: 0.0056 - rbf_fourier_loss: 2.7851\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3878 - out_loss: 0.0012 - rbf_fourier_loss: 2.7744\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4052 - out_loss: 0.0012 - rbf_fourier_loss: 2.8092\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3972 - out_loss: 8.5576e-04 - rbf_fourier_loss: 2.7935\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3937 - out_loss: 8.4307e-04 - rbf_fourier_loss: 2.7867\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4051 - out_loss: 6.1785e-04 - rbf_fourier_loss: 2.8097\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3903 - out_loss: 6.5026e-04 - rbf_fourier_loss: 2.7799\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3942 - out_loss: 0.0053 - rbf_fourier_loss: 2.7831\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3947 - out_loss: 5.5461e-04 - rbf_fourier_loss: 2.7889\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4076 - out_loss: 5.3527e-04 - rbf_fourier_loss: 2.8147\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3974 - out_loss: 6.0652e-04 - rbf_fourier_loss: 2.7941\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3898 - out_loss: 3.5437e-04 - rbf_fourier_loss: 2.7792\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3979 - out_loss: 0.0049 - rbf_fourier_loss: 2.7908\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4065 - out_loss: 4.6819e-04 - rbf_fourier_loss: 2.8126\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3857 - out_loss: 2.2750e-04 - rbf_fourier_loss: 2.7712\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4153 - out_loss: 2.4835e-04 - rbf_fourier_loss: 2.8304\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4101 - out_loss: 1.8266e-04 - rbf_fourier_loss: 2.8201\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3750 - out_loss: 1.5889e-04 - rbf_fourier_loss: 2.7499\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4098 - out_loss: 2.1497e-04 - rbf_fourier_loss: 2.8194\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3963 - out_loss: 1.3971e-04 - rbf_fourier_loss: 2.7925\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3947 - out_loss: 4.2551e-04 - rbf_fourier_loss: 2.7889\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3992 - out_loss: 2.8309e-04 - rbf_fourier_loss: 2.7982\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3920 - out_loss: 1.0177e-04 - rbf_fourier_loss: 2.7838\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3645 - out_loss: 3.5672e-04 - rbf_fourier_loss: 2.7286\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3882 - out_loss: 7.9266e-05 - rbf_fourier_loss: 2.7764\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3935 - out_loss: 1.4318e-04 - rbf_fourier_loss: 2.7869\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3963 - out_loss: 5.7034e-05 - rbf_fourier_loss: 2.7926\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4012 - out_loss: 9.7152e-05 - rbf_fourier_loss: 2.8023\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3913 - out_loss: 7.9143e-05 - rbf_fourier_loss: 2.7825\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4010 - out_loss: 1.1523e-04 - rbf_fourier_loss: 2.8019\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3891 - out_loss: 4.4710e-05 - rbf_fourier_loss: 2.7781\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3846 - out_loss: 3.1466e-05 - rbf_fourier_loss: 2.7691\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4100 - out_loss: 5.3025e-04 - rbf_fourier_loss: 2.8195\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3861 - out_loss: 2.9588e-05 - rbf_fourier_loss: 2.7722\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3987 - out_loss: 2.4319e-05 - rbf_fourier_loss: 2.7974\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3871 - out_loss: 2.0082e-05 - rbf_fourier_loss: 2.7742\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3907 - out_loss: 2.3793e-05 - rbf_fourier_loss: 2.7813\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3991 - out_loss: 1.9605e-05 - rbf_fourier_loss: 2.7981\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3862 - out_loss: 2.1508e-05 - rbf_fourier_loss: 2.7723\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3925 - out_loss: 1.6416e-05 - rbf_fourier_loss: 2.7849\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4070 - out_loss: 2.0200e-05 - rbf_fourier_loss: 2.8140\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3816 - out_loss: 1.4432e-05 - rbf_fourier_loss: 2.7631\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3884 - out_loss: 1.1590e-04 - rbf_fourier_loss: 2.7767\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3944 - out_loss: 0.0012 - rbf_fourier_loss: 2.7876\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3835 - out_loss: 1.8132e-05 - rbf_fourier_loss: 2.7669\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3955 - out_loss: 9.6110e-06 - rbf_fourier_loss: 2.7909\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3991 - out_loss: 7.1429e-06 - rbf_fourier_loss: 2.7982\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3923 - out_loss: 7.6860e-06 - rbf_fourier_loss: 2.7847\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3994 - out_loss: 7.5402e-06 - rbf_fourier_loss: 2.7989\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3968 - out_loss: 5.9330e-06 - rbf_fourier_loss: 2.7937\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3943 - out_loss: 8.3581e-06 - rbf_fourier_loss: 2.7886\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3987 - out_loss: 6.0577e-06 - rbf_fourier_loss: 2.7974\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4076 - out_loss: 6.4246e-06 - rbf_fourier_loss: 2.8152\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3860 - out_loss: 5.8297e-06 - rbf_fourier_loss: 2.7719\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3969 - out_loss: 6.7042e-06 - rbf_fourier_loss: 2.7938\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3935 - out_loss: 6.5650e-06 - rbf_fourier_loss: 2.7870\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4062 - out_loss: 7.9950e-06 - rbf_fourier_loss: 2.8123\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4014 - out_loss: 5.9865e-05 - rbf_fourier_loss: 2.8027\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3811 - out_loss: 3.6171e-05 - rbf_fourier_loss: 2.7621\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3793 - out_loss: 4.0475e-06 - rbf_fourier_loss: 2.7586\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3879 - out_loss: 3.6342e-06 - rbf_fourier_loss: 2.7758\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3979 - out_loss: 3.2232e-06 - rbf_fourier_loss: 2.7957\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3886 - out_loss: 7.7242e-05 - rbf_fourier_loss: 2.7772\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4043 - out_loss: 1.7101e-06 - rbf_fourier_loss: 2.8085\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3828 - out_loss: 3.5624e-06 - rbf_fourier_loss: 2.7656\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3934 - out_loss: 2.1575e-06 - rbf_fourier_loss: 2.7868\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3984 - out_loss: 2.3940e-06 - rbf_fourier_loss: 2.7968\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3940 - out_loss: 2.0572e-06 - rbf_fourier_loss: 2.7880\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4033 - out_loss: 2.1493e-06 - rbf_fourier_loss: 2.8066\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3952 - out_loss: 3.9957e-06 - rbf_fourier_loss: 2.7904\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3971 - out_loss: 1.5427e-06 - rbf_fourier_loss: 2.7942\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4189 - out_loss: 3.6874e-06 - rbf_fourier_loss: 2.8378\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4085 - out_loss: 2.9881e-06 - rbf_fourier_loss: 2.8170\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4035 - out_loss: 1.7457e-06 - rbf_fourier_loss: 2.8071\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3995 - out_loss: 1.2646e-06 - rbf_fourier_loss: 2.7989\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 217ms/step - loss: 2.4938 - out_loss: 0.3285 - rbf_fourier_loss: 4.6590\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4575 - out_loss: 0.2588 - rbf_fourier_loss: 4.6562\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4887 - out_loss: 0.2783 - rbf_fourier_loss: 4.6992\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4776 - out_loss: 0.2342 - rbf_fourier_loss: 4.7210\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4397 - out_loss: 0.2129 - rbf_fourier_loss: 4.6665\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4409 - out_loss: 0.1962 - rbf_fourier_loss: 4.6856\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4344 - out_loss: 0.2111 - rbf_fourier_loss: 4.6577\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4446 - out_loss: 0.1772 - rbf_fourier_loss: 4.7121\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4205 - out_loss: 0.1606 - rbf_fourier_loss: 4.6804\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4214 - out_loss: 0.2030 - rbf_fourier_loss: 4.6398\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4265 - out_loss: 0.1531 - rbf_fourier_loss: 4.7000\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4315 - out_loss: 0.1675 - rbf_fourier_loss: 4.6955\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4155 - out_loss: 0.1828 - rbf_fourier_loss: 4.6482\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4195 - out_loss: 0.1441 - rbf_fourier_loss: 4.6949\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3958 - out_loss: 0.1265 - rbf_fourier_loss: 4.6651\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4905 - out_loss: 0.2294 - rbf_fourier_loss: 4.7516\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3904 - out_loss: 0.1271 - rbf_fourier_loss: 4.6538\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4144 - out_loss: 0.2097 - rbf_fourier_loss: 4.6191\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3967 - out_loss: 0.1397 - rbf_fourier_loss: 4.6537\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4005 - out_loss: 0.1305 - rbf_fourier_loss: 4.6704\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3949 - out_loss: 0.1303 - rbf_fourier_loss: 4.6596\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3987 - out_loss: 0.1149 - rbf_fourier_loss: 4.6826\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4192 - out_loss: 0.1571 - rbf_fourier_loss: 4.6813\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3675 - out_loss: 0.1234 - rbf_fourier_loss: 4.6116\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4001 - out_loss: 0.1301 - rbf_fourier_loss: 4.6700\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4159 - out_loss: 0.1382 - rbf_fourier_loss: 4.6937\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4135 - out_loss: 0.1173 - rbf_fourier_loss: 4.7097\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3819 - out_loss: 0.1145 - rbf_fourier_loss: 4.6493\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3938 - out_loss: 0.0987 - rbf_fourier_loss: 4.6888\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3929 - out_loss: 0.1294 - rbf_fourier_loss: 4.6564\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4019 - out_loss: 0.1110 - rbf_fourier_loss: 4.6928\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3978 - out_loss: 0.1186 - rbf_fourier_loss: 4.6770\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3945 - out_loss: 0.1199 - rbf_fourier_loss: 4.6690\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3954 - out_loss: 0.1229 - rbf_fourier_loss: 4.6679\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3821 - out_loss: 0.1002 - rbf_fourier_loss: 4.6641\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3634 - out_loss: 0.1166 - rbf_fourier_loss: 4.6103\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3994 - out_loss: 0.1215 - rbf_fourier_loss: 4.6773\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4070 - out_loss: 0.1083 - rbf_fourier_loss: 4.7058\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3847 - out_loss: 0.1119 - rbf_fourier_loss: 4.6574\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4063 - out_loss: 0.1154 - rbf_fourier_loss: 4.6971\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3779 - out_loss: 0.1039 - rbf_fourier_loss: 4.6519\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3995 - out_loss: 0.1270 - rbf_fourier_loss: 4.6721\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4185 - out_loss: 0.1296 - rbf_fourier_loss: 4.7075\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3872 - out_loss: 0.1006 - rbf_fourier_loss: 4.6738\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3644 - out_loss: 0.0924 - rbf_fourier_loss: 4.6364\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3885 - out_loss: 0.1517 - rbf_fourier_loss: 4.6253\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3618 - out_loss: 0.1180 - rbf_fourier_loss: 4.6055\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4010 - out_loss: 0.1053 - rbf_fourier_loss: 4.6966\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3912 - out_loss: 0.1124 - rbf_fourier_loss: 4.6700\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3809 - out_loss: 0.1155 - rbf_fourier_loss: 4.6463\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3805 - out_loss: 0.0955 - rbf_fourier_loss: 4.6656\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3557 - out_loss: 0.1138 - rbf_fourier_loss: 4.5976\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3802 - out_loss: 0.1110 - rbf_fourier_loss: 4.6494\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3868 - out_loss: 0.1092 - rbf_fourier_loss: 4.6644\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3772 - out_loss: 0.1115 - rbf_fourier_loss: 4.6429\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3631 - out_loss: 0.1090 - rbf_fourier_loss: 4.6172\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3753 - out_loss: 0.0929 - rbf_fourier_loss: 4.6577\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3833 - out_loss: 0.0972 - rbf_fourier_loss: 4.6694\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3909 - out_loss: 0.0951 - rbf_fourier_loss: 4.6868\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3685 - out_loss: 0.1266 - rbf_fourier_loss: 4.6105\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3752 - out_loss: 0.0973 - rbf_fourier_loss: 4.6531\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3743 - out_loss: 0.0913 - rbf_fourier_loss: 4.6573\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3823 - out_loss: 0.1098 - rbf_fourier_loss: 4.6547\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3642 - out_loss: 0.1009 - rbf_fourier_loss: 4.6274\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3698 - out_loss: 0.0868 - rbf_fourier_loss: 4.6527\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3829 - out_loss: 0.1042 - rbf_fourier_loss: 4.6616\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3860 - out_loss: 0.1017 - rbf_fourier_loss: 4.6704\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4082 - out_loss: 0.1239 - rbf_fourier_loss: 4.6925\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3794 - out_loss: 0.0790 - rbf_fourier_loss: 4.6799\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3847 - out_loss: 0.0881 - rbf_fourier_loss: 4.6812\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3841 - out_loss: 0.0813 - rbf_fourier_loss: 4.6869\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3925 - out_loss: 0.1050 - rbf_fourier_loss: 4.6800\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3621 - out_loss: 0.0802 - rbf_fourier_loss: 4.6441\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3856 - out_loss: 0.1322 - rbf_fourier_loss: 4.6391\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3805 - out_loss: 0.0893 - rbf_fourier_loss: 4.6716\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3792 - out_loss: 0.0979 - rbf_fourier_loss: 4.6605\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3834 - out_loss: 0.0879 - rbf_fourier_loss: 4.6789\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3592 - out_loss: 0.1000 - rbf_fourier_loss: 4.6184\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4009 - out_loss: 0.1158 - rbf_fourier_loss: 4.6860\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3780 - out_loss: 0.0802 - rbf_fourier_loss: 4.6758\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3802 - out_loss: 0.0913 - rbf_fourier_loss: 4.6692\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3728 - out_loss: 0.0835 - rbf_fourier_loss: 4.6621\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3942 - out_loss: 0.1264 - rbf_fourier_loss: 4.6620\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3583 - out_loss: 0.0885 - rbf_fourier_loss: 4.6281\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3861 - out_loss: 0.1030 - rbf_fourier_loss: 4.6692\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3892 - out_loss: 0.0846 - rbf_fourier_loss: 4.6937\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3855 - out_loss: 0.0945 - rbf_fourier_loss: 4.6765\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4109 - out_loss: 0.1332 - rbf_fourier_loss: 4.6885\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3674 - out_loss: 0.0818 - rbf_fourier_loss: 4.6530\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3705 - out_loss: 0.0861 - rbf_fourier_loss: 4.6550\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3916 - out_loss: 0.0868 - rbf_fourier_loss: 4.6964\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3687 - out_loss: 0.0943 - rbf_fourier_loss: 4.6432\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3859 - out_loss: 0.0962 - rbf_fourier_loss: 4.6756\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3702 - out_loss: 0.0775 - rbf_fourier_loss: 4.6628\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4166 - out_loss: 0.1087 - rbf_fourier_loss: 4.7245\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3649 - out_loss: 0.0801 - rbf_fourier_loss: 4.6497\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3742 - out_loss: 0.0824 - rbf_fourier_loss: 4.6660\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4116 - out_loss: 0.1269 - rbf_fourier_loss: 4.6963\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3854 - out_loss: 0.0806 - rbf_fourier_loss: 4.6903\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3797 - out_loss: 0.0826 - rbf_fourier_loss: 4.6767\n",
            "it 1/10\n",
            "acc: 69.17293233082707\n",
            "ari: 34.20810360919784\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 217ms/step - loss: 0.7940 - out_loss: 0.5626 - rbf_fourier_loss: 1.0255\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7421 - out_loss: 0.4564 - rbf_fourier_loss: 1.0278\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7213 - out_loss: 0.4246 - rbf_fourier_loss: 1.0180\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6916 - out_loss: 0.3664 - rbf_fourier_loss: 1.0168\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6790 - out_loss: 0.3186 - rbf_fourier_loss: 1.0394\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6597 - out_loss: 0.2961 - rbf_fourier_loss: 1.0233\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6689 - out_loss: 0.3106 - rbf_fourier_loss: 1.0273\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6571 - out_loss: 0.2685 - rbf_fourier_loss: 1.0457\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6613 - out_loss: 0.2880 - rbf_fourier_loss: 1.0347\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6677 - out_loss: 0.2970 - rbf_fourier_loss: 1.0383\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6674 - out_loss: 0.2940 - rbf_fourier_loss: 1.0408\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6612 - out_loss: 0.2995 - rbf_fourier_loss: 1.0230\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6586 - out_loss: 0.2889 - rbf_fourier_loss: 1.0282\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6600 - out_loss: 0.2858 - rbf_fourier_loss: 1.0342\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6654 - out_loss: 0.2862 - rbf_fourier_loss: 1.0447\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6624 - out_loss: 0.2931 - rbf_fourier_loss: 1.0316\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6515 - out_loss: 0.2692 - rbf_fourier_loss: 1.0339\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6568 - out_loss: 0.2947 - rbf_fourier_loss: 1.0190\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6634 - out_loss: 0.2954 - rbf_fourier_loss: 1.0314\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6587 - out_loss: 0.2862 - rbf_fourier_loss: 1.0313\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6469 - out_loss: 0.2924 - rbf_fourier_loss: 1.0014\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6563 - out_loss: 0.2816 - rbf_fourier_loss: 1.0310\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6484 - out_loss: 0.2648 - rbf_fourier_loss: 1.0320\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6457 - out_loss: 0.2725 - rbf_fourier_loss: 1.0190\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6382 - out_loss: 0.2551 - rbf_fourier_loss: 1.0214\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6359 - out_loss: 0.2563 - rbf_fourier_loss: 1.0155\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6443 - out_loss: 0.2580 - rbf_fourier_loss: 1.0306\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6461 - out_loss: 0.2556 - rbf_fourier_loss: 1.0367\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6392 - out_loss: 0.2469 - rbf_fourier_loss: 1.0315\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6420 - out_loss: 0.2615 - rbf_fourier_loss: 1.0226\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6387 - out_loss: 0.2477 - rbf_fourier_loss: 1.0298\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6266 - out_loss: 0.2245 - rbf_fourier_loss: 1.0286\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6250 - out_loss: 0.2157 - rbf_fourier_loss: 1.0344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6244 - out_loss: 0.2277 - rbf_fourier_loss: 1.0211\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6213 - out_loss: 0.2207 - rbf_fourier_loss: 1.0219\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6199 - out_loss: 0.2088 - rbf_fourier_loss: 1.0311\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6136 - out_loss: 0.2010 - rbf_fourier_loss: 1.0262\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6036 - out_loss: 0.1967 - rbf_fourier_loss: 1.0106\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6061 - out_loss: 0.1876 - rbf_fourier_loss: 1.0245\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5996 - out_loss: 0.1724 - rbf_fourier_loss: 1.0268\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5952 - out_loss: 0.1604 - rbf_fourier_loss: 1.0299\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6138 - out_loss: 0.1982 - rbf_fourier_loss: 1.0295\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6015 - out_loss: 0.1704 - rbf_fourier_loss: 1.0327\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5951 - out_loss: 0.1786 - rbf_fourier_loss: 1.0116\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5962 - out_loss: 0.1770 - rbf_fourier_loss: 1.0154\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6121 - out_loss: 0.1895 - rbf_fourier_loss: 1.0348\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6005 - out_loss: 0.1751 - rbf_fourier_loss: 1.0258\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6027 - out_loss: 0.1860 - rbf_fourier_loss: 1.0193\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6005 - out_loss: 0.1724 - rbf_fourier_loss: 1.0286\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6091 - out_loss: 0.1921 - rbf_fourier_loss: 1.0262\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6146 - out_loss: 0.1990 - rbf_fourier_loss: 1.0302\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6019 - out_loss: 0.1835 - rbf_fourier_loss: 1.0204\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6107 - out_loss: 0.1925 - rbf_fourier_loss: 1.0290\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5862 - out_loss: 0.1586 - rbf_fourier_loss: 1.0137\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5980 - out_loss: 0.1708 - rbf_fourier_loss: 1.0253\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6072 - out_loss: 0.1845 - rbf_fourier_loss: 1.0298\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6130 - out_loss: 0.1899 - rbf_fourier_loss: 1.0362\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6046 - out_loss: 0.1808 - rbf_fourier_loss: 1.0284\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6032 - out_loss: 0.1819 - rbf_fourier_loss: 1.0244\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6089 - out_loss: 0.1883 - rbf_fourier_loss: 1.0294\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6121 - out_loss: 0.1824 - rbf_fourier_loss: 1.0418\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6111 - out_loss: 0.1919 - rbf_fourier_loss: 1.0302\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6052 - out_loss: 0.1777 - rbf_fourier_loss: 1.0326\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6178 - out_loss: 0.2049 - rbf_fourier_loss: 1.0306\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5989 - out_loss: 0.1806 - rbf_fourier_loss: 1.0172\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5938 - out_loss: 0.1760 - rbf_fourier_loss: 1.0115\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6108 - out_loss: 0.1902 - rbf_fourier_loss: 1.0314\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5951 - out_loss: 0.1698 - rbf_fourier_loss: 1.0203\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5984 - out_loss: 0.1880 - rbf_fourier_loss: 1.0089\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6029 - out_loss: 0.1828 - rbf_fourier_loss: 1.0231\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6080 - out_loss: 0.1924 - rbf_fourier_loss: 1.0236\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6043 - out_loss: 0.1869 - rbf_fourier_loss: 1.0217\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6088 - out_loss: 0.1947 - rbf_fourier_loss: 1.0228\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6146 - out_loss: 0.1913 - rbf_fourier_loss: 1.0379\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6061 - out_loss: 0.1802 - rbf_fourier_loss: 1.0320\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6056 - out_loss: 0.1882 - rbf_fourier_loss: 1.0231\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5937 - out_loss: 0.1715 - rbf_fourier_loss: 1.0158\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5956 - out_loss: 0.1743 - rbf_fourier_loss: 1.0169\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6034 - out_loss: 0.1750 - rbf_fourier_loss: 1.0318\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5964 - out_loss: 0.1678 - rbf_fourier_loss: 1.0251\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6069 - out_loss: 0.1893 - rbf_fourier_loss: 1.0245\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6037 - out_loss: 0.1819 - rbf_fourier_loss: 1.0255\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6019 - out_loss: 0.1814 - rbf_fourier_loss: 1.0225\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5968 - out_loss: 0.1798 - rbf_fourier_loss: 1.0138\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6006 - out_loss: 0.1734 - rbf_fourier_loss: 1.0279\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5991 - out_loss: 0.1803 - rbf_fourier_loss: 1.0179\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5983 - out_loss: 0.1665 - rbf_fourier_loss: 1.0301\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5979 - out_loss: 0.1774 - rbf_fourier_loss: 1.0183\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6089 - out_loss: 0.1921 - rbf_fourier_loss: 1.0258\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6038 - out_loss: 0.1806 - rbf_fourier_loss: 1.0270\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6025 - out_loss: 0.1814 - rbf_fourier_loss: 1.0237\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5976 - out_loss: 0.1714 - rbf_fourier_loss: 1.0238\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6000 - out_loss: 0.1796 - rbf_fourier_loss: 1.0204\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5966 - out_loss: 0.1689 - rbf_fourier_loss: 1.0244\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6152 - out_loss: 0.1919 - rbf_fourier_loss: 1.0385\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6016 - out_loss: 0.1802 - rbf_fourier_loss: 1.0229\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6082 - out_loss: 0.1854 - rbf_fourier_loss: 1.0310\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6058 - out_loss: 0.1767 - rbf_fourier_loss: 1.0349\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6094 - out_loss: 0.1869 - rbf_fourier_loss: 1.0319\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5917 - out_loss: 0.1709 - rbf_fourier_loss: 1.0126\n",
            "it 1/10\n",
            "acc: 72.55639097744361\n",
            "ari: 69.01583700375393\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 220ms/step - loss: 0.5670 - out_loss: 0.0924 - rbf_fourier_loss: 1.0416\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5522 - out_loss: 0.0720 - rbf_fourier_loss: 1.0324\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5507 - out_loss: 0.0532 - rbf_fourier_loss: 1.0482\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5500 - out_loss: 0.0466 - rbf_fourier_loss: 1.0533\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5335 - out_loss: 0.0403 - rbf_fourier_loss: 1.0267\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5390 - out_loss: 0.0332 - rbf_fourier_loss: 1.0448\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5264 - out_loss: 0.0291 - rbf_fourier_loss: 1.0236\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5179 - out_loss: 0.0158 - rbf_fourier_loss: 1.0201\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5166 - out_loss: 0.0014 - rbf_fourier_loss: 1.0319\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5187 - out_loss: 8.6792e-04 - rbf_fourier_loss: 1.0366\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5154 - out_loss: 7.1055e-04 - rbf_fourier_loss: 1.0301\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5208 - out_loss: 5.5337e-04 - rbf_fourier_loss: 1.0410\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5188 - out_loss: 3.3499e-04 - rbf_fourier_loss: 1.0373\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5167 - out_loss: 3.3324e-04 - rbf_fourier_loss: 1.0331\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5146 - out_loss: 1.3109e-04 - rbf_fourier_loss: 1.0290\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5141 - out_loss: 1.2784e-04 - rbf_fourier_loss: 1.0281\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5180 - out_loss: 1.3499e-04 - rbf_fourier_loss: 1.0359\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5210 - out_loss: 1.0098e-04 - rbf_fourier_loss: 1.0419\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5129 - out_loss: 8.1149e-05 - rbf_fourier_loss: 1.0257\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5151 - out_loss: 4.4883e-05 - rbf_fourier_loss: 1.0301\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5157 - out_loss: 3.4137e-05 - rbf_fourier_loss: 1.0314\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5136 - out_loss: 1.6779e-05 - rbf_fourier_loss: 1.0272\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5144 - out_loss: 2.5856e-04 - rbf_fourier_loss: 1.0285\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5140 - out_loss: 1.8042e-05 - rbf_fourier_loss: 1.0280\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5150 - out_loss: 1.0274e-05 - rbf_fourier_loss: 1.0300\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5128 - out_loss: 4.9394e-06 - rbf_fourier_loss: 1.0256\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5159 - out_loss: 3.2051e-06 - rbf_fourier_loss: 1.0317\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5224 - out_loss: 3.6196e-06 - rbf_fourier_loss: 1.0447\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5073 - out_loss: 3.3174e-06 - rbf_fourier_loss: 1.0147\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5268 - out_loss: 2.1455e-06 - rbf_fourier_loss: 1.0536\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5150 - out_loss: 2.0469e-06 - rbf_fourier_loss: 1.0301\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5173 - out_loss: 1.8329e-06 - rbf_fourier_loss: 1.0346\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5142 - out_loss: 1.4847e-06 - rbf_fourier_loss: 1.0284\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5136 - out_loss: 1.8481e-06 - rbf_fourier_loss: 1.0272\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5170 - out_loss: 1.4265e-06 - rbf_fourier_loss: 1.0339\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5143 - out_loss: 1.3853e-06 - rbf_fourier_loss: 1.0285\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5185 - out_loss: 1.3982e-06 - rbf_fourier_loss: 1.0370\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5209 - out_loss: 5.8409e-07 - rbf_fourier_loss: 1.0417\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5093 - out_loss: 1.6428e-06 - rbf_fourier_loss: 1.0186\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5177 - out_loss: 5.2393e-07 - rbf_fourier_loss: 1.0354\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5238 - out_loss: 2.3953e-07 - rbf_fourier_loss: 1.0477\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5212 - out_loss: 1.7989e-07 - rbf_fourier_loss: 1.0424\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5206 - out_loss: 1.7791e-07 - rbf_fourier_loss: 1.0413\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5196 - out_loss: 1.6586e-07 - rbf_fourier_loss: 1.0392\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5118 - out_loss: 1.6433e-07 - rbf_fourier_loss: 1.0237\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5128 - out_loss: 9.8839e-08 - rbf_fourier_loss: 1.0256\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5114 - out_loss: 9.8535e-08 - rbf_fourier_loss: 1.0229\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5148 - out_loss: 1.1450e-07 - rbf_fourier_loss: 1.0296\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5138 - out_loss: 6.1915e-08 - rbf_fourier_loss: 1.0277\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5168 - out_loss: 6.9501e-08 - rbf_fourier_loss: 1.0337\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5213 - out_loss: 5.5716e-08 - rbf_fourier_loss: 1.0426\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5202 - out_loss: 4.2488e-07 - rbf_fourier_loss: 1.0403\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5080 - out_loss: 3.0865e-08 - rbf_fourier_loss: 1.0159\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5060 - out_loss: 2.7604e-08 - rbf_fourier_loss: 1.0119\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5212 - out_loss: 2.8185e-08 - rbf_fourier_loss: 1.0425\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5144 - out_loss: 1.7881e-08 - rbf_fourier_loss: 1.0287\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5111 - out_loss: 2.1128e-08 - rbf_fourier_loss: 1.0221\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5168 - out_loss: 1.5915e-08 - rbf_fourier_loss: 1.0336\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5243 - out_loss: 1.4628e-08 - rbf_fourier_loss: 1.0486\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5186 - out_loss: 1.6156e-08 - rbf_fourier_loss: 1.0372\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5151 - out_loss: 1.3340e-08 - rbf_fourier_loss: 1.0303\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5185 - out_loss: 1.5103e-08 - rbf_fourier_loss: 1.0369\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5095 - out_loss: 1.3076e-08 - rbf_fourier_loss: 1.0190\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5246 - out_loss: 1.0452e-08 - rbf_fourier_loss: 1.0491\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5208 - out_loss: 8.6153e-09 - rbf_fourier_loss: 1.0415\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5155 - out_loss: 9.2586e-09 - rbf_fourier_loss: 1.0310\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5156 - out_loss: 7.4272e-09 - rbf_fourier_loss: 1.0311\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5138 - out_loss: 7.1245e-09 - rbf_fourier_loss: 1.0276\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5038 - out_loss: 6.5332e-09 - rbf_fourier_loss: 1.0076\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5192 - out_loss: 6.5657e-09 - rbf_fourier_loss: 1.0385\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5171 - out_loss: 6.2567e-09 - rbf_fourier_loss: 1.0342\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5186 - out_loss: 7.0558e-09 - rbf_fourier_loss: 1.0373\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5171 - out_loss: 5.2664e-09 - rbf_fourier_loss: 1.0341\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5168 - out_loss: 7.0811e-09 - rbf_fourier_loss: 1.0336\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5150 - out_loss: 5.2859e-09 - rbf_fourier_loss: 1.0300\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5197 - out_loss: 5.3290e-09 - rbf_fourier_loss: 1.0395\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5151 - out_loss: 6.7774e-09 - rbf_fourier_loss: 1.0302\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5147 - out_loss: 5.9120e-09 - rbf_fourier_loss: 1.0293\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5216 - out_loss: 5.1267e-09 - rbf_fourier_loss: 1.0432\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5158 - out_loss: 5.0748e-09 - rbf_fourier_loss: 1.0317\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5157 - out_loss: 4.7316e-09 - rbf_fourier_loss: 1.0313\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5220 - out_loss: 6.0484e-09 - rbf_fourier_loss: 1.0439\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5078 - out_loss: 4.1517e-09 - rbf_fourier_loss: 1.0156\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5297 - out_loss: 5.2927e-09 - rbf_fourier_loss: 1.0593\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5136 - out_loss: 4.0581e-09 - rbf_fourier_loss: 1.0271\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5158 - out_loss: 3.7773e-09 - rbf_fourier_loss: 1.0317\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5204 - out_loss: 4.6918e-09 - rbf_fourier_loss: 1.0407\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5141 - out_loss: 3.6956e-09 - rbf_fourier_loss: 1.0282\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5204 - out_loss: 3.6229e-09 - rbf_fourier_loss: 1.0407\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5144 - out_loss: 3.7927e-09 - rbf_fourier_loss: 1.0288\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5104 - out_loss: 3.3790e-09 - rbf_fourier_loss: 1.0209\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5140 - out_loss: 3.6713e-09 - rbf_fourier_loss: 1.0281\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5125 - out_loss: 3.7757e-09 - rbf_fourier_loss: 1.0251\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5230 - out_loss: 3.8388e-09 - rbf_fourier_loss: 1.0460\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5257 - out_loss: 4.0116e-09 - rbf_fourier_loss: 1.0515\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5165 - out_loss: 2.7202e-09 - rbf_fourier_loss: 1.0330\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5180 - out_loss: 3.2436e-09 - rbf_fourier_loss: 1.0361\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5203 - out_loss: 2.9399e-09 - rbf_fourier_loss: 1.0405\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5159 - out_loss: 3.0399e-09 - rbf_fourier_loss: 1.0318\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5208 - out_loss: 3.2836e-09 - rbf_fourier_loss: 1.0415\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 0.7767 - out_loss: 0.3443 - rbf_fourier_loss: 1.2090\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7105 - out_loss: 0.2103 - rbf_fourier_loss: 1.2106\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7044 - out_loss: 0.2035 - rbf_fourier_loss: 1.2052\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6990 - out_loss: 0.1878 - rbf_fourier_loss: 1.2102\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6677 - out_loss: 0.1308 - rbf_fourier_loss: 1.2045\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6146 - out_loss: 0.0214 - rbf_fourier_loss: 1.2079\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6078 - out_loss: 0.0127 - rbf_fourier_loss: 1.2029\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6156 - out_loss: 0.0264 - rbf_fourier_loss: 1.2048\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6085 - out_loss: 0.0099 - rbf_fourier_loss: 1.2070\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5986 - out_loss: 0.0054 - rbf_fourier_loss: 1.1918\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6201 - out_loss: 0.0059 - rbf_fourier_loss: 1.2343\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6127 - out_loss: 0.0073 - rbf_fourier_loss: 1.2181\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6015 - out_loss: 0.0047 - rbf_fourier_loss: 1.1983\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6141 - out_loss: 0.0024 - rbf_fourier_loss: 1.2259\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6025 - out_loss: 0.0021 - rbf_fourier_loss: 1.2030\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6007 - out_loss: 0.0033 - rbf_fourier_loss: 1.1981\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5966 - out_loss: 0.0029 - rbf_fourier_loss: 1.1904\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6137 - out_loss: 0.0031 - rbf_fourier_loss: 1.2242\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6030 - out_loss: 8.8536e-04 - rbf_fourier_loss: 1.2051\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6041 - out_loss: 0.0110 - rbf_fourier_loss: 1.1972\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6026 - out_loss: 7.1383e-04 - rbf_fourier_loss: 1.2044\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6024 - out_loss: 6.6706e-04 - rbf_fourier_loss: 1.2041\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6047 - out_loss: 7.2753e-04 - rbf_fourier_loss: 1.2086\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6110 - out_loss: 5.5914e-04 - rbf_fourier_loss: 1.2215\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5981 - out_loss: 4.7941e-04 - rbf_fourier_loss: 1.1956\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6041 - out_loss: 4.9675e-04 - rbf_fourier_loss: 1.2077\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6022 - out_loss: 3.7966e-04 - rbf_fourier_loss: 1.2041\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6047 - out_loss: 0.0061 - rbf_fourier_loss: 1.2032\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6068 - out_loss: 3.6871e-04 - rbf_fourier_loss: 1.2131\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6176 - out_loss: 0.0029 - rbf_fourier_loss: 1.2323\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6106 - out_loss: 4.4481e-04 - rbf_fourier_loss: 1.2208\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6063 - out_loss: 2.4857e-04 - rbf_fourier_loss: 1.2123\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6152 - out_loss: 1.8026e-04 - rbf_fourier_loss: 1.2302\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6052 - out_loss: 0.0012 - rbf_fourier_loss: 1.2092\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6133 - out_loss: 2.2128e-04 - rbf_fourier_loss: 1.2263\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5989 - out_loss: 1.4712e-04 - rbf_fourier_loss: 1.1977\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6087 - out_loss: 0.0011 - rbf_fourier_loss: 1.2163\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6066 - out_loss: 2.2581e-04 - rbf_fourier_loss: 1.2130\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6092 - out_loss: 9.7727e-05 - rbf_fourier_loss: 1.2182\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6014 - out_loss: 0.0033 - rbf_fourier_loss: 1.1996\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5999 - out_loss: 1.3070e-04 - rbf_fourier_loss: 1.1997\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5980 - out_loss: 1.3453e-04 - rbf_fourier_loss: 1.1958\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6050 - out_loss: 8.4696e-05 - rbf_fourier_loss: 1.2100\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6065 - out_loss: 6.8941e-05 - rbf_fourier_loss: 1.2129\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6095 - out_loss: 6.6006e-05 - rbf_fourier_loss: 1.2188\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6041 - out_loss: 6.8531e-05 - rbf_fourier_loss: 1.2082\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5990 - out_loss: 8.1573e-05 - rbf_fourier_loss: 1.1978\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6016 - out_loss: 2.8736e-04 - rbf_fourier_loss: 1.2030\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5995 - out_loss: 2.7973e-04 - rbf_fourier_loss: 1.1988\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6064 - out_loss: 7.8991e-05 - rbf_fourier_loss: 1.2127\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5994 - out_loss: 1.0412e-04 - rbf_fourier_loss: 1.1988\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6049 - out_loss: 4.9793e-05 - rbf_fourier_loss: 1.2098\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6003 - out_loss: 4.8561e-05 - rbf_fourier_loss: 1.2005\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6092 - out_loss: 4.3628e-05 - rbf_fourier_loss: 1.2184\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5975 - out_loss: 4.0774e-05 - rbf_fourier_loss: 1.1949\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6037 - out_loss: 4.7506e-05 - rbf_fourier_loss: 1.2073\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6020 - out_loss: 5.2032e-04 - rbf_fourier_loss: 1.2035\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6007 - out_loss: 7.9571e-05 - rbf_fourier_loss: 1.2014\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6063 - out_loss: 3.5034e-05 - rbf_fourier_loss: 1.2126\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6092 - out_loss: 3.1522e-05 - rbf_fourier_loss: 1.2185\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6032 - out_loss: 2.7659e-05 - rbf_fourier_loss: 1.2064\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6041 - out_loss: 2.7425e-05 - rbf_fourier_loss: 1.2082\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5949 - out_loss: 1.1629e-04 - rbf_fourier_loss: 1.1896\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6033 - out_loss: 3.1408e-05 - rbf_fourier_loss: 1.2066\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6090 - out_loss: 2.3432e-05 - rbf_fourier_loss: 1.2179\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6102 - out_loss: 4.5269e-05 - rbf_fourier_loss: 1.2204\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6018 - out_loss: 5.8641e-05 - rbf_fourier_loss: 1.2035\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5978 - out_loss: 3.1012e-05 - rbf_fourier_loss: 1.1956\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6085 - out_loss: 1.3191e-05 - rbf_fourier_loss: 1.2170\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6027 - out_loss: 1.5100e-05 - rbf_fourier_loss: 1.2054\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6054 - out_loss: 1.5550e-05 - rbf_fourier_loss: 1.2108\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6094 - out_loss: 0.0027 - rbf_fourier_loss: 1.2160\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6046 - out_loss: 1.6483e-05 - rbf_fourier_loss: 1.2093\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6070 - out_loss: 1.4821e-05 - rbf_fourier_loss: 1.2140\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6013 - out_loss: 1.1185e-05 - rbf_fourier_loss: 1.2026\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6106 - out_loss: 1.4514e-05 - rbf_fourier_loss: 1.2212\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6053 - out_loss: 1.1025e-05 - rbf_fourier_loss: 1.2105\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6117 - out_loss: 1.1618e-05 - rbf_fourier_loss: 1.2233\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6047 - out_loss: 1.0157e-05 - rbf_fourier_loss: 1.2094\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6020 - out_loss: 1.1557e-05 - rbf_fourier_loss: 1.2039\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6000 - out_loss: 9.8287e-06 - rbf_fourier_loss: 1.2000\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6091 - out_loss: 2.3645e-05 - rbf_fourier_loss: 1.2182\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6008 - out_loss: 9.5701e-06 - rbf_fourier_loss: 1.2016\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6079 - out_loss: 1.1885e-05 - rbf_fourier_loss: 1.2158\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6128 - out_loss: 1.6134e-05 - rbf_fourier_loss: 1.2255\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6033 - out_loss: 5.6419e-06 - rbf_fourier_loss: 1.2065\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5996 - out_loss: 6.7059e-06 - rbf_fourier_loss: 1.1992\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6020 - out_loss: 6.9906e-06 - rbf_fourier_loss: 1.2040\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6008 - out_loss: 5.7070e-06 - rbf_fourier_loss: 1.2016\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5997 - out_loss: 1.0954e-05 - rbf_fourier_loss: 1.1993\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6043 - out_loss: 4.6411e-05 - rbf_fourier_loss: 1.2085\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6082 - out_loss: 8.1964e-06 - rbf_fourier_loss: 1.2164\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6035 - out_loss: 5.9217e-06 - rbf_fourier_loss: 1.2070\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6083 - out_loss: 8.3075e-06 - rbf_fourier_loss: 1.2165\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6102 - out_loss: 4.6255e-06 - rbf_fourier_loss: 1.2203\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5974 - out_loss: 4.3907e-06 - rbf_fourier_loss: 1.1949\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6040 - out_loss: 5.2196e-06 - rbf_fourier_loss: 1.2080\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6065 - out_loss: 9.2928e-06 - rbf_fourier_loss: 1.2129\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6018 - out_loss: 9.1749e-05 - rbf_fourier_loss: 1.2036\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6102 - out_loss: 4.4423e-06 - rbf_fourier_loss: 1.2204\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 1.4457 - out_loss: 0.4759 - rbf_fourier_loss: 2.4156\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4308 - out_loss: 0.4491 - rbf_fourier_loss: 2.4125\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4169 - out_loss: 0.3922 - rbf_fourier_loss: 2.4417\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3744 - out_loss: 0.3037 - rbf_fourier_loss: 2.4451\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3755 - out_loss: 0.3111 - rbf_fourier_loss: 2.4399\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3587 - out_loss: 0.2912 - rbf_fourier_loss: 2.4261\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3836 - out_loss: 0.3306 - rbf_fourier_loss: 2.4365\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3608 - out_loss: 0.2917 - rbf_fourier_loss: 2.4300\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3567 - out_loss: 0.2487 - rbf_fourier_loss: 2.4647\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3436 - out_loss: 0.2491 - rbf_fourier_loss: 2.4381\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3601 - out_loss: 0.2753 - rbf_fourier_loss: 2.4449\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3389 - out_loss: 0.2532 - rbf_fourier_loss: 2.4245\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3354 - out_loss: 0.2477 - rbf_fourier_loss: 2.4230\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3294 - out_loss: 0.2217 - rbf_fourier_loss: 2.4371\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3238 - out_loss: 0.2266 - rbf_fourier_loss: 2.4211\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3734 - out_loss: 0.2995 - rbf_fourier_loss: 2.4473\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3169 - out_loss: 0.2043 - rbf_fourier_loss: 2.4294\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3273 - out_loss: 0.2357 - rbf_fourier_loss: 2.4189\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2963 - out_loss: 0.1848 - rbf_fourier_loss: 2.4077\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3154 - out_loss: 0.2177 - rbf_fourier_loss: 2.4130\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3052 - out_loss: 0.1989 - rbf_fourier_loss: 2.4115\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3089 - out_loss: 0.1784 - rbf_fourier_loss: 2.4395\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3210 - out_loss: 0.1936 - rbf_fourier_loss: 2.4483\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2873 - out_loss: 0.1770 - rbf_fourier_loss: 2.3976\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3169 - out_loss: 0.2114 - rbf_fourier_loss: 2.4223\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3103 - out_loss: 0.1947 - rbf_fourier_loss: 2.4259\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3063 - out_loss: 0.1728 - rbf_fourier_loss: 2.4399\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3011 - out_loss: 0.1600 - rbf_fourier_loss: 2.4422\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2935 - out_loss: 0.1591 - rbf_fourier_loss: 2.4279\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3003 - out_loss: 0.1545 - rbf_fourier_loss: 2.4461\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3101 - out_loss: 0.1773 - rbf_fourier_loss: 2.4429\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2986 - out_loss: 0.1469 - rbf_fourier_loss: 2.4503\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2927 - out_loss: 0.1781 - rbf_fourier_loss: 2.4072\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2783 - out_loss: 0.1341 - rbf_fourier_loss: 2.4225\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3061 - out_loss: 0.1779 - rbf_fourier_loss: 2.4343\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2853 - out_loss: 0.1503 - rbf_fourier_loss: 2.4202\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2702 - out_loss: 0.1331 - rbf_fourier_loss: 2.4073\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2732 - out_loss: 0.1318 - rbf_fourier_loss: 2.4146\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2806 - out_loss: 0.1403 - rbf_fourier_loss: 2.4208\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2769 - out_loss: 0.1452 - rbf_fourier_loss: 2.4086\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2685 - out_loss: 0.1146 - rbf_fourier_loss: 2.4223\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2852 - out_loss: 0.1498 - rbf_fourier_loss: 2.4207\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2663 - out_loss: 0.1189 - rbf_fourier_loss: 2.4137\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2867 - out_loss: 0.1144 - rbf_fourier_loss: 2.4590\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2706 - out_loss: 0.1278 - rbf_fourier_loss: 2.4134\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2767 - out_loss: 0.1132 - rbf_fourier_loss: 2.4402\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2671 - out_loss: 0.1039 - rbf_fourier_loss: 2.4304\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2770 - out_loss: 0.1436 - rbf_fourier_loss: 2.4105\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2746 - out_loss: 0.1274 - rbf_fourier_loss: 2.4218\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2747 - out_loss: 0.1168 - rbf_fourier_loss: 2.4326\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2727 - out_loss: 0.1159 - rbf_fourier_loss: 2.4294\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2670 - out_loss: 0.1165 - rbf_fourier_loss: 2.4175\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2878 - out_loss: 0.1464 - rbf_fourier_loss: 2.4292\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2629 - out_loss: 0.1171 - rbf_fourier_loss: 2.4087\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2686 - out_loss: 0.1245 - rbf_fourier_loss: 2.4126\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2699 - out_loss: 0.1079 - rbf_fourier_loss: 2.4320\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2750 - out_loss: 0.1202 - rbf_fourier_loss: 2.4298\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2801 - out_loss: 0.1200 - rbf_fourier_loss: 2.4402\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2754 - out_loss: 0.1116 - rbf_fourier_loss: 2.4392\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2687 - out_loss: 0.1150 - rbf_fourier_loss: 2.4224\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2829 - out_loss: 0.1247 - rbf_fourier_loss: 2.4412\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2891 - out_loss: 0.1586 - rbf_fourier_loss: 2.4196\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2730 - out_loss: 0.1200 - rbf_fourier_loss: 2.4261\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2952 - out_loss: 0.1567 - rbf_fourier_loss: 2.4337\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2598 - out_loss: 0.0973 - rbf_fourier_loss: 2.4224\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2753 - out_loss: 0.1299 - rbf_fourier_loss: 2.4208\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2813 - out_loss: 0.1314 - rbf_fourier_loss: 2.4312\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2591 - out_loss: 0.0928 - rbf_fourier_loss: 2.4254\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2639 - out_loss: 0.1075 - rbf_fourier_loss: 2.4202\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2673 - out_loss: 0.1003 - rbf_fourier_loss: 2.4344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2773 - out_loss: 0.1474 - rbf_fourier_loss: 2.4072\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2810 - out_loss: 0.1425 - rbf_fourier_loss: 2.4195\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2661 - out_loss: 0.1050 - rbf_fourier_loss: 2.4271\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2692 - out_loss: 0.1072 - rbf_fourier_loss: 2.4311\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2656 - out_loss: 0.1085 - rbf_fourier_loss: 2.4227\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2627 - out_loss: 0.1097 - rbf_fourier_loss: 2.4156\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2675 - out_loss: 0.0915 - rbf_fourier_loss: 2.4435\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2877 - out_loss: 0.1440 - rbf_fourier_loss: 2.4315\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2665 - out_loss: 0.1029 - rbf_fourier_loss: 2.4301\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2621 - out_loss: 0.1136 - rbf_fourier_loss: 2.4105\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2764 - out_loss: 0.1322 - rbf_fourier_loss: 2.4206\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2699 - out_loss: 0.0989 - rbf_fourier_loss: 2.4408\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2660 - out_loss: 0.1251 - rbf_fourier_loss: 2.4068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2663 - out_loss: 0.1117 - rbf_fourier_loss: 2.4208\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2661 - out_loss: 0.1053 - rbf_fourier_loss: 2.4270\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2601 - out_loss: 0.1006 - rbf_fourier_loss: 2.4195\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2938 - out_loss: 0.1474 - rbf_fourier_loss: 2.4402\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2520 - out_loss: 0.0819 - rbf_fourier_loss: 2.4220\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2578 - out_loss: 0.0910 - rbf_fourier_loss: 2.4246\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2678 - out_loss: 0.1108 - rbf_fourier_loss: 2.4248\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2632 - out_loss: 0.0981 - rbf_fourier_loss: 2.4284\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2660 - out_loss: 0.1030 - rbf_fourier_loss: 2.4291\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2736 - out_loss: 0.1134 - rbf_fourier_loss: 2.4338\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2714 - out_loss: 0.1106 - rbf_fourier_loss: 2.4322\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2693 - out_loss: 0.1042 - rbf_fourier_loss: 2.4345\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2544 - out_loss: 0.0975 - rbf_fourier_loss: 2.4112\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2555 - out_loss: 0.0941 - rbf_fourier_loss: 2.4170\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2607 - out_loss: 0.0904 - rbf_fourier_loss: 2.4310\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2808 - out_loss: 0.1250 - rbf_fourier_loss: 2.4366\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2565 - out_loss: 0.0867 - rbf_fourier_loss: 2.4263\n",
            "it 1/10\n",
            "acc: 85.33834586466166\n",
            "ari: 59.78988606176342\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 0.0630 - out_loss: 0.3202 - rbf_fourier_loss: -0.1942\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0283 - out_loss: 0.2542 - rbf_fourier_loss: -0.1977\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - out_loss: 0.2063 - rbf_fourier_loss: -0.1937\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0281 - out_loss: 0.1383 - rbf_fourier_loss: -0.1944\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0537 - out_loss: 0.0886 - rbf_fourier_loss: -0.1960\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0649 - out_loss: 0.0635 - rbf_fourier_loss: -0.1934\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0701 - out_loss: 0.0526 - rbf_fourier_loss: -0.1927\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0698 - out_loss: 0.0556 - rbf_fourier_loss: -0.1951\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0655 - out_loss: 0.0624 - rbf_fourier_loss: -0.1935\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0705 - out_loss: 0.0550 - rbf_fourier_loss: -0.1959\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0756 - out_loss: 0.0423 - rbf_fourier_loss: -0.1935\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0792 - out_loss: 0.0355 - rbf_fourier_loss: -0.1939\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0830 - out_loss: 0.0280 - rbf_fourier_loss: -0.1940\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0846 - out_loss: 0.0268 - rbf_fourier_loss: -0.1961\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0838 - out_loss: 0.0217 - rbf_fourier_loss: -0.1892\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0843 - out_loss: 0.0293 - rbf_fourier_loss: -0.1979\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0868 - out_loss: 0.0196 - rbf_fourier_loss: -0.1931\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0883 - out_loss: 0.0178 - rbf_fourier_loss: -0.1944\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0853 - out_loss: 0.0214 - rbf_fourier_loss: -0.1921\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0882 - out_loss: 0.0188 - rbf_fourier_loss: -0.1953\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -0.0857 - out_loss: 0.0223 - rbf_fourier_loss: -0.1937\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0886 - out_loss: 0.0191 - rbf_fourier_loss: -0.1963\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0859 - out_loss: 0.0212 - rbf_fourier_loss: -0.1929\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0851 - out_loss: 0.0165 - rbf_fourier_loss: -0.1867\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0916 - out_loss: 0.0147 - rbf_fourier_loss: -0.1980\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0885 - out_loss: 0.0155 - rbf_fourier_loss: -0.1926\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0912 - out_loss: 0.0104 - rbf_fourier_loss: -0.1928\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0907 - out_loss: 0.0129 - rbf_fourier_loss: -0.1942\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0951 - out_loss: 0.0061 - rbf_fourier_loss: -0.1962\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0929 - out_loss: 0.0083 - rbf_fourier_loss: -0.1940\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0940 - out_loss: 0.0044 - rbf_fourier_loss: -0.1923\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0979 - out_loss: 1.6828e-04 - rbf_fourier_loss: -0.1960\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0994 - out_loss: 4.6734e-05 - rbf_fourier_loss: -0.1988\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0946 - out_loss: 4.3321e-05 - rbf_fourier_loss: -0.1893\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0963 - out_loss: 2.0868e-05 - rbf_fourier_loss: -0.1926\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0986 - out_loss: 2.9699e-05 - rbf_fourier_loss: -0.1972\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0985 - out_loss: 1.6662e-05 - rbf_fourier_loss: -0.1971\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0959 - out_loss: 1.3036e-05 - rbf_fourier_loss: -0.1918\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0963 - out_loss: 1.1093e-05 - rbf_fourier_loss: -0.1927\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0964 - out_loss: 7.5006e-06 - rbf_fourier_loss: -0.1927\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0984 - out_loss: 6.8949e-06 - rbf_fourier_loss: -0.1968\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0960 - out_loss: 5.7582e-06 - rbf_fourier_loss: -0.1921\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0974 - out_loss: 4.2763e-06 - rbf_fourier_loss: -0.1947\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0980 - out_loss: 2.8868e-06 - rbf_fourier_loss: -0.1959\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0974 - out_loss: 2.0702e-06 - rbf_fourier_loss: -0.1948\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0975 - out_loss: 2.1829e-06 - rbf_fourier_loss: -0.1951\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0947 - out_loss: 1.7613e-06 - rbf_fourier_loss: -0.1893\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0981 - out_loss: 1.3417e-06 - rbf_fourier_loss: -0.1961\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0981 - out_loss: 9.7664e-07 - rbf_fourier_loss: -0.1962\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0950 - out_loss: 5.6176e-07 - rbf_fourier_loss: -0.1901\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0985 - out_loss: 4.2800e-07 - rbf_fourier_loss: -0.1970\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0957 - out_loss: 4.4628e-07 - rbf_fourier_loss: -0.1915\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0974 - out_loss: 2.7742e-07 - rbf_fourier_loss: -0.1947\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0993 - out_loss: 1.9040e-07 - rbf_fourier_loss: -0.1987\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0972 - out_loss: 1.6918e-07 - rbf_fourier_loss: -0.1944\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0955 - out_loss: 1.2698e-07 - rbf_fourier_loss: -0.1909\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0980 - out_loss: 8.3825e-08 - rbf_fourier_loss: -0.1960\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0977 - out_loss: 5.5403e-08 - rbf_fourier_loss: -0.1955\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0965 - out_loss: 5.2554e-08 - rbf_fourier_loss: -0.1930\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0941 - out_loss: 5.5897e-08 - rbf_fourier_loss: -0.1882\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0987 - out_loss: 4.7900e-08 - rbf_fourier_loss: -0.1973\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0951 - out_loss: 3.7022e-08 - rbf_fourier_loss: -0.1901\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0981 - out_loss: 2.8747e-08 - rbf_fourier_loss: -0.1962\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0989 - out_loss: 3.2513e-08 - rbf_fourier_loss: -0.1979\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0973 - out_loss: 2.3906e-08 - rbf_fourier_loss: -0.1947\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0955 - out_loss: 1.8880e-08 - rbf_fourier_loss: -0.1909\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0955 - out_loss: 1.4385e-08 - rbf_fourier_loss: -0.1910\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0986 - out_loss: 1.2622e-08 - rbf_fourier_loss: -0.1972\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0962 - out_loss: 1.2715e-08 - rbf_fourier_loss: -0.1923\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0969 - out_loss: 7.1985e-09 - rbf_fourier_loss: -0.1939\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0976 - out_loss: 7.7134e-09 - rbf_fourier_loss: -0.1952\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0966 - out_loss: 7.6246e-09 - rbf_fourier_loss: -0.1932\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0977 - out_loss: 7.4232e-09 - rbf_fourier_loss: -0.1954\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0965 - out_loss: 7.2682e-09 - rbf_fourier_loss: -0.1930\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0971 - out_loss: 6.3774e-09 - rbf_fourier_loss: -0.1942\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0953 - out_loss: 5.5567e-09 - rbf_fourier_loss: -0.1907\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0972 - out_loss: 5.5180e-09 - rbf_fourier_loss: -0.1943\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0966 - out_loss: 3.8487e-09 - rbf_fourier_loss: -0.1932\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0964 - out_loss: 5.9091e-09 - rbf_fourier_loss: -0.1928\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0981 - out_loss: 4.7069e-09 - rbf_fourier_loss: -0.1961\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0963 - out_loss: 4.1076e-09 - rbf_fourier_loss: -0.1926\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0973 - out_loss: 5.1737e-09 - rbf_fourier_loss: -0.1946\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0978 - out_loss: 3.9674e-09 - rbf_fourier_loss: -0.1956\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0959 - out_loss: 3.1899e-09 - rbf_fourier_loss: -0.1919\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0950 - out_loss: 3.6259e-09 - rbf_fourier_loss: -0.1900\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0964 - out_loss: 3.4245e-09 - rbf_fourier_loss: -0.1928\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0979 - out_loss: 2.6562e-09 - rbf_fourier_loss: -0.1958\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0972 - out_loss: 2.5604e-09 - rbf_fourier_loss: -0.1943\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0962 - out_loss: 2.6695e-09 - rbf_fourier_loss: -0.1925\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0962 - out_loss: 2.5200e-09 - rbf_fourier_loss: -0.1924\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0970 - out_loss: 2.4961e-09 - rbf_fourier_loss: -0.1939\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0967 - out_loss: 2.7816e-09 - rbf_fourier_loss: -0.1935\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0973 - out_loss: 2.8590e-09 - rbf_fourier_loss: -0.1945\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0980 - out_loss: 2.3934e-09 - rbf_fourier_loss: -0.1961\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0970 - out_loss: 2.4194e-09 - rbf_fourier_loss: -0.1939\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0966 - out_loss: 2.4458e-09 - rbf_fourier_loss: -0.1932\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0956 - out_loss: 2.3248e-09 - rbf_fourier_loss: -0.1913\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0952 - out_loss: 1.7383e-09 - rbf_fourier_loss: -0.1903\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0972 - out_loss: 1.7852e-09 - rbf_fourier_loss: -0.1944\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0960 - out_loss: 2.5358e-09 - rbf_fourier_loss: -0.1920\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 0.1845 - out_loss: 0.4077 - rbf_fourier_loss: -0.0387\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1557 - out_loss: 0.3410 - rbf_fourier_loss: -0.0297\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1422 - out_loss: 0.3233 - rbf_fourier_loss: -0.0388\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1012 - out_loss: 0.2300 - rbf_fourier_loss: -0.0277\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0952 - out_loss: 0.2157 - rbf_fourier_loss: -0.0254\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0855 - out_loss: 0.1983 - rbf_fourier_loss: -0.0273\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0633 - out_loss: 0.1640 - rbf_fourier_loss: -0.0374\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0698 - out_loss: 0.1658 - rbf_fourier_loss: -0.0262\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - out_loss: 0.1511 - rbf_fourier_loss: -0.0322\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - out_loss: 0.1474 - rbf_fourier_loss: -0.0324\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0630 - out_loss: 0.1607 - rbf_fourier_loss: -0.0347\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0653 - out_loss: 0.1581 - rbf_fourier_loss: -0.0275\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0723 - out_loss: 0.1674 - rbf_fourier_loss: -0.0228\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - out_loss: 0.1485 - rbf_fourier_loss: -0.0376\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0626 - out_loss: 0.1527 - rbf_fourier_loss: -0.0275\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - out_loss: 0.1565 - rbf_fourier_loss: -0.0360\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0648 - out_loss: 0.1483 - rbf_fourier_loss: -0.0188\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0614 - out_loss: 0.1500 - rbf_fourier_loss: -0.0271\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0565 - out_loss: 0.1543 - rbf_fourier_loss: -0.0413\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0580 - out_loss: 0.1409 - rbf_fourier_loss: -0.0249\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0521 - out_loss: 0.1454 - rbf_fourier_loss: -0.0412\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0615 - out_loss: 0.1383 - rbf_fourier_loss: -0.0153\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0725 - out_loss: 0.1742 - rbf_fourier_loss: -0.0293\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - out_loss: 0.1467 - rbf_fourier_loss: -0.0268\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0550 - out_loss: 0.1458 - rbf_fourier_loss: -0.0359\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0554 - out_loss: 0.1484 - rbf_fourier_loss: -0.0376\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0663 - out_loss: 0.1557 - rbf_fourier_loss: -0.0231\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - out_loss: 0.1513 - rbf_fourier_loss: -0.0332\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0315 - out_loss: 0.0923 - rbf_fourier_loss: -0.0293\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0051 - out_loss: 0.0184 - rbf_fourier_loss: -0.0285\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0115 - out_loss: 0.0118 - rbf_fourier_loss: -0.0349\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0100 - out_loss: 0.0061 - rbf_fourier_loss: -0.0261\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0202 - out_loss: 0.0035 - rbf_fourier_loss: -0.0439\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0155 - out_loss: 0.0031 - rbf_fourier_loss: -0.0341\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0076 - out_loss: 0.0114 - rbf_fourier_loss: -0.0266\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0143 - out_loss: 0.0012 - rbf_fourier_loss: -0.0297\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0177 - out_loss: 0.0013 - rbf_fourier_loss: -0.0367\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0154 - out_loss: 7.8894e-04 - rbf_fourier_loss: -0.0315\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0186 - out_loss: 7.6611e-04 - rbf_fourier_loss: -0.0379\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0164 - out_loss: 4.3553e-04 - rbf_fourier_loss: -0.0331\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0181 - out_loss: 3.6289e-04 - rbf_fourier_loss: -0.0365\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0117 - out_loss: 3.3610e-04 - rbf_fourier_loss: -0.0237\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0170 - out_loss: 2.9667e-04 - rbf_fourier_loss: -0.0343\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0166 - out_loss: 2.3373e-04 - rbf_fourier_loss: -0.0334\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0183 - out_loss: 1.7489e-04 - rbf_fourier_loss: -0.0368\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0191 - out_loss: 1.0162e-04 - rbf_fourier_loss: -0.0383\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0123 - out_loss: 1.7211e-04 - rbf_fourier_loss: -0.0249\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0190 - out_loss: 1.2105e-04 - rbf_fourier_loss: -0.0381\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0138 - out_loss: 5.7672e-05 - rbf_fourier_loss: -0.0277\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0049 - out_loss: 5.3055e-05 - rbf_fourier_loss: -0.0099\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0122 - out_loss: 3.5971e-05 - rbf_fourier_loss: -0.0245\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0177 - out_loss: 3.4286e-05 - rbf_fourier_loss: -0.0354\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0163 - out_loss: 2.2162e-05 - rbf_fourier_loss: -0.0326\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0201 - out_loss: 1.5497e-05 - rbf_fourier_loss: -0.0403\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0081 - out_loss: 1.6161e-05 - rbf_fourier_loss: -0.0163  \n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0221 - out_loss: 9.9043e-06 - rbf_fourier_loss: -0.0442\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0083 - out_loss: 0.0017 - rbf_fourier_loss: -0.0183\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0095 - out_loss: 2.2672e-05 - rbf_fourier_loss: -0.0191\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0161 - out_loss: 7.6458e-06 - rbf_fourier_loss: -0.0323\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0146 - out_loss: 7.9513e-06 - rbf_fourier_loss: -0.0293\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0181 - out_loss: 7.1444e-06 - rbf_fourier_loss: -0.0363\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0162 - out_loss: 6.5712e-06 - rbf_fourier_loss: -0.0323\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0197 - out_loss: 5.4329e-06 - rbf_fourier_loss: -0.0395\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0126 - out_loss: 4.5990e-06 - rbf_fourier_loss: -0.0252\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0135 - out_loss: 3.7425e-06 - rbf_fourier_loss: -0.0270\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0186 - out_loss: 3.8506e-06 - rbf_fourier_loss: -0.0373\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0179 - out_loss: 3.1188e-06 - rbf_fourier_loss: -0.0359\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0170 - out_loss: 3.9328e-06 - rbf_fourier_loss: -0.0340\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0214 - out_loss: 2.9805e-06 - rbf_fourier_loss: -0.0428\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0125 - out_loss: 2.6011e-06 - rbf_fourier_loss: -0.0251\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0172 - out_loss: 2.8155e-06 - rbf_fourier_loss: -0.0344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0100 - out_loss: 2.1384e-06 - rbf_fourier_loss: -0.0200\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0167 - out_loss: 2.6343e-06 - rbf_fourier_loss: -0.0335\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0106 - out_loss: 1.8851e-06 - rbf_fourier_loss: -0.0212\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0123 - out_loss: 1.6844e-06 - rbf_fourier_loss: -0.0245\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0206 - out_loss: 1.4759e-06 - rbf_fourier_loss: -0.0412\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0162 - out_loss: 1.4599e-06 - rbf_fourier_loss: -0.0324\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0181 - out_loss: 9.4676e-07 - rbf_fourier_loss: -0.0362\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0165 - out_loss: 8.9274e-07 - rbf_fourier_loss: -0.0329\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0135 - out_loss: 8.1330e-07 - rbf_fourier_loss: -0.0271\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0154 - out_loss: 6.4634e-07 - rbf_fourier_loss: -0.0308\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0143 - out_loss: 5.0675e-07 - rbf_fourier_loss: -0.0285\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0174 - out_loss: 4.1935e-07 - rbf_fourier_loss: -0.0348\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0132 - out_loss: 4.3516e-07 - rbf_fourier_loss: -0.0264\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0148 - out_loss: 6.7509e-07 - rbf_fourier_loss: -0.0297\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0122 - out_loss: 1.5306e-07 - rbf_fourier_loss: -0.0245\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0106 - out_loss: 9.8532e-07 - rbf_fourier_loss: -0.0213\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0131 - out_loss: 4.6858e-07 - rbf_fourier_loss: -0.0262\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0169 - out_loss: 1.1012e-07 - rbf_fourier_loss: -0.0338\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0219 - out_loss: 7.9617e-08 - rbf_fourier_loss: -0.0438\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0158 - out_loss: 6.7397e-08 - rbf_fourier_loss: -0.0317\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0218 - out_loss: 4.6450e-08 - rbf_fourier_loss: -0.0436\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0181 - out_loss: 3.8493e-08 - rbf_fourier_loss: -0.0362\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0129 - out_loss: 5.2438e-08 - rbf_fourier_loss: -0.0258\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0166 - out_loss: 5.7142e-08 - rbf_fourier_loss: -0.0331\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0167 - out_loss: 5.7605e-08 - rbf_fourier_loss: -0.0333\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0186 - out_loss: 4.7474e-08 - rbf_fourier_loss: -0.0372\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0124 - out_loss: 3.9994e-08 - rbf_fourier_loss: -0.0247\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: -0.0158 - out_loss: 2.9318e-08 - rbf_fourier_loss: -0.0317\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -0.0185 - out_loss: 4.0705e-08 - rbf_fourier_loss: -0.0371\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-dbd2225f5c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 24\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhappy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 _r=1):\n\u001b[1;32m   1067\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2927\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2929\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, flat_args, flat_kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     ],\n\u001b[1;32m   1859\u001b[0m                            \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                            cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1934\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1936\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1937\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1938\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    554\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wJvIMhFgNIZ",
        "colab_type": "text"
      },
      "source": [
        "**Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa6rusJtgPpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=2\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQYVv0tpgP0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53b55b9a-178f-4266-9a32-8aa0ebf952d0"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/moonsp3' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_moonso))\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(moons.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_mse(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(moons, [labels_moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(moons)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_moonso)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_moonso,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_moonso,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_moonso,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_moonso,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.6656 - out_loss: 0.4134 - rbf_fourier_loss: 2.9178\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6452 - out_loss: 0.3668 - rbf_fourier_loss: 2.9237\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6450 - out_loss: 0.3665 - rbf_fourier_loss: 2.9235\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6295 - out_loss: 0.3362 - rbf_fourier_loss: 2.9229\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6346 - out_loss: 0.3492 - rbf_fourier_loss: 2.9200\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6159 - out_loss: 0.3095 - rbf_fourier_loss: 2.9223\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6061 - out_loss: 0.2982 - rbf_fourier_loss: 2.9139\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6031 - out_loss: 0.2830 - rbf_fourier_loss: 2.9232\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6085 - out_loss: 0.2978 - rbf_fourier_loss: 2.9191\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5970 - out_loss: 0.2742 - rbf_fourier_loss: 2.9198\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6031 - out_loss: 0.2913 - rbf_fourier_loss: 2.9149\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5976 - out_loss: 0.2750 - rbf_fourier_loss: 2.9201\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5972 - out_loss: 0.2735 - rbf_fourier_loss: 2.9208\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5897 - out_loss: 0.2571 - rbf_fourier_loss: 2.9224\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5955 - out_loss: 0.2802 - rbf_fourier_loss: 2.9108\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5990 - out_loss: 0.2789 - rbf_fourier_loss: 2.9191\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5867 - out_loss: 0.2500 - rbf_fourier_loss: 2.9233\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5869 - out_loss: 0.2528 - rbf_fourier_loss: 2.9211\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5771 - out_loss: 0.2339 - rbf_fourier_loss: 2.9204\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5832 - out_loss: 0.2451 - rbf_fourier_loss: 2.9212\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5731 - out_loss: 0.2246 - rbf_fourier_loss: 2.9216\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5657 - out_loss: 0.2126 - rbf_fourier_loss: 2.9189\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5768 - out_loss: 0.2330 - rbf_fourier_loss: 2.9206\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5671 - out_loss: 0.2179 - rbf_fourier_loss: 2.9163\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5632 - out_loss: 0.2038 - rbf_fourier_loss: 2.9226\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5515 - out_loss: 0.1862 - rbf_fourier_loss: 2.9167\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5606 - out_loss: 0.2002 - rbf_fourier_loss: 2.9210\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5622 - out_loss: 0.1995 - rbf_fourier_loss: 2.9249\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5543 - out_loss: 0.1832 - rbf_fourier_loss: 2.9253\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5370 - out_loss: 0.1496 - rbf_fourier_loss: 2.9243\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5548 - out_loss: 0.1891 - rbf_fourier_loss: 2.9205\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5485 - out_loss: 0.1769 - rbf_fourier_loss: 2.9201\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5414 - out_loss: 0.1603 - rbf_fourier_loss: 2.9226\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5423 - out_loss: 0.1633 - rbf_fourier_loss: 2.9214\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5483 - out_loss: 0.1720 - rbf_fourier_loss: 2.9247\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5334 - out_loss: 0.1456 - rbf_fourier_loss: 2.9213\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5464 - out_loss: 0.1729 - rbf_fourier_loss: 2.9198\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5365 - out_loss: 0.1513 - rbf_fourier_loss: 2.9218\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5419 - out_loss: 0.1596 - rbf_fourier_loss: 2.9242\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5420 - out_loss: 0.1612 - rbf_fourier_loss: 2.9228\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5305 - out_loss: 0.1440 - rbf_fourier_loss: 2.9170\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5301 - out_loss: 0.1411 - rbf_fourier_loss: 2.9190\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5308 - out_loss: 0.1407 - rbf_fourier_loss: 2.9209\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5424 - out_loss: 0.1622 - rbf_fourier_loss: 2.9226\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5256 - out_loss: 0.1276 - rbf_fourier_loss: 2.9236\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5318 - out_loss: 0.1391 - rbf_fourier_loss: 2.9245\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5297 - out_loss: 0.1381 - rbf_fourier_loss: 2.9214\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5267 - out_loss: 0.1340 - rbf_fourier_loss: 2.9193\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5330 - out_loss: 0.1452 - rbf_fourier_loss: 2.9208\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5231 - out_loss: 0.1226 - rbf_fourier_loss: 2.9236\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5187 - out_loss: 0.1135 - rbf_fourier_loss: 2.9239\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5320 - out_loss: 0.1416 - rbf_fourier_loss: 2.9223\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5286 - out_loss: 0.1347 - rbf_fourier_loss: 2.9224\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5170 - out_loss: 0.1122 - rbf_fourier_loss: 2.9219\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5236 - out_loss: 0.1296 - rbf_fourier_loss: 2.9177\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5318 - out_loss: 0.1413 - rbf_fourier_loss: 2.9224\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5291 - out_loss: 0.1355 - rbf_fourier_loss: 2.9226\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5262 - out_loss: 0.1314 - rbf_fourier_loss: 2.9211\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5105 - out_loss: 0.1072 - rbf_fourier_loss: 2.9137\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5261 - out_loss: 0.1298 - rbf_fourier_loss: 2.9224\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5129 - out_loss: 0.1077 - rbf_fourier_loss: 2.9182\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5218 - out_loss: 0.1212 - rbf_fourier_loss: 2.9225\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5152 - out_loss: 0.1051 - rbf_fourier_loss: 2.9252\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5139 - out_loss: 0.1033 - rbf_fourier_loss: 2.9246\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5124 - out_loss: 0.1040 - rbf_fourier_loss: 2.9207\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5146 - out_loss: 0.1098 - rbf_fourier_loss: 2.9193\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5308 - out_loss: 0.1397 - rbf_fourier_loss: 2.9219\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5138 - out_loss: 0.1089 - rbf_fourier_loss: 2.9186\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5112 - out_loss: 0.1016 - rbf_fourier_loss: 2.9209\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5223 - out_loss: 0.1293 - rbf_fourier_loss: 2.9153\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5092 - out_loss: 0.1045 - rbf_fourier_loss: 2.9140\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5138 - out_loss: 0.1091 - rbf_fourier_loss: 2.9186\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5233 - out_loss: 0.1215 - rbf_fourier_loss: 2.9252\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5179 - out_loss: 0.1177 - rbf_fourier_loss: 2.9181\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5130 - out_loss: 0.1033 - rbf_fourier_loss: 2.9227\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5055 - out_loss: 0.0913 - rbf_fourier_loss: 2.9198\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5141 - out_loss: 0.1056 - rbf_fourier_loss: 2.9225\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5080 - out_loss: 0.0918 - rbf_fourier_loss: 2.9241\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5126 - out_loss: 0.1093 - rbf_fourier_loss: 2.9159\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5142 - out_loss: 0.1100 - rbf_fourier_loss: 2.9185\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5087 - out_loss: 0.0963 - rbf_fourier_loss: 2.9212\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5045 - out_loss: 0.0883 - rbf_fourier_loss: 2.9208\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4993 - out_loss: 0.0878 - rbf_fourier_loss: 2.9108\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5063 - out_loss: 0.0905 - rbf_fourier_loss: 2.9222\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5072 - out_loss: 0.0910 - rbf_fourier_loss: 2.9233\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5079 - out_loss: 0.0942 - rbf_fourier_loss: 2.9216\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5074 - out_loss: 0.0921 - rbf_fourier_loss: 2.9227\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5015 - out_loss: 0.0840 - rbf_fourier_loss: 2.9189\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5111 - out_loss: 0.1004 - rbf_fourier_loss: 2.9217\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5040 - out_loss: 0.0850 - rbf_fourier_loss: 2.9229\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5099 - out_loss: 0.0971 - rbf_fourier_loss: 2.9228\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5108 - out_loss: 0.0991 - rbf_fourier_loss: 2.9226\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5010 - out_loss: 0.0809 - rbf_fourier_loss: 2.9211\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5034 - out_loss: 0.0862 - rbf_fourier_loss: 2.9205\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5083 - out_loss: 0.0959 - rbf_fourier_loss: 2.9206\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4986 - out_loss: 0.0798 - rbf_fourier_loss: 2.9174\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5058 - out_loss: 0.0906 - rbf_fourier_loss: 2.9210\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5045 - out_loss: 0.0885 - rbf_fourier_loss: 2.9206\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4964 - out_loss: 0.0736 - rbf_fourier_loss: 2.9193\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5009 - out_loss: 0.0850 - rbf_fourier_loss: 2.9169\n",
            "it 1/10\n",
            "acc: 91.77777777777779\n",
            "ari: 69.74800950426022\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 135ms/step - loss: 1.7079 - out_loss: 0.5015 - rbf_fourier_loss: 2.9143\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6663 - out_loss: 0.4226 - rbf_fourier_loss: 2.9099\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6440 - out_loss: 0.3857 - rbf_fourier_loss: 2.9022\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6072 - out_loss: 0.3098 - rbf_fourier_loss: 2.9047\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6079 - out_loss: 0.3080 - rbf_fourier_loss: 2.9078\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5721 - out_loss: 0.2295 - rbf_fourier_loss: 2.9147\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5458 - out_loss: 0.1904 - rbf_fourier_loss: 2.9013\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5355 - out_loss: 0.1696 - rbf_fourier_loss: 2.9014\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5231 - out_loss: 0.1399 - rbf_fourier_loss: 2.9064\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5120 - out_loss: 0.1146 - rbf_fourier_loss: 2.9095\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5116 - out_loss: 0.1012 - rbf_fourier_loss: 2.9221\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5120 - out_loss: 0.1098 - rbf_fourier_loss: 2.9143\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4901 - out_loss: 0.0574 - rbf_fourier_loss: 2.9227\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4734 - out_loss: 0.0376 - rbf_fourier_loss: 2.9092\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4636 - out_loss: 0.0171 - rbf_fourier_loss: 2.9100\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4536 - out_loss: 0.0085 - rbf_fourier_loss: 2.8987\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4544 - out_loss: 0.0095 - rbf_fourier_loss: 2.8993\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4572 - out_loss: 0.0100 - rbf_fourier_loss: 2.9044\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4572 - out_loss: 0.0055 - rbf_fourier_loss: 2.9088\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4635 - out_loss: 0.0050 - rbf_fourier_loss: 2.9220\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4645 - out_loss: 0.0024 - rbf_fourier_loss: 2.9267\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4534 - out_loss: 7.7399e-04 - rbf_fourier_loss: 2.9060\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4528 - out_loss: 0.0014 - rbf_fourier_loss: 2.9042\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4595 - out_loss: 0.0014 - rbf_fourier_loss: 2.9177\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4540 - out_loss: 3.4291e-05 - rbf_fourier_loss: 2.9079\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4621 - out_loss: 2.3617e-05 - rbf_fourier_loss: 2.9242\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4589 - out_loss: 2.4022e-05 - rbf_fourier_loss: 2.9178\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4601 - out_loss: 1.0196e-05 - rbf_fourier_loss: 2.9201\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4572 - out_loss: 7.9560e-06 - rbf_fourier_loss: 2.9144\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4574 - out_loss: 4.2589e-06 - rbf_fourier_loss: 2.9149\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4584 - out_loss: 4.3103e-06 - rbf_fourier_loss: 2.9167\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4456 - out_loss: 2.2557e-06 - rbf_fourier_loss: 2.8912\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4550 - out_loss: 1.6351e-06 - rbf_fourier_loss: 2.9101\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4586 - out_loss: 1.4713e-06 - rbf_fourier_loss: 2.9171\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4528 - out_loss: 8.2177e-07 - rbf_fourier_loss: 2.9057\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4502 - out_loss: 5.4095e-07 - rbf_fourier_loss: 2.9005\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4573 - out_loss: 3.9802e-07 - rbf_fourier_loss: 2.9146\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4610 - out_loss: 3.2096e-07 - rbf_fourier_loss: 2.9221\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4484 - out_loss: 1.7239e-07 - rbf_fourier_loss: 2.8968\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4560 - out_loss: 1.4953e-07 - rbf_fourier_loss: 2.9121\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4501 - out_loss: 9.9859e-08 - rbf_fourier_loss: 2.9002\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4554 - out_loss: 8.1308e-08 - rbf_fourier_loss: 2.9107\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4438 - out_loss: 4.5354e-08 - rbf_fourier_loss: 2.8875\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4586 - out_loss: 4.3197e-08 - rbf_fourier_loss: 2.9173\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4515 - out_loss: 3.5973e-08 - rbf_fourier_loss: 2.9029\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4491 - out_loss: 2.0223e-08 - rbf_fourier_loss: 2.8983\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4524 - out_loss: 1.6358e-08 - rbf_fourier_loss: 2.9049\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4471 - out_loss: 1.8534e-08 - rbf_fourier_loss: 2.8942\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4589 - out_loss: 1.6016e-08 - rbf_fourier_loss: 2.9178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1757eb483eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       history = model.fit(moons, [labels_moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 23\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1108\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_finalize_progbar\u001b[0;34m(self, logs, counter)\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i626vxVDgP-6",
        "colab_type": "text"
      },
      "source": [
        "**mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12BB1GQ0gSSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=10\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-Sjf-nUgSZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/mnistp3' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(ytrain))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_mse(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(Xtrain, [ytrain,Xtrain], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0.3)\n",
        "      [y_pred,_] = model.predict(Xtrain)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,ytraino)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(ytraino,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(ytraino,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(ytraino,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(ytraino,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTtMS8_02E2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'__results'\n",
        "shutil.make_archive(namefile, 'zip', '/content/CKAPRI')\n",
        "files.download(namefile+'.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqFK0MtYhZku",
        "colab_type": "text"
      },
      "source": [
        "**fcosto1 y fcosto2 supervisado con mean Kl divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-R-zQRuhaDB",
        "colab_type": "text"
      },
      "source": [
        "**happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov1JQgRzhaPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=3\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ_NqmP2haZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eebe0a3d-8abe-40be-f42e-9d0075459a16"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/happyp4' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_happy))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(happy.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_kld(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(happy)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_happyo)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_happyo,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_happyo,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_happyo,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_happyo,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 220ms/step - loss: 4.2485 - out_loss: 5.6486 - rbf_fourier_loss: 2.8483\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 3.1122 - out_loss: 3.3909 - rbf_fourier_loss: 2.8336\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.6956 - out_loss: 2.5443 - rbf_fourier_loss: 2.8468\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.3208 - out_loss: 1.8302 - rbf_fourier_loss: 2.8114\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.2184 - out_loss: 1.6164 - rbf_fourier_loss: 2.8203\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9061 - out_loss: 0.9884 - rbf_fourier_loss: 2.8238\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0915 - out_loss: 1.3663 - rbf_fourier_loss: 2.8167\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.8335 - out_loss: 0.8292 - rbf_fourier_loss: 2.8379\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5685 - out_loss: 0.3070 - rbf_fourier_loss: 2.8301\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5101 - out_loss: 0.1918 - rbf_fourier_loss: 2.8285\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4499 - out_loss: 0.0707 - rbf_fourier_loss: 2.8290\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4106 - out_loss: 0.0243 - rbf_fourier_loss: 2.7969\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4258 - out_loss: 0.0147 - rbf_fourier_loss: 2.8368\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4128 - out_loss: 0.0080 - rbf_fourier_loss: 2.8177\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4153 - out_loss: 0.0053 - rbf_fourier_loss: 2.8253\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4215 - out_loss: 0.0023 - rbf_fourier_loss: 2.8408\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4145 - out_loss: 0.0020 - rbf_fourier_loss: 2.8271\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4136 - out_loss: 0.0015 - rbf_fourier_loss: 2.8258\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4126 - out_loss: 0.0014 - rbf_fourier_loss: 2.8238\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4215 - out_loss: 9.6660e-04 - rbf_fourier_loss: 2.8420\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4244 - out_loss: 8.5784e-04 - rbf_fourier_loss: 2.8480\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4073 - out_loss: 7.3181e-04 - rbf_fourier_loss: 2.8138\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4135 - out_loss: 6.7829e-04 - rbf_fourier_loss: 2.8263\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4091 - out_loss: 5.0998e-04 - rbf_fourier_loss: 2.8178\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4189 - out_loss: 4.6587e-04 - rbf_fourier_loss: 2.8374\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4321 - out_loss: 3.1249e-04 - rbf_fourier_loss: 2.8639\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4203 - out_loss: 3.2722e-04 - rbf_fourier_loss: 2.8403\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4125 - out_loss: 2.9359e-04 - rbf_fourier_loss: 2.8248\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4123 - out_loss: 1.8456e-04 - rbf_fourier_loss: 2.8243\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3929 - out_loss: 1.4643e-04 - rbf_fourier_loss: 2.7857\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4192 - out_loss: 9.5823e-05 - rbf_fourier_loss: 2.8384\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4244 - out_loss: 8.8098e-05 - rbf_fourier_loss: 2.8486\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3988 - out_loss: 8.0529e-05 - rbf_fourier_loss: 2.7976\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4221 - out_loss: 6.6711e-05 - rbf_fourier_loss: 2.8441\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4301 - out_loss: 5.0317e-05 - rbf_fourier_loss: 2.8602\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4114 - out_loss: 3.5665e-05 - rbf_fourier_loss: 2.8229\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4176 - out_loss: 3.3216e-05 - rbf_fourier_loss: 2.8352\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4113 - out_loss: 2.1937e-05 - rbf_fourier_loss: 2.8226\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4130 - out_loss: 1.5666e-05 - rbf_fourier_loss: 2.8259\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4235 - out_loss: 1.0394e-05 - rbf_fourier_loss: 2.8470\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4094 - out_loss: 1.0342e-05 - rbf_fourier_loss: 2.8189\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4067 - out_loss: 6.4561e-06 - rbf_fourier_loss: 2.8134\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4256 - out_loss: 4.9080e-06 - rbf_fourier_loss: 2.8511\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4023 - out_loss: 4.6954e-06 - rbf_fourier_loss: 2.8046\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4070 - out_loss: 3.4218e-06 - rbf_fourier_loss: 2.8140\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4019 - out_loss: 2.7077e-06 - rbf_fourier_loss: 2.8038\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4149 - out_loss: 2.0784e-06 - rbf_fourier_loss: 2.8299\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4172 - out_loss: 1.9240e-06 - rbf_fourier_loss: 2.8345\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4251 - out_loss: 1.4177e-06 - rbf_fourier_loss: 2.8501\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4168 - out_loss: 1.0035e-06 - rbf_fourier_loss: 2.8335\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4162 - out_loss: 6.6903e-07 - rbf_fourier_loss: 2.8323\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4211 - out_loss: 5.9699e-07 - rbf_fourier_loss: 2.8422\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4033 - out_loss: 5.2561e-07 - rbf_fourier_loss: 2.8066\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4172 - out_loss: 4.1985e-07 - rbf_fourier_loss: 2.8343\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4243 - out_loss: 2.9913e-07 - rbf_fourier_loss: 2.8485\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4191 - out_loss: 2.6933e-07 - rbf_fourier_loss: 2.8382\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3994 - out_loss: 2.5855e-07 - rbf_fourier_loss: 2.7988\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4151 - out_loss: 1.4731e-07 - rbf_fourier_loss: 2.8303\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4161 - out_loss: 1.1413e-07 - rbf_fourier_loss: 2.8322\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4229 - out_loss: 1.0924e-07 - rbf_fourier_loss: 2.8458\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4248 - out_loss: 9.5100e-08 - rbf_fourier_loss: 2.8497\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4131 - out_loss: 9.3914e-08 - rbf_fourier_loss: 2.8261\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4015 - out_loss: 7.8054e-08 - rbf_fourier_loss: 2.8029\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4116 - out_loss: 7.2038e-08 - rbf_fourier_loss: 2.8231\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4123 - out_loss: 6.4781e-08 - rbf_fourier_loss: 2.8246\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4167 - out_loss: 4.8894e-08 - rbf_fourier_loss: 2.8334\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4102 - out_loss: 4.6251e-08 - rbf_fourier_loss: 2.8205\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4085 - out_loss: 3.3888e-08 - rbf_fourier_loss: 2.8169\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4093 - out_loss: 4.4059e-08 - rbf_fourier_loss: 2.8186\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4137 - out_loss: 3.2470e-08 - rbf_fourier_loss: 2.8274\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4317 - out_loss: 2.8180e-08 - rbf_fourier_loss: 2.8635\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4208 - out_loss: 2.3706e-08 - rbf_fourier_loss: 2.8415\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4028 - out_loss: 1.8884e-08 - rbf_fourier_loss: 2.8055\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4135 - out_loss: 1.9586e-08 - rbf_fourier_loss: 2.8270\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4245 - out_loss: 1.6536e-08 - rbf_fourier_loss: 2.8490\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4201 - out_loss: 1.5899e-08 - rbf_fourier_loss: 2.8403\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4006 - out_loss: 1.8643e-08 - rbf_fourier_loss: 2.8012\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4053 - out_loss: 1.5358e-08 - rbf_fourier_loss: 2.8106\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4091 - out_loss: 1.5324e-08 - rbf_fourier_loss: 2.8181\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4095 - out_loss: 1.3399e-08 - rbf_fourier_loss: 2.8190\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4118 - out_loss: 1.2274e-08 - rbf_fourier_loss: 2.8237\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4041 - out_loss: 1.1539e-08 - rbf_fourier_loss: 2.8082\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4123 - out_loss: 9.5720e-09 - rbf_fourier_loss: 2.8245\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4111 - out_loss: 1.2163e-08 - rbf_fourier_loss: 2.8223\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4116 - out_loss: 1.1875e-08 - rbf_fourier_loss: 2.8232\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4095 - out_loss: 9.4861e-09 - rbf_fourier_loss: 2.8190\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4255 - out_loss: 1.0535e-08 - rbf_fourier_loss: 2.8510\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4216 - out_loss: 8.0121e-09 - rbf_fourier_loss: 2.8431\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4159 - out_loss: 8.0408e-09 - rbf_fourier_loss: 2.8318\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4065 - out_loss: 8.6585e-09 - rbf_fourier_loss: 2.8131\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3973 - out_loss: 8.7296e-09 - rbf_fourier_loss: 2.7946\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4229 - out_loss: 8.4447e-09 - rbf_fourier_loss: 2.8458\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4102 - out_loss: 7.0420e-09 - rbf_fourier_loss: 2.8205\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4078 - out_loss: 6.6910e-09 - rbf_fourier_loss: 2.8156\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4108 - out_loss: 7.6997e-09 - rbf_fourier_loss: 2.8215\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4198 - out_loss: 7.6647e-09 - rbf_fourier_loss: 2.8396\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4258 - out_loss: 8.6197e-09 - rbf_fourier_loss: 2.8517\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4209 - out_loss: 7.4645e-09 - rbf_fourier_loss: 2.8418\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4096 - out_loss: 8.3145e-09 - rbf_fourier_loss: 2.8191\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3934 - out_loss: 7.0152e-09 - rbf_fourier_loss: 2.7868\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 4.7981 - out_loss: 6.9207 - rbf_fourier_loss: 2.6754\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 4.1607 - out_loss: 5.6626 - rbf_fourier_loss: 2.6588\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 3.4417 - out_loss: 4.2227 - rbf_fourier_loss: 2.6606\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.7132 - out_loss: 2.7702 - rbf_fourier_loss: 2.6561\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3194 - out_loss: 1.9633 - rbf_fourier_loss: 2.6754\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.8369 - out_loss: 1.0258 - rbf_fourier_loss: 2.6480\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.6528 - out_loss: 0.6557 - rbf_fourier_loss: 2.6500\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4702 - out_loss: 0.2692 - rbf_fourier_loss: 2.6711\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4060 - out_loss: 0.1392 - rbf_fourier_loss: 2.6728\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3792 - out_loss: 0.0872 - rbf_fourier_loss: 2.6711\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3471 - out_loss: 0.0575 - rbf_fourier_loss: 2.6366\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3644 - out_loss: 0.0585 - rbf_fourier_loss: 2.6703\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3534 - out_loss: 0.0417 - rbf_fourier_loss: 2.6652\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3393 - out_loss: 0.0316 - rbf_fourier_loss: 2.6469\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3359 - out_loss: 0.0227 - rbf_fourier_loss: 2.6492\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3240 - out_loss: 0.0163 - rbf_fourier_loss: 2.6317\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3487 - out_loss: 0.0124 - rbf_fourier_loss: 2.6849\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3359 - out_loss: 0.0081 - rbf_fourier_loss: 2.6636\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3329 - out_loss: 0.0080 - rbf_fourier_loss: 2.6577\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3362 - out_loss: 0.0067 - rbf_fourier_loss: 2.6658\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3387 - out_loss: 0.0057 - rbf_fourier_loss: 2.6717\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3207 - out_loss: 0.0048 - rbf_fourier_loss: 2.6367\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3207 - out_loss: 0.0033 - rbf_fourier_loss: 2.6381\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3374 - out_loss: 0.0037 - rbf_fourier_loss: 2.6711\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3195 - out_loss: 0.0023 - rbf_fourier_loss: 2.6367\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3423 - out_loss: 0.0025 - rbf_fourier_loss: 2.6821\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3347 - out_loss: 0.0012 - rbf_fourier_loss: 2.6682\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3449 - out_loss: 0.0011 - rbf_fourier_loss: 2.6887\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3207 - out_loss: 0.0012 - rbf_fourier_loss: 2.6402\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3318 - out_loss: 8.0557e-04 - rbf_fourier_loss: 2.6628\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3267 - out_loss: 4.5686e-04 - rbf_fourier_loss: 2.6529\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3257 - out_loss: 9.9698e-04 - rbf_fourier_loss: 2.6504\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3370 - out_loss: 3.5423e-04 - rbf_fourier_loss: 2.6737\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3433 - out_loss: 2.6309e-04 - rbf_fourier_loss: 2.6864\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3377 - out_loss: 6.3438e-04 - rbf_fourier_loss: 2.6747\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3238 - out_loss: 2.2773e-04 - rbf_fourier_loss: 2.6473\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3324 - out_loss: 1.6511e-04 - rbf_fourier_loss: 2.6646\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3317 - out_loss: 1.2818e-04 - rbf_fourier_loss: 2.6633\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3247 - out_loss: 1.2305e-04 - rbf_fourier_loss: 2.6493\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3278 - out_loss: 1.0838e-04 - rbf_fourier_loss: 2.6555\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3275 - out_loss: 9.5671e-05 - rbf_fourier_loss: 2.6549\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3223 - out_loss: 8.6921e-05 - rbf_fourier_loss: 2.6446\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3350 - out_loss: 6.1052e-05 - rbf_fourier_loss: 2.6699\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3279 - out_loss: 5.2353e-05 - rbf_fourier_loss: 2.6557\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3441 - out_loss: 3.9702e-05 - rbf_fourier_loss: 2.6881\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3121 - out_loss: 3.2854e-05 - rbf_fourier_loss: 2.6242\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3138 - out_loss: 2.8859e-05 - rbf_fourier_loss: 2.6276\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3280 - out_loss: 2.6665e-05 - rbf_fourier_loss: 2.6559\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3191 - out_loss: 1.7402e-05 - rbf_fourier_loss: 2.6382\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3432 - out_loss: 3.3629e-05 - rbf_fourier_loss: 2.6863\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3276 - out_loss: 1.5205e-05 - rbf_fourier_loss: 2.6552\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3319 - out_loss: 9.2787e-06 - rbf_fourier_loss: 2.6637\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3298 - out_loss: 1.2659e-05 - rbf_fourier_loss: 2.6596\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3273 - out_loss: 7.5239e-06 - rbf_fourier_loss: 2.6545\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3178 - out_loss: 6.2379e-06 - rbf_fourier_loss: 2.6357\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3256 - out_loss: 5.8898e-06 - rbf_fourier_loss: 2.6511\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3450 - out_loss: 3.6957e-06 - rbf_fourier_loss: 2.6900\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3283 - out_loss: 5.9498e-06 - rbf_fourier_loss: 2.6565\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3259 - out_loss: 2.3262e-06 - rbf_fourier_loss: 2.6518\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3302 - out_loss: 2.5011e-06 - rbf_fourier_loss: 2.6605\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3214 - out_loss: 1.7903e-06 - rbf_fourier_loss: 2.6428\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3294 - out_loss: 1.8798e-06 - rbf_fourier_loss: 2.6588\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3133 - out_loss: 1.4367e-06 - rbf_fourier_loss: 2.6266\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3178 - out_loss: 1.8479e-06 - rbf_fourier_loss: 2.6356\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3143 - out_loss: 1.5217e-06 - rbf_fourier_loss: 2.6285\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3237 - out_loss: 1.3297e-06 - rbf_fourier_loss: 2.6474\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3298 - out_loss: 8.2647e-07 - rbf_fourier_loss: 2.6596\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3307 - out_loss: 7.0634e-07 - rbf_fourier_loss: 2.6615\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3263 - out_loss: 7.2213e-07 - rbf_fourier_loss: 2.6526\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3402 - out_loss: 6.0284e-07 - rbf_fourier_loss: 2.6804\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3387 - out_loss: 6.4172e-07 - rbf_fourier_loss: 2.6774\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3262 - out_loss: 3.8076e-07 - rbf_fourier_loss: 2.6524\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3333 - out_loss: 9.3019e-07 - rbf_fourier_loss: 2.6665\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3123 - out_loss: 2.9937e-07 - rbf_fourier_loss: 2.6246\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3288 - out_loss: 3.7242e-07 - rbf_fourier_loss: 2.6575\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3346 - out_loss: 2.7971e-07 - rbf_fourier_loss: 2.6692\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3356 - out_loss: 1.7078e-07 - rbf_fourier_loss: 2.6711\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3316 - out_loss: 2.2298e-07 - rbf_fourier_loss: 2.6631\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3255 - out_loss: 2.0637e-07 - rbf_fourier_loss: 2.6510\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3332 - out_loss: 2.0045e-07 - rbf_fourier_loss: 2.6663\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3257 - out_loss: 1.4254e-07 - rbf_fourier_loss: 2.6514\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3478 - out_loss: 1.5870e-07 - rbf_fourier_loss: 2.6957\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3125 - out_loss: 1.2318e-07 - rbf_fourier_loss: 2.6251\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3377 - out_loss: 2.1881e-07 - rbf_fourier_loss: 2.6753\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3298 - out_loss: 1.1714e-07 - rbf_fourier_loss: 2.6595\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3291 - out_loss: 1.0745e-07 - rbf_fourier_loss: 2.6583\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3239 - out_loss: 9.8215e-08 - rbf_fourier_loss: 2.6478\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3078 - out_loss: 9.8345e-08 - rbf_fourier_loss: 2.6156\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3305 - out_loss: 8.7431e-08 - rbf_fourier_loss: 2.6611\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3471 - out_loss: 7.3064e-08 - rbf_fourier_loss: 2.6941\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3269 - out_loss: 8.1409e-08 - rbf_fourier_loss: 2.6539\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3237 - out_loss: 7.5077e-08 - rbf_fourier_loss: 2.6475\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3091 - out_loss: 9.0468e-08 - rbf_fourier_loss: 2.6182\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3212 - out_loss: 7.1831e-08 - rbf_fourier_loss: 2.6423\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3284 - out_loss: 6.6256e-08 - rbf_fourier_loss: 2.6568\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3330 - out_loss: 7.1303e-08 - rbf_fourier_loss: 2.6660\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3288 - out_loss: 6.5002e-08 - rbf_fourier_loss: 2.6577\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3213 - out_loss: 6.6253e-08 - rbf_fourier_loss: 2.6426\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3351 - out_loss: 6.1308e-08 - rbf_fourier_loss: 2.6703\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3349 - out_loss: 6.0975e-08 - rbf_fourier_loss: 2.6697\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 219ms/step - loss: 4.1389 - out_loss: 5.4504 - rbf_fourier_loss: 2.8275\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.4706 - out_loss: 2.0558 - rbf_fourier_loss: 2.8854\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.7863 - out_loss: 0.7713 - rbf_fourier_loss: 2.8013\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.6496 - out_loss: 0.4660 - rbf_fourier_loss: 2.8332\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5771 - out_loss: 0.3295 - rbf_fourier_loss: 2.8248\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5640 - out_loss: 0.3246 - rbf_fourier_loss: 2.8034\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5196 - out_loss: 0.2289 - rbf_fourier_loss: 2.8104\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5039 - out_loss: 0.1872 - rbf_fourier_loss: 2.8205\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.5068 - out_loss: 0.1941 - rbf_fourier_loss: 2.8195\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4661 - out_loss: 0.1186 - rbf_fourier_loss: 2.8137\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4806 - out_loss: 0.1238 - rbf_fourier_loss: 2.8374\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4659 - out_loss: 0.0891 - rbf_fourier_loss: 2.8427\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4391 - out_loss: 0.0688 - rbf_fourier_loss: 2.8094\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4560 - out_loss: 0.0714 - rbf_fourier_loss: 2.8406\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4439 - out_loss: 0.0492 - rbf_fourier_loss: 2.8387\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4312 - out_loss: 0.0448 - rbf_fourier_loss: 2.8176\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4242 - out_loss: 0.0311 - rbf_fourier_loss: 2.8173\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4335 - out_loss: 0.0357 - rbf_fourier_loss: 2.8313\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4152 - out_loss: 0.0353 - rbf_fourier_loss: 2.7951\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4180 - out_loss: 0.0197 - rbf_fourier_loss: 2.8162\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4300 - out_loss: 0.0185 - rbf_fourier_loss: 2.8415\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4351 - out_loss: 0.0168 - rbf_fourier_loss: 2.8533\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4023 - out_loss: 0.0142 - rbf_fourier_loss: 2.7904\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4143 - out_loss: 0.0120 - rbf_fourier_loss: 2.8167\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4155 - out_loss: 0.0103 - rbf_fourier_loss: 2.8207\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4092 - out_loss: 0.0109 - rbf_fourier_loss: 2.8076\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4088 - out_loss: 0.0080 - rbf_fourier_loss: 2.8096\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4283 - out_loss: 0.0073 - rbf_fourier_loss: 2.8494\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4063 - out_loss: 0.0069 - rbf_fourier_loss: 2.8058\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4245 - out_loss: 0.0046 - rbf_fourier_loss: 2.8444\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3998 - out_loss: 0.0036 - rbf_fourier_loss: 2.7961\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4215 - out_loss: 0.0037 - rbf_fourier_loss: 2.8392\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4199 - out_loss: 0.0030 - rbf_fourier_loss: 2.8369\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4025 - out_loss: 0.0039 - rbf_fourier_loss: 2.8012\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4057 - out_loss: 0.0023 - rbf_fourier_loss: 2.8092\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3819 - out_loss: 0.0021 - rbf_fourier_loss: 2.7617\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4204 - out_loss: 0.0021 - rbf_fourier_loss: 2.8388\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4113 - out_loss: 0.0054 - rbf_fourier_loss: 2.8172\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3985 - out_loss: 0.0013 - rbf_fourier_loss: 2.7957\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4167 - out_loss: 0.0014 - rbf_fourier_loss: 2.8321\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4035 - out_loss: 0.0014 - rbf_fourier_loss: 2.8056\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4129 - out_loss: 0.0010 - rbf_fourier_loss: 2.8249\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4191 - out_loss: 0.0010 - rbf_fourier_loss: 2.8372\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4014 - out_loss: 9.7430e-04 - rbf_fourier_loss: 2.8017\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4157 - out_loss: 8.3525e-04 - rbf_fourier_loss: 2.8305\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4073 - out_loss: 7.8446e-04 - rbf_fourier_loss: 2.8138\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4231 - out_loss: 0.0035 - rbf_fourier_loss: 2.8426\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4063 - out_loss: 6.0062e-04 - rbf_fourier_loss: 2.8121\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4080 - out_loss: 5.7661e-04 - rbf_fourier_loss: 2.8154\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4287 - out_loss: 3.9821e-04 - rbf_fourier_loss: 2.8571\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4173 - out_loss: 0.0029 - rbf_fourier_loss: 2.8317\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4015 - out_loss: 4.4283e-04 - rbf_fourier_loss: 2.8026\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4136 - out_loss: 3.5863e-04 - rbf_fourier_loss: 2.8268\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4159 - out_loss: 4.1190e-04 - rbf_fourier_loss: 2.8314\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4027 - out_loss: 3.8881e-04 - rbf_fourier_loss: 2.8051\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4192 - out_loss: 3.2162e-04 - rbf_fourier_loss: 2.8381\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3925 - out_loss: 2.6032e-04 - rbf_fourier_loss: 2.7847\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4224 - out_loss: 5.0974e-04 - rbf_fourier_loss: 2.8443\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4257 - out_loss: 7.5963e-04 - rbf_fourier_loss: 2.8507\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4079 - out_loss: 2.2219e-04 - rbf_fourier_loss: 2.8156\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4104 - out_loss: 2.3505e-04 - rbf_fourier_loss: 2.8207\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4118 - out_loss: 2.2287e-04 - rbf_fourier_loss: 2.8233\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4197 - out_loss: 1.9364e-04 - rbf_fourier_loss: 2.8391\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4052 - out_loss: 1.5997e-04 - rbf_fourier_loss: 2.8102\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4183 - out_loss: 1.9623e-04 - rbf_fourier_loss: 2.8365\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4164 - out_loss: 1.1308e-04 - rbf_fourier_loss: 2.8326\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4309 - out_loss: 2.4535e-04 - rbf_fourier_loss: 2.8615\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4126 - out_loss: 1.8398e-04 - rbf_fourier_loss: 2.8250\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4080 - out_loss: 1.0508e-04 - rbf_fourier_loss: 2.8159\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4304 - out_loss: 6.2147e-04 - rbf_fourier_loss: 2.8602\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4125 - out_loss: 1.1903e-04 - rbf_fourier_loss: 2.8250\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4091 - out_loss: 8.4894e-05 - rbf_fourier_loss: 2.8181\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4024 - out_loss: 8.5033e-05 - rbf_fourier_loss: 2.8048\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4138 - out_loss: 2.6575e-04 - rbf_fourier_loss: 2.8274\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4187 - out_loss: 7.3344e-05 - rbf_fourier_loss: 2.8373\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3984 - out_loss: 5.8039e-05 - rbf_fourier_loss: 2.7967\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3990 - out_loss: 5.9512e-05 - rbf_fourier_loss: 2.7980\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4120 - out_loss: 5.9793e-05 - rbf_fourier_loss: 2.8240\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4148 - out_loss: 4.0750e-05 - rbf_fourier_loss: 2.8296\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4107 - out_loss: 4.9668e-05 - rbf_fourier_loss: 2.8213\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4249 - out_loss: 6.3558e-05 - rbf_fourier_loss: 2.8497\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4143 - out_loss: 3.6256e-05 - rbf_fourier_loss: 2.8285\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4114 - out_loss: 3.9650e-05 - rbf_fourier_loss: 2.8227\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4186 - out_loss: 5.8781e-05 - rbf_fourier_loss: 2.8370\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4255 - out_loss: 4.0215e-05 - rbf_fourier_loss: 2.8510\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4204 - out_loss: 5.8769e-05 - rbf_fourier_loss: 2.8408\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4068 - out_loss: 2.0373e-05 - rbf_fourier_loss: 2.8137\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4073 - out_loss: 2.0524e-05 - rbf_fourier_loss: 2.8145\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.3999 - out_loss: 2.3700e-05 - rbf_fourier_loss: 2.7997\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4009 - out_loss: 2.0039e-05 - rbf_fourier_loss: 2.8017\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4088 - out_loss: 2.2008e-05 - rbf_fourier_loss: 2.8175\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4085 - out_loss: 2.4166e-05 - rbf_fourier_loss: 2.8169\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4136 - out_loss: 1.7462e-05 - rbf_fourier_loss: 2.8273\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4050 - out_loss: 1.2187e-05 - rbf_fourier_loss: 2.8100\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4168 - out_loss: 1.4353e-05 - rbf_fourier_loss: 2.8336\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4248 - out_loss: 1.2929e-05 - rbf_fourier_loss: 2.8496\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4003 - out_loss: 1.1302e-05 - rbf_fourier_loss: 2.8005\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4096 - out_loss: 1.1225e-05 - rbf_fourier_loss: 2.8191\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4155 - out_loss: 8.4673e-06 - rbf_fourier_loss: 2.8309\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4077 - out_loss: 1.1592e-05 - rbf_fourier_loss: 2.8154\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-52a23628197b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       history = model.fit(happy, [labels_happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 24\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhappy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 _r=1):\n\u001b[1;32m   1067\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    715\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    716\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 717\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2955\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2956\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3333\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3334\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3186\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3188\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 ))\n\u001b[1;32m    972\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    769\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1259\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1260\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2794\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    726\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m--> 728\u001b[0;31m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0m\u001b[1;32m    729\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_metric_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mloss_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, values, sample_weight)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mvalue_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_sum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mupdate_total_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m# Exit early if the reduction doesn't have a denominator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\n\u001b[0;32m--> 850\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m           name=name)\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyqIYB-Fh0zw",
        "colab_type": "text"
      },
      "source": [
        "**Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQSX5SmRiVyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=2\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl8BYBMpiV7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccf62d44-4258-4931-b17f-4f605bfbb717"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/moonsp4' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_moonso))\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(moons.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_kld(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(moons, [labels_moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(moons)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_moonso)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_moonso,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_moonso,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_moonso,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_moonso,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 139ms/step - loss: 3.2996 - out_loss: 3.6769 - rbf_fourier_loss: 2.9224\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0758 - out_loss: 3.2283 - rbf_fourier_loss: 2.9232\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8356 - out_loss: 2.7509 - rbf_fourier_loss: 2.9204\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8412 - out_loss: 2.7593 - rbf_fourier_loss: 2.9231\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7750 - out_loss: 2.6259 - rbf_fourier_loss: 2.9241\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7132 - out_loss: 2.5025 - rbf_fourier_loss: 2.9240\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5486 - out_loss: 2.1790 - rbf_fourier_loss: 2.9183\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.6178 - out_loss: 2.3153 - rbf_fourier_loss: 2.9202\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4792 - out_loss: 2.0344 - rbf_fourier_loss: 2.9241\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4469 - out_loss: 1.9726 - rbf_fourier_loss: 2.9212\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3215 - out_loss: 1.7211 - rbf_fourier_loss: 2.9219\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4000 - out_loss: 1.8787 - rbf_fourier_loss: 2.9213\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2761 - out_loss: 1.6409 - rbf_fourier_loss: 2.9114\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3160 - out_loss: 1.7146 - rbf_fourier_loss: 2.9173\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1957 - out_loss: 1.4701 - rbf_fourier_loss: 2.9212\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1133 - out_loss: 1.3054 - rbf_fourier_loss: 2.9212\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1609 - out_loss: 1.3978 - rbf_fourier_loss: 2.9240\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1479 - out_loss: 1.3751 - rbf_fourier_loss: 2.9208\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0689 - out_loss: 1.2183 - rbf_fourier_loss: 2.9194\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9783 - out_loss: 1.0373 - rbf_fourier_loss: 2.9194\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9195 - out_loss: 0.9193 - rbf_fourier_loss: 2.9198\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9344 - out_loss: 0.9622 - rbf_fourier_loss: 2.9067\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9703 - out_loss: 1.0198 - rbf_fourier_loss: 2.9208\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8894 - out_loss: 0.8572 - rbf_fourier_loss: 2.9216\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8161 - out_loss: 0.7161 - rbf_fourier_loss: 2.9161\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8673 - out_loss: 0.8150 - rbf_fourier_loss: 2.9196\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7739 - out_loss: 0.6273 - rbf_fourier_loss: 2.9205\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7983 - out_loss: 0.6760 - rbf_fourier_loss: 2.9206\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7112 - out_loss: 0.4995 - rbf_fourier_loss: 2.9229\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7771 - out_loss: 0.6297 - rbf_fourier_loss: 2.9245\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7115 - out_loss: 0.5038 - rbf_fourier_loss: 2.9192\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6516 - out_loss: 0.3843 - rbf_fourier_loss: 2.9188\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6887 - out_loss: 0.4541 - rbf_fourier_loss: 2.9232\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6786 - out_loss: 0.4389 - rbf_fourier_loss: 2.9182\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6797 - out_loss: 0.4352 - rbf_fourier_loss: 2.9243\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6920 - out_loss: 0.4618 - rbf_fourier_loss: 2.9222\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6418 - out_loss: 0.3644 - rbf_fourier_loss: 2.9191\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6240 - out_loss: 0.3256 - rbf_fourier_loss: 2.9225\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5648 - out_loss: 0.2065 - rbf_fourier_loss: 2.9231\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5652 - out_loss: 0.2078 - rbf_fourier_loss: 2.9225\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5590 - out_loss: 0.1956 - rbf_fourier_loss: 2.9225\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5346 - out_loss: 0.1553 - rbf_fourier_loss: 2.9139\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5449 - out_loss: 0.1712 - rbf_fourier_loss: 2.9185\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5216 - out_loss: 0.1208 - rbf_fourier_loss: 2.9225\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5187 - out_loss: 0.1191 - rbf_fourier_loss: 2.9183\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5144 - out_loss: 0.1074 - rbf_fourier_loss: 2.9214\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5128 - out_loss: 0.1009 - rbf_fourier_loss: 2.9247\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5087 - out_loss: 0.0949 - rbf_fourier_loss: 2.9225\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5133 - out_loss: 0.1020 - rbf_fourier_loss: 2.9246\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5081 - out_loss: 0.0914 - rbf_fourier_loss: 2.9247\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5081 - out_loss: 0.0932 - rbf_fourier_loss: 2.9231\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5013 - out_loss: 0.0811 - rbf_fourier_loss: 2.9215\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5024 - out_loss: 0.0904 - rbf_fourier_loss: 2.9144\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4999 - out_loss: 0.0790 - rbf_fourier_loss: 2.9208\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5048 - out_loss: 0.0858 - rbf_fourier_loss: 2.9238\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5013 - out_loss: 0.0798 - rbf_fourier_loss: 2.9228\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4983 - out_loss: 0.0745 - rbf_fourier_loss: 2.9220\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5016 - out_loss: 0.0793 - rbf_fourier_loss: 2.9239\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4931 - out_loss: 0.0635 - rbf_fourier_loss: 2.9227\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4879 - out_loss: 0.0549 - rbf_fourier_loss: 2.9209\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4893 - out_loss: 0.0562 - rbf_fourier_loss: 2.9225\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4838 - out_loss: 0.0452 - rbf_fourier_loss: 2.9224\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4811 - out_loss: 0.0476 - rbf_fourier_loss: 2.9147\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4828 - out_loss: 0.0470 - rbf_fourier_loss: 2.9185\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4813 - out_loss: 0.0403 - rbf_fourier_loss: 2.9224\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4791 - out_loss: 0.0378 - rbf_fourier_loss: 2.9203\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4809 - out_loss: 0.0435 - rbf_fourier_loss: 2.9183\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4862 - out_loss: 0.0485 - rbf_fourier_loss: 2.9239\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4840 - out_loss: 0.0474 - rbf_fourier_loss: 2.9205\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4840 - out_loss: 0.0464 - rbf_fourier_loss: 2.9216\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4823 - out_loss: 0.0424 - rbf_fourier_loss: 2.9221\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4838 - out_loss: 0.0426 - rbf_fourier_loss: 2.9250\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4764 - out_loss: 0.0337 - rbf_fourier_loss: 2.9191\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4818 - out_loss: 0.0384 - rbf_fourier_loss: 2.9252\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4751 - out_loss: 0.0369 - rbf_fourier_loss: 2.9132\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4795 - out_loss: 0.0364 - rbf_fourier_loss: 2.9225\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4781 - out_loss: 0.0318 - rbf_fourier_loss: 2.9244\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4760 - out_loss: 0.0337 - rbf_fourier_loss: 2.9184\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4766 - out_loss: 0.0310 - rbf_fourier_loss: 2.9221\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4761 - out_loss: 0.0311 - rbf_fourier_loss: 2.9211\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4758 - out_loss: 0.0304 - rbf_fourier_loss: 2.9213\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4726 - out_loss: 0.0261 - rbf_fourier_loss: 2.9191\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4738 - out_loss: 0.0241 - rbf_fourier_loss: 2.9236\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4721 - out_loss: 0.0260 - rbf_fourier_loss: 2.9181\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4728 - out_loss: 0.0269 - rbf_fourier_loss: 2.9187\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4707 - out_loss: 0.0227 - rbf_fourier_loss: 2.9186\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4731 - out_loss: 0.0225 - rbf_fourier_loss: 2.9237\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4698 - out_loss: 0.0233 - rbf_fourier_loss: 2.9163\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4718 - out_loss: 0.0229 - rbf_fourier_loss: 2.9206\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4723 - out_loss: 0.0209 - rbf_fourier_loss: 2.9238\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4676 - out_loss: 0.0200 - rbf_fourier_loss: 2.9151\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4700 - out_loss: 0.0196 - rbf_fourier_loss: 2.9204\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4711 - out_loss: 0.0208 - rbf_fourier_loss: 2.9214\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4668 - out_loss: 0.0207 - rbf_fourier_loss: 2.9129\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4722 - out_loss: 0.0187 - rbf_fourier_loss: 2.9257\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4706 - out_loss: 0.0190 - rbf_fourier_loss: 2.9222\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4716 - out_loss: 0.0193 - rbf_fourier_loss: 2.9239\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4696 - out_loss: 0.0188 - rbf_fourier_loss: 2.9205\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4703 - out_loss: 0.0178 - rbf_fourier_loss: 2.9228\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4673 - out_loss: 0.0163 - rbf_fourier_loss: 2.9183\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 137ms/step - loss: 4.5054 - out_loss: 6.1097 - rbf_fourier_loss: 2.9011\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4067 - out_loss: 3.9054 - rbf_fourier_loss: 2.9081\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8253 - out_loss: 2.7403 - rbf_fourier_loss: 2.9103\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7018 - out_loss: 2.4784 - rbf_fourier_loss: 2.9253\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3434 - out_loss: 1.7815 - rbf_fourier_loss: 2.9052\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0801 - out_loss: 1.2306 - rbf_fourier_loss: 2.9297\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8922 - out_loss: 0.8817 - rbf_fourier_loss: 2.9027\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6671 - out_loss: 0.4404 - rbf_fourier_loss: 2.8937\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5900 - out_loss: 0.2799 - rbf_fourier_loss: 2.9002\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5218 - out_loss: 0.1400 - rbf_fourier_loss: 2.9036\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5073 - out_loss: 0.0947 - rbf_fourier_loss: 2.9198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c9e617c3d0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       history = model.fit(moons, [labels_moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 23\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1055\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \"\"\"\n\u001b[1;32m   1610\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   def train_on_batch(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3582\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3583\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3584\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3585\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3586\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    886\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[1;32m    887\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcg9FWaEiWbU",
        "colab_type": "text"
      },
      "source": [
        "**mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81qogDguiWq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=10\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSY-MgaLiW0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/mnistp4' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(ytrain))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_kld(),custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(Xtrain, [ytrain,Xtrain], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0.3)\n",
        "      [y_pred,_] = model.predict(Xtrain)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,ytraino)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(ytraino,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(ytraino,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(ytraino,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(ytraino,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITU9IGS82Jjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'__results'\n",
        "shutil.make_archive(namefile, 'zip', '/content/CKAPRI')\n",
        "files.download(namefile+'.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3B22YwjUGp",
        "colab_type": "text"
      },
      "source": [
        "**Funcion fcosto1 y fcosto2 no supervisado**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kop5NJcHjUSl",
        "colab_type": "text"
      },
      "source": [
        "**happy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9afWEMMjm_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=3\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGisM-qmjnH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e29e73c1-d18a-467e-e874-c917118b0f61"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/happyp5' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_happy))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(happy.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl( lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(happy, [happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(happy)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_happyo)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_happyo,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_happyo,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_happyo,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_happyo,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 2.3856 - out_loss: 2.7959 - rbf_fourier_loss: 1.9753\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2905 - out_loss: 2.5744 - rbf_fourier_loss: 2.0066\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3003 - out_loss: 2.6142 - rbf_fourier_loss: 1.9863\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2878 - out_loss: 2.6026 - rbf_fourier_loss: 1.9731\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.2594 - out_loss: 2.5416 - rbf_fourier_loss: 1.9772\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2960 - out_loss: 2.6420 - rbf_fourier_loss: 1.9500\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2224 - out_loss: 2.4914 - rbf_fourier_loss: 1.9535\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.1550 - out_loss: 2.3294 - rbf_fourier_loss: 1.9806\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0484 - out_loss: 2.1144 - rbf_fourier_loss: 1.9824\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0508 - out_loss: 2.1267 - rbf_fourier_loss: 1.9749\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0585 - out_loss: 2.1481 - rbf_fourier_loss: 1.9689\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0861 - out_loss: 2.1642 - rbf_fourier_loss: 2.0079\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0425 - out_loss: 2.1128 - rbf_fourier_loss: 1.9722\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0194 - out_loss: 2.0822 - rbf_fourier_loss: 1.9566\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0401 - out_loss: 2.1020 - rbf_fourier_loss: 1.9782\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0679 - out_loss: 2.1457 - rbf_fourier_loss: 1.9902\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0456 - out_loss: 2.1105 - rbf_fourier_loss: 1.9806\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0556 - out_loss: 2.1210 - rbf_fourier_loss: 1.9902\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0344 - out_loss: 2.1054 - rbf_fourier_loss: 1.9633\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0242 - out_loss: 2.0901 - rbf_fourier_loss: 1.9583\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0137 - out_loss: 2.0626 - rbf_fourier_loss: 1.9647\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0274 - out_loss: 2.0756 - rbf_fourier_loss: 1.9792\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0211 - out_loss: 2.0591 - rbf_fourier_loss: 1.9830\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0358 - out_loss: 2.0793 - rbf_fourier_loss: 1.9923\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0287 - out_loss: 2.0574 - rbf_fourier_loss: 2.0001\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9971 - out_loss: 2.0143 - rbf_fourier_loss: 1.9799\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0080 - out_loss: 2.0299 - rbf_fourier_loss: 1.9861\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9933 - out_loss: 2.0176 - rbf_fourier_loss: 1.9691\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9881 - out_loss: 2.0008 - rbf_fourier_loss: 1.9754\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9863 - out_loss: 2.0055 - rbf_fourier_loss: 1.9671\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9949 - out_loss: 2.0260 - rbf_fourier_loss: 1.9639\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9931 - out_loss: 2.0126 - rbf_fourier_loss: 1.9736\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9977 - out_loss: 2.0130 - rbf_fourier_loss: 1.9824\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0151 - out_loss: 2.0320 - rbf_fourier_loss: 1.9982\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0171 - out_loss: 2.0431 - rbf_fourier_loss: 1.9911\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9857 - out_loss: 2.0003 - rbf_fourier_loss: 1.9711\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9905 - out_loss: 2.0145 - rbf_fourier_loss: 1.9664\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0276 - out_loss: 2.0481 - rbf_fourier_loss: 2.0070\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9737 - out_loss: 1.9956 - rbf_fourier_loss: 1.9519\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9714 - out_loss: 1.9844 - rbf_fourier_loss: 1.9584\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0415 - out_loss: 2.0734 - rbf_fourier_loss: 2.0096\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0168 - out_loss: 2.0412 - rbf_fourier_loss: 1.9923\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9815 - out_loss: 1.9976 - rbf_fourier_loss: 1.9655\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9890 - out_loss: 2.0059 - rbf_fourier_loss: 1.9720\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0062 - out_loss: 2.0159 - rbf_fourier_loss: 1.9965\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0175 - out_loss: 2.0417 - rbf_fourier_loss: 1.9932\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0091 - out_loss: 2.0332 - rbf_fourier_loss: 1.9851\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0057 - out_loss: 2.0275 - rbf_fourier_loss: 1.9839\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9785 - out_loss: 1.9944 - rbf_fourier_loss: 1.9625\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9798 - out_loss: 1.9984 - rbf_fourier_loss: 1.9612\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9789 - out_loss: 2.0044 - rbf_fourier_loss: 1.9534\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9996 - out_loss: 2.0121 - rbf_fourier_loss: 1.9872\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9910 - out_loss: 2.0064 - rbf_fourier_loss: 1.9756\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9608 - out_loss: 1.9813 - rbf_fourier_loss: 1.9404\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9988 - out_loss: 2.0157 - rbf_fourier_loss: 1.9819\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9901 - out_loss: 2.0046 - rbf_fourier_loss: 1.9755\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0108 - out_loss: 2.0234 - rbf_fourier_loss: 1.9982\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9745 - out_loss: 1.9883 - rbf_fourier_loss: 1.9607\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9853 - out_loss: 1.9965 - rbf_fourier_loss: 1.9740\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0018 - out_loss: 2.0139 - rbf_fourier_loss: 1.9896\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9941 - out_loss: 2.0067 - rbf_fourier_loss: 1.9815\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0299 - out_loss: 2.0456 - rbf_fourier_loss: 2.0142\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0047 - out_loss: 2.0197 - rbf_fourier_loss: 1.9897\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9973 - out_loss: 2.0253 - rbf_fourier_loss: 1.9693\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0287 - out_loss: 2.0415 - rbf_fourier_loss: 2.0158\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0106 - out_loss: 2.0331 - rbf_fourier_loss: 1.9882\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0227 - out_loss: 2.0394 - rbf_fourier_loss: 2.0060\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9771 - out_loss: 1.9997 - rbf_fourier_loss: 1.9545\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9786 - out_loss: 1.9985 - rbf_fourier_loss: 1.9588\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9877 - out_loss: 2.0027 - rbf_fourier_loss: 1.9728\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9768 - out_loss: 1.9945 - rbf_fourier_loss: 1.9592\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0226 - out_loss: 2.0457 - rbf_fourier_loss: 1.9996\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9993 - out_loss: 2.0226 - rbf_fourier_loss: 1.9760\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9923 - out_loss: 2.0062 - rbf_fourier_loss: 1.9784\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9965 - out_loss: 2.0128 - rbf_fourier_loss: 1.9801\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0113 - out_loss: 2.0298 - rbf_fourier_loss: 1.9929\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9935 - out_loss: 2.0144 - rbf_fourier_loss: 1.9727\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0030 - out_loss: 2.0156 - rbf_fourier_loss: 1.9903\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0054 - out_loss: 2.0201 - rbf_fourier_loss: 1.9906\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9811 - out_loss: 2.0016 - rbf_fourier_loss: 1.9606\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9999 - out_loss: 2.0069 - rbf_fourier_loss: 1.9929\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9648 - out_loss: 1.9917 - rbf_fourier_loss: 1.9379\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9849 - out_loss: 1.9957 - rbf_fourier_loss: 1.9741\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0039 - out_loss: 2.0335 - rbf_fourier_loss: 1.9743\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0009 - out_loss: 2.0155 - rbf_fourier_loss: 1.9863\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9701 - out_loss: 1.9866 - rbf_fourier_loss: 1.9537\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0207 - out_loss: 2.0357 - rbf_fourier_loss: 2.0056\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0095 - out_loss: 2.0274 - rbf_fourier_loss: 1.9916\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9852 - out_loss: 1.9977 - rbf_fourier_loss: 1.9728\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9852 - out_loss: 2.0014 - rbf_fourier_loss: 1.9689\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0082 - out_loss: 2.0310 - rbf_fourier_loss: 1.9853\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0056 - out_loss: 2.0246 - rbf_fourier_loss: 1.9865\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9839 - out_loss: 2.0046 - rbf_fourier_loss: 1.9633\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9987 - out_loss: 2.0162 - rbf_fourier_loss: 1.9813\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0260 - out_loss: 2.0428 - rbf_fourier_loss: 2.0091\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0181 - out_loss: 2.0387 - rbf_fourier_loss: 1.9975\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.9848 - out_loss: 1.9904 - rbf_fourier_loss: 1.9793\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0024 - out_loss: 2.0191 - rbf_fourier_loss: 1.9856\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9859 - out_loss: 2.0006 - rbf_fourier_loss: 1.9713\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0187 - out_loss: 2.0374 - rbf_fourier_loss: 1.9999\n",
            "it 1/10\n",
            "acc: 100.0\n",
            "ari: 100.0\n",
            "it 1/10\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-93a753973618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       history = model.fit(happy, [happy,happy], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 24\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhappy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 _r=1):\n\u001b[1;32m   1067\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2927\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2929\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, flat_args, flat_kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     ],\n\u001b[1;32m   1859\u001b[0m                            \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                            cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1934\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1936\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1937\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1938\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    554\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqb0x1DOjnWQ",
        "colab_type": "text"
      },
      "source": [
        "**Moons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkPBxcKTjpoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=2\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGNxpZ-bjpwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2cecabd-8ba8-4b6d-9a41-5feb6e3ef03a"
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/moonsp5' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(labels_moonso))\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(moons.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl( lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(moons, [moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0)\n",
        "      [y_pred,_] = model.predict(moons)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,labels_moonso)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(labels_moonso,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(labels_moonso,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(labels_moonso,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(labels_moonso,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it 1/10\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 3.5411 - out_loss: 4.0309 - rbf_fourier_loss: 3.0513\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5447 - out_loss: 4.0094 - rbf_fourier_loss: 3.0800\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4875 - out_loss: 3.9328 - rbf_fourier_loss: 3.0421\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4993 - out_loss: 3.9520 - rbf_fourier_loss: 3.0466\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4879 - out_loss: 3.9345 - rbf_fourier_loss: 3.0412\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4888 - out_loss: 3.9330 - rbf_fourier_loss: 3.0446\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4984 - out_loss: 3.9394 - rbf_fourier_loss: 3.0574\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4778 - out_loss: 3.9323 - rbf_fourier_loss: 3.0234\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4883 - out_loss: 3.9379 - rbf_fourier_loss: 3.0387\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5111 - out_loss: 3.9615 - rbf_fourier_loss: 3.0606\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5065 - out_loss: 3.9587 - rbf_fourier_loss: 3.0544\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5055 - out_loss: 3.9533 - rbf_fourier_loss: 3.0577\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4811 - out_loss: 3.9403 - rbf_fourier_loss: 3.0218\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4991 - out_loss: 3.9356 - rbf_fourier_loss: 3.0625\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4755 - out_loss: 3.9248 - rbf_fourier_loss: 3.0263\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4799 - out_loss: 3.9459 - rbf_fourier_loss: 3.0140\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4979 - out_loss: 3.9537 - rbf_fourier_loss: 3.0421\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5046 - out_loss: 3.9450 - rbf_fourier_loss: 3.0643\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5302 - out_loss: 3.9866 - rbf_fourier_loss: 3.0737\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5277 - out_loss: 3.9885 - rbf_fourier_loss: 3.0669\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5182 - out_loss: 3.9680 - rbf_fourier_loss: 3.0683\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4709 - out_loss: 3.9025 - rbf_fourier_loss: 3.0393\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5268 - out_loss: 4.0002 - rbf_fourier_loss: 3.0534\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4856 - out_loss: 3.9253 - rbf_fourier_loss: 3.0459\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4823 - out_loss: 3.9251 - rbf_fourier_loss: 3.0395\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4820 - out_loss: 3.9227 - rbf_fourier_loss: 3.0413\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5066 - out_loss: 3.9502 - rbf_fourier_loss: 3.0630\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5193 - out_loss: 3.9700 - rbf_fourier_loss: 3.0686\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5255 - out_loss: 3.9822 - rbf_fourier_loss: 3.0687\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4658 - out_loss: 3.9097 - rbf_fourier_loss: 3.0220\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4613 - out_loss: 3.8910 - rbf_fourier_loss: 3.0316\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4763 - out_loss: 3.9155 - rbf_fourier_loss: 3.0372\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4879 - out_loss: 3.9349 - rbf_fourier_loss: 3.0408\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5233 - out_loss: 3.9686 - rbf_fourier_loss: 3.0780\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4857 - out_loss: 3.9122 - rbf_fourier_loss: 3.0593\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4880 - out_loss: 3.9365 - rbf_fourier_loss: 3.0395\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4980 - out_loss: 3.9286 - rbf_fourier_loss: 3.0673\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4803 - out_loss: 3.9151 - rbf_fourier_loss: 3.0456\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5159 - out_loss: 3.9563 - rbf_fourier_loss: 3.0756\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5033 - out_loss: 3.9470 - rbf_fourier_loss: 3.0596\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5157 - out_loss: 3.9633 - rbf_fourier_loss: 3.0681\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4705 - out_loss: 3.9185 - rbf_fourier_loss: 3.0226\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4825 - out_loss: 3.9033 - rbf_fourier_loss: 3.0618\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4788 - out_loss: 3.9237 - rbf_fourier_loss: 3.0340\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4592 - out_loss: 3.8898 - rbf_fourier_loss: 3.0286\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4605 - out_loss: 3.8954 - rbf_fourier_loss: 3.0256\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4816 - out_loss: 3.9086 - rbf_fourier_loss: 3.0545\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4810 - out_loss: 3.9094 - rbf_fourier_loss: 3.0526\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4864 - out_loss: 3.9150 - rbf_fourier_loss: 3.0578\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4790 - out_loss: 3.9313 - rbf_fourier_loss: 3.0267\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4779 - out_loss: 3.9177 - rbf_fourier_loss: 3.0381\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4720 - out_loss: 3.9143 - rbf_fourier_loss: 3.0297\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5116 - out_loss: 3.9672 - rbf_fourier_loss: 3.0560\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5150 - out_loss: 3.9716 - rbf_fourier_loss: 3.0584\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5186 - out_loss: 3.9699 - rbf_fourier_loss: 3.0674\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5048 - out_loss: 3.9479 - rbf_fourier_loss: 3.0617\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5004 - out_loss: 3.9403 - rbf_fourier_loss: 3.0605\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4740 - out_loss: 3.9211 - rbf_fourier_loss: 3.0269\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4965 - out_loss: 3.9217 - rbf_fourier_loss: 3.0713\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5018 - out_loss: 3.9514 - rbf_fourier_loss: 3.0523\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4660 - out_loss: 3.8981 - rbf_fourier_loss: 3.0339\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4776 - out_loss: 3.9158 - rbf_fourier_loss: 3.0393\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5024 - out_loss: 3.9776 - rbf_fourier_loss: 3.0273\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4705 - out_loss: 3.9022 - rbf_fourier_loss: 3.0388\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4900 - out_loss: 3.9300 - rbf_fourier_loss: 3.0501\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4849 - out_loss: 3.9225 - rbf_fourier_loss: 3.0473\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4921 - out_loss: 3.9394 - rbf_fourier_loss: 3.0448\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5012 - out_loss: 3.9327 - rbf_fourier_loss: 3.0696\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4871 - out_loss: 3.9353 - rbf_fourier_loss: 3.0389\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4955 - out_loss: 3.9449 - rbf_fourier_loss: 3.0461\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4896 - out_loss: 3.9412 - rbf_fourier_loss: 3.0380\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5095 - out_loss: 3.9672 - rbf_fourier_loss: 3.0519\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4817 - out_loss: 3.9234 - rbf_fourier_loss: 3.0401\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4848 - out_loss: 3.9248 - rbf_fourier_loss: 3.0448\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5209 - out_loss: 3.9672 - rbf_fourier_loss: 3.0746\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4664 - out_loss: 3.8846 - rbf_fourier_loss: 3.0482\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5050 - out_loss: 3.9505 - rbf_fourier_loss: 3.0596\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5259 - out_loss: 3.9791 - rbf_fourier_loss: 3.0727\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4979 - out_loss: 3.9400 - rbf_fourier_loss: 3.0558\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4788 - out_loss: 3.9098 - rbf_fourier_loss: 3.0477\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4936 - out_loss: 3.9337 - rbf_fourier_loss: 3.0535\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5113 - out_loss: 3.9490 - rbf_fourier_loss: 3.0736\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4785 - out_loss: 3.9105 - rbf_fourier_loss: 3.0465\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5146 - out_loss: 3.9666 - rbf_fourier_loss: 3.0626\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4773 - out_loss: 3.9170 - rbf_fourier_loss: 3.0376\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4740 - out_loss: 3.9125 - rbf_fourier_loss: 3.0355\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4978 - out_loss: 3.9384 - rbf_fourier_loss: 3.0572\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4712 - out_loss: 3.9031 - rbf_fourier_loss: 3.0393\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4873 - out_loss: 3.9210 - rbf_fourier_loss: 3.0536\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4796 - out_loss: 3.9046 - rbf_fourier_loss: 3.0545\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5227 - out_loss: 3.9732 - rbf_fourier_loss: 3.0722\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4861 - out_loss: 3.9183 - rbf_fourier_loss: 3.0539\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4947 - out_loss: 3.9364 - rbf_fourier_loss: 3.0531\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4742 - out_loss: 3.9165 - rbf_fourier_loss: 3.0318\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4642 - out_loss: 3.9090 - rbf_fourier_loss: 3.0193\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4597 - out_loss: 3.8824 - rbf_fourier_loss: 3.0369\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4922 - out_loss: 3.9416 - rbf_fourier_loss: 3.0427\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4867 - out_loss: 3.9545 - rbf_fourier_loss: 3.0188\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5020 - out_loss: 3.9380 - rbf_fourier_loss: 3.0659\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4785 - out_loss: 3.9138 - rbf_fourier_loss: 3.0432\n",
            "it 1/10\n",
            "acc: 54.22222222222223\n",
            "ari: 0.4924974904356286\n",
            "it 1/10\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-164a3651bc4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f1, precision, re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       history = model.fit(moons, [moons,moons], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n\u001b[0;32m---> 23\u001b[0;31m                     validation_split=0)\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 _r=1):\n\u001b[1;32m   1067\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2926\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3333\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3334\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3186\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3188\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 ))\n\u001b[1;32m    972\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    769\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1259\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1260\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2794\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    726\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m--> 728\u001b[0;31m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0m\u001b[1;32m    729\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0mloss_metric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mag_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    150\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    250\u001b[0m           y_pred, y_true)\n\u001b[1;32m    251\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmpmpbrecxg.py\u001b[0m in \u001b[0;36mtf__custom_kitl\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_kernely\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mtrkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[...\n\u001b[1;32m     19\u001b[0m                 \u001b[0mtrkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[...\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(num_rows, num_columns, batch_shape, dtype, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m                              \u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                              \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                              name=name)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg_ops_impl.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(num_rows, num_columns, batch_shape, dtype, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m       batch_shape = ops.convert_to_tensor(\n\u001b[1;32m     64\u001b[0m           batch_shape, name='shape', dtype=dtypes.int32)\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0mdiag_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdiag_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_square\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1670\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1671\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1221\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 1223\u001b[0;31m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   1224\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    417\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m               \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m               as_ref=input_arg.is_ref)\n\u001b[0m\u001b[1;32m    420\u001b[0m           if input_arg.number_attr and len(\n\u001b[1;32m    421\u001b[0m               set(v.dtype.base_dtype for v in values)) > 1:\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[0;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             ctx=ctx))\n\u001b[0m\u001b[1;32m   1597\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1518\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1454\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m   1455\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m-> 1456\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6476\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6477\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 6478\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   6479\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    776\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    592\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    593\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3519\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3521\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3570\u001b[0m                 (key, value))\n\u001b[1;32m   3571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m     \u001b[0;31m# Apply a kernel label if one has been specified for this op type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1hTdAKDjp9n",
        "colab_type": "text"
      },
      "source": [
        "**Mnist**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUslC9Majs2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters=10\n",
        "D=150\n",
        "seed=100\n",
        "lr  = 0.01\n",
        "sigmax=1\n",
        "lk = 0.5\n",
        "bs=64\n",
        "parameters =[ {'rep__lambda_':[0.2,0.5,0.7],'rep__sigmay':[0.05,0.2,0.3,1.7],'rep__K':[n_clusters]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHO9p6DAjs-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meth_name = 'CKAPRI'\n",
        "name='/content/CKAPRI/mnistp5' + meth_name + '.joblib'\n",
        "Niter = 10 #numero particiones\n",
        "sl=len(parameters[0]['rep__lambda_'])\n",
        "ss=len(parameters[0]['rep__sigmay'])\n",
        "acc =np.zeros((Niter,sl,ss))#arreglo para guardar acierto\n",
        "ari=np.zeros((Niter,sl,ss))\n",
        "jacc=np.zeros((Niter,sl,ss))\n",
        "puri=np.zeros((Niter,sl,ss))\n",
        "Nc = len(np.unique(ytrain))\n",
        "\n",
        "for j in range(Niter):\n",
        "  for l in range(sl):\n",
        "    for s in range(ss):\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1, seed=seed)\n",
        "      input_l = tf.keras.layers.Input(shape=(Xtrain.shape[1]), name='entrada')\n",
        "      h1 = tf.keras.layers.experimental.RandomFourierFeatures(output_dim=D,scale=parameters[0]['rep__sigmay'][s], kernel_initializer='gaussian', trainable= False, name='rbf_fourier')(input_l)\n",
        "      output = tf.keras.layers.Dense(n_clusters, activation='softmax', name='out', kernel_initializer=initializer)(h1)\n",
        "      model = tf.keras.Model(inputs=input_l, outputs=[output,h1])\n",
        "      model_loss=[custom_loss_itlh(scalex=sigmax, lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s]),custom_loss_itl( lanbda=parameters[0]['rep__lambda_'][l], scaley=parameters[0]['rep__sigmay'][s])]\n",
        "      model.compile(loss=model_loss,loss_weights = [1-lk,lk],optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),)  # f1, precision, re\n",
        "      history = model.fit(Xtrain, [Xtrain,Xtrain], epochs=100, batch_size=bs,  # 32, 64, 128, 256\n",
        "                    validation_split=0.3)\n",
        "      [y_pred,_] = model.predict(Xtrain)\n",
        "      y_pred=np.argmax(y_pred,axis=1)\n",
        "      y_pred=PRICKA().Lconvert(y_pred,ytraino)\n",
        "      #guardar acierto\n",
        "      acc[j,l,s] = 100*accuracy_score(ytraino,y_pred)\n",
        "      ari[j,l,s]=100*adjusted_rand_score(ytraino,y_pred)\n",
        "      jacc[j,l,s]=100*jaccard_score(ytraino,y_pred,average='weighted')\n",
        "      puri[j,l,s]=100*purity_score(ytraino,y_pred)\n",
        "      #estimar matriz de confusion\n",
        "      print('it %d/%d'%(j+1,Niter))\n",
        "      print('acc:',acc[j,l,s])\n",
        "      print('ari:',ari[j,l,s])\n",
        "      #print('confusionmatrix \\n',cmc[j])\n",
        "      savedata = {\n",
        "        'ari':ari,\n",
        "        'acc':acc,\n",
        "        'jacc':jacc,\n",
        "        'puri':puri,\n",
        "          } \n",
        "      dump(savedata,name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRFemheR2MPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'__results'\n",
        "shutil.make_archive(namefile, 'zip', '/content/CKAPRI')\n",
        "files.download(namefile+'.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4RfHBHrjtSK",
        "colab_type": "text"
      },
      "source": [
        "**Resultados de pruebas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVXFY8DPqr7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[out,h1]=model.predict(Xtrain)\n",
        "lab_e=np.argmax(out,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEF9tJ5UTDdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "804ed4e4-18a2-4b74-e5a0-3295423131e9"
      },
      "source": [
        "\n",
        "def norcka(K):\n",
        "  #K = tf.expand_dims(K,axis=2)\n",
        "  Ke=tf.matmul(K,K,transpose_b=True)\n",
        "  Ke=Ke-tf.math.reduce_min(Ke)\n",
        "  Ke=Ke/tf.math.reduce_max(Ke)\n",
        "  #Ke = tf.expand_dims(K,axis=0)\n",
        "  return Ke\n",
        "\n",
        "plt.subplot(321)\n",
        "Kx = norcka(tf.convert_to_tensor(h1,dtype=tf.float32))\n",
        "plt.imshow(Kx.numpy())\n",
        "plt.title('K estimado')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(322)\n",
        "scalar_kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
        "            amplitude=1, length_scale=sigmay)\n",
        "Ky = scalar_kernel.matrix(tf.convert_to_tensor(Xtrain,dtype=tf.float32), tf.convert_to_tensor(Xtrain,dtype=tf.float32))\n",
        "plt.imshow(Ky.numpy())\n",
        "plt.title('K original')\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "plt.subplot(323)\n",
        "red = PCA(n_components=2)\n",
        "zr = red.fit_transform(h1)\n",
        "plt.scatter(zr[:,0],zr[:,1],c=lab_e)\n",
        "plt.title('etiquetas est')\n",
        "\n",
        "plt.subplot(324)\n",
        "red = PCA(n_components=2)\n",
        "zr = red.fit_transform(h1)\n",
        "plt.scatter(zr[:,0],zr[:,1],c=ytrain)\n",
        "plt.title('etiquetas ori')\n",
        "\n",
        "plt.subplot(325)\n",
        "plt.scatter(Xtrain[:,0],Xtrain[:,1],c=lab_e)\n",
        "plt.title('etiquetas est')\n",
        "\n",
        "plt.subplot(326)\n",
        "plt.scatter(Xtrain[:,0],Xtrain[:,1],c=ytrain)\n",
        "plt.title('etiquetas ori')\n",
        "\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5,wspace=0.5,bottom=0,top=1.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBHGZq8M2tWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}